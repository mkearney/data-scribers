---
title: "Density Ratio Estimation for KL Divergence Minimization between Implicit Distributions"
author: 'tiao.io'
date: '2018-08-27'
slug: density-ratio-estimation-for-k
link: https://tiao.io/post/density-ratio-estimation-for-kl-divergence-minimization-between-implicit-distributions/
categories:
- bloglink
tags:
  - rstats
  - machine-learning
  - modeling
  - tiaoio
---

The Kullback-Leibler (KL) divergence between distributions $p$ and $q$ is defined as $$ \mathcal{D}_{\mathrm{KL}}[p(x) || q(x)] := \mathbb{E}_{p(x)} \left [ \log \left ( \frac{p(x)}{q(x)} \right )[... <i class="fas fa-external-link-alt"></i>](https://tiao.io/post/density-ratio-estimation-for-kl-divergence-minimization-between-implicit-distributions/)

