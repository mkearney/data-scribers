<!DOCTYPE html>
<html lang="en-us">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
  <head>
	<meta name="generator" content="Hugo 0.48" />
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
			<meta name="description" content="">
	
		<title>
				DATA SCrIbers
		</title>
	
		
  		<link rel="stylesheet" href="/css/style.css">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
	
		
		<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
		<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
	
		
		<link href="/index.xml" rel="alternate" type="application/rss+xml" title="DATA SCrIbers" />
	</head>
	

  <body>
		<nav class="nav">
			<div class="nav-container">
			<a href="//">
				<h2 class="nav-title">DATA SCrIbers</h2>
			</a>
			<ul>
				<li><a href="/about"><i class="fas fa-info"></i></a></li>
			</ul>
			</div>
		</nav>


<main>
	<div class="catalogue">
		
				<div>
				  <br>
          <time datetime="2018-01-30 00:00:00 &#43;0000 UTC" class="catalogue-time">January 30, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.gokhanciflikli.com">www.gokhanciflikli.com</a></span>
					<a href="http://www.gokhanciflikli.com"><h1 class="catalogue-title">Scraping Wikipedia Tables from Lists for Visualisation</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://www.gokhan.io/post/scraping-wikipedia/">Get WikiTables from Lists Recently I was asked to submit a short take-home challenge and I thought what better excuse for writing a quick blog post! It was on short notice so initially I stayed within the confines of my comfort zone and went for something safe and bland. However, I alleviated that rather fast; I guess you want to stand out a bit in a competitive setting. Note that it was a visualisation task, so the data scraping was just a necessary<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-29 00:00:00 &#43;0000 UTC" class="catalogue-time">January 29, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://cevo.com.au">cevo.com.au</a></span>
					<a href="http://cevo.com.au"><h1 class="catalogue-title">Introduction to R</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://cevo.com.au/post/2018-01-29-introduction-to-r/">R is great for doing any kind of slicing and dicing with data. However the barrier to entry can be high, especially for people that come from a non-data background. I know that it took me quite some time to grasp just how R does its magic. When you do though, it really is a &ldquo;that&rsquo;s damn awesome&rdquo; moment. Rather than running through all of the basics of R, I put together a script that takes you through some of the features in the context of analysing EC2 pricing<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-29 00:00:00 &#43;0000 UTC" class="catalogue-time">January 29, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://asch3tti.netlify.com">asch3tti.netlify.com</a></span>
					<a href="http://asch3tti.netlify.com"><h1 class="catalogue-title">My first experience with text mining</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://asch3tti.netlify.com/post/text-analysis-wuthheights/">The first step was to quantify how often words were used across the 34 chapters of the novel, to have an initial idea of the content. So, I counted the number of occurrences for each word and selected only the most common ones (i.e., occurring at least 100 times). “How a human being could have attempted such a book as the present without committing suicide before he had finished a dozen chapters, is a<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-28 00:00:00 &#43;0000 UTC" class="catalogue-time">January 28, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.rdatagen.net">www.rdatagen.net</a></span>
					<a href="http://www.rdatagen.net"><h1 class="catalogue-title">Have you ever asked yourself, &#39;how should I approach the classic pre-post analysis?&#39;</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://www.rdatagen.net/post/thinking-about-the-run-of-the-mill-pre-post-analysis/">I’ve explored various scenarios (i.e. different data generating assumptions) to see if it matters which approach we use. (Of course it does.) The plots show the three different types of analysis - follow-up measurement alone, change, or follow-up controlling for baseline: I compare the different modeling approaches by using simulation to estimate statistical power for each. That is, given that there is some effect, how often is the p-value of the test less than<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-28 00:00:00 &#43;0000 UTC" class="catalogue-time">January 28, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.jessemaegan.com">www.jessemaegan.com</a></span>
					<a href="http://www.jessemaegan.com"><h1 class="catalogue-title">R4DS February Challenge</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://www.jessemaegan.com/post/r4ds-february-challenge-winning/">The challenge is short and sweet this month, and the same for both learners and mentors: Remember: the size of your win isn’t what’s important–everyone’s learning process unfolds at different rates and sizes–what matters is coming together to celebrate everyone’s learning journey within our online<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-28 00:00:00 &#43;0000 UTC" class="catalogue-time">January 28, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://ryanestrellado.netlify.com">ryanestrellado.netlify.com</a></span>
					<a href="http://ryanestrellado.netlify.com"><h1 class="catalogue-title">Turning Dataset Codes to Words With R</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://ryanestrellado.netlify.com/post/turning-dataset-codes-to-words/">Note: I include a lot of code in this post so my fellow data scientists can either learn from it or give me feedback about how to make it better. It’s totally ok to skip over all that and just check out the<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-27 00:00:00 &#43;0000 UTC" class="catalogue-time">January 27, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://rsangole.netlify.com">rsangole.netlify.com</a></span>
					<a href="http://rsangole.netlify.com"><h1 class="catalogue-title">First foray into Shiny</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://rsangole.netlify.com/post/first-foray-into-shiny/">Visualising Distributions Visualising Linear Discriminant Analysis Shiny had interested me for a while for it’s power to quickly communicate and vizualise data and models. I hadn’t delved into it due to lack of time to do so, until now. Two quick visualizations I’ve created as my 1st foray into R Shiny. Nothing earth shattering, but was helpful to learn the tool. Visualising Distributions Hosted on shinyapps for free, at link Github code<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-27 00:00:00 &#43;0000 UTC" class="catalogue-time">January 27, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://josiahparry.com">josiahparry.com</a></span>
					<a href="http://josiahparry.com"><h1 class="catalogue-title">Introducing geniusR</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://josiahparry.com/post/introducing-geniusr/">The functions in this package enable easy access of individual song lyrics, album tracklists, and lyrics to whole albums. Load the package: This returns a tidy data frame with three columns: In this example I will extract 3 albums from Kendrick Lamar and Sara Bareilles (two of my favotire musicians). The first step is to create the tibble with artists and album<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-27 00:00:00 &#43;0000 UTC" class="catalogue-time">January 27, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://jesse.tw">jesse.tw</a></span>
					<a href="http://jesse.tw"><h1 class="catalogue-title">Jalen v. Shaq as baby names</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://jesse.tw/post/jalen-v-shaq/">Was Jalen Rose really the first Jalen? He claims his mother was the first to make up the name, a combo of his father’s (the NBA player Jimmie Walker) and uncle’s (Leonard) names. And now we see them everywhere: Jalen Hurts (the Alabama QB that was benched in the national title game a few weeks ago) and Jalen Ramsey (Jags cornerback). Was he really? On the other hand, Shaq is an equally distinct name, what happened after he got<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-26 00:00:00 &#43;0000 UTC" class="catalogue-time">January 26, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.blog.rdata.lu">www.blog.rdata.lu</a></span>
					<a href="http://www.blog.rdata.lu"><h1 class="catalogue-title">Analysis of the Renert - Part 3</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://www.blog.rdata.lu/post/2018-01-26-analysis-of-the-renert-part-3/">Now that we have the data in a nice format, let’s make a frequency plot! First let’s load the data and the packages: Because such a list is not available in Luxembourguish, I have translated it using Google’s translate api. Here is the code to do that: For the above code to work, you need to have a Google cloud account, which you can create for free. Now, I need to merge the dictionary with the data from each<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-26 00:00:00 &#43;0000 UTC" class="catalogue-time">January 26, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://r-tastic.co.uk">r-tastic.co.uk</a></span>
					<a href="http://r-tastic.co.uk"><h1 class="catalogue-title">Trump VS Clinton Interpretable Text Classifier</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://r-tastic.co.uk/post/trump-vs-clinton-interpretable-text-classifier/">As always, let&rsquo;s start with loading necessary packages. Quick glimpse on the class balance, which looks very good, BTW. Finally, let&rsquo;s clean the data a little: select only tweets text and author, change column names to something more readable and remove URLs from text. In order to build the model, we need to tokenize our data and transform it to Document Term Matrices. In this example, I&rsquo;ll use word-level tokens: Now, time for the<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-26 00:00:00 &#43;0000 UTC" class="catalogue-time">January 26, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://thug-r.life">thug-r.life</a></span>
					<a href="http://thug-r.life"><h1 class="catalogue-title">mgsub v1.0 Launched to CRAN</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://thug-r.life/post/2018-01-26-mgsub-launched/">Official CRAN Launch Earlier this week I submitted mgsub to CRAN and after a couple of days it was accepted! Now it’s live! I’m very excited to have published my second package and one that I think is a more valuable contribution than my first. The package represented a few firsts for me. The first package that I wrote tests for, checked code coverage on and for which I wrote a<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-25 00:00:00 &#43;0000 UTC" class="catalogue-time">January 25, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://nowosad.github.io">nowosad.github.io</a></span>
					<a href="http://nowosad.github.io"><h1 class="catalogue-title">Geocomputation with R - the intermission</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://nowosad.github.io/post/geocomputation-with-r-the-intermission/">Both chapters apply command-line based geocomputation introduced in chapters 1-6 to the real world, and answer relevant questions in a reproducible manner with the help of open data and<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-25 00:00:00 &#43;0000 UTC" class="catalogue-time">January 25, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://wenlong-liu.github.io">wenlong-liu.github.io</a></span>
					<a href="http://wenlong-liu.github.io"><h1 class="catalogue-title">Hellow world!</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://wenlong-liu.github.io/post/brand-new-personal-website-of-wenlong-liu-powered-by-hugo-academic-and-blogdown/">I build this website to achieve two goals: helping others know more about my professional achievements, and presenting my most latest output (with details) to persons of interest. Therefore, I will list my publications, including journal articles, conference presentations and proceedings, and book chapters (if any) here. In addition, the post section will briefly introduce my new ideas, experiences or findings. I will also upload some interesting pictures to draw more<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-25 00:00:00 &#43;0000 UTC" class="catalogue-time">January 25, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://saidejp.rbind.io">saidejp.rbind.io</a></span>
					<a href="http://saidejp.rbind.io"><h1 class="catalogue-title">Introducción al Aprendizaje no Supervisado con R</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://saidejp.rbind.io/post/aprendizaje-supervisado/">El presente documento realiza una introducción al aprendizaje no supervisado, el cual se puede entender como un conjunto de técnicas estadísticas que permiten encontrar patrones o estructura en los datos, sin necesariamente contar con hipótesis. Si inspeccionamos la gráfica anterior nos damos cuenta de que hay tres grupos en todo el conjunto de<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-25 00:00:00 &#43;0000 UTC" class="catalogue-time">January 25, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://mouse-imaging-centre.github.io/blog">mouse-imaging-centre.github.io/blog</a></span>
					<a href="http://mouse-imaging-centre.github.io/blog"><h1 class="catalogue-title">Linear Models</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://mouse-imaging-centre.github.io/blog/blog/post/linearmodels/">Preamble The purpose of this post is to elucidate some of the concepts associated with statistical linear models. Let’s start by loading some libraries. library(ggplot2) library(datasets) Background Theory The basic idea is as follows: Given two variables, (x) and (y), for which we’ve measured a set of data points ({x_i, y_i}) with (i = 1, &hellip;, n), we want to estimate a function, (f(x)), such that [y_i = f(x_i) +<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-25 00:00:00 &#43;0000 UTC" class="catalogue-time">January 25, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://thug-r.life">thug-r.life</a></span>
					<a href="http://thug-r.life"><h1 class="catalogue-title">One Year of Trump Executive Orders</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://thug-r.life/post/2018-01-25-one-year-of-trump-eo/">First Year Less than a week ago marked the end of Trump’s first year in office. Back in August I posted code on analyzing the issuing of Executive Orders. Today I’m just going to provide updated commentary. Notes The Federal Register takes time to actually publish Executive Orders. This window is variable but has a median value of 5 days. That’s why this post is coming out on the 25th instead of the<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-25 00:00:00 &#43;0000 UTC" class="catalogue-time">January 25, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://roelandtn.frama.io">roelandtn.frama.io</a></span>
					<a href="http://roelandtn.frama.io"><h1 class="catalogue-title">Problematic, data source, and variables selection</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://roelandtn.frama.io/post/problematic-data-source-and-variable-selection/">This is the first part of a series of blog post regarding a project I did with 2 master degree colleagues. The main entry to this series is here. Today, we will discuss the problematic, the data and the variables selection from those data in respect of the problematic. Althought it is not really technical post, it provides some context and elements do someone who wants to redo the<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-24 00:00:00 &#43;0000 UTC" class="catalogue-time">January 24, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.blog.rdata.lu">www.blog.rdata.lu</a></span>
					<a href="http://www.blog.rdata.lu"><h1 class="catalogue-title">Analysis of the Renert - Part 2</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://www.blog.rdata.lu/post/2018-01-24-analysis-of-the-renert-part-2/">So, let’s unnest the tokens: We can remove these with a couple lines of code: For my Luxembourgish-speaking compatriots, I’d be glad to get help to make this list better! This list is far from perfect, certainly contains typos, or even words that have no reason to be there! Please<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-24 00:00:00 &#43;0000 UTC" class="catalogue-time">January 24, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://blog.schochastics.net">blog.schochastics.net</a></span>
					<a href="http://blog.schochastics.net"><h1 class="catalogue-title">SOMs and ggplot</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://blog.schochastics.net/post/soms-and-ggplot/">We will, however, only use a random sample of the 75,000 players, for computational convenience. We start by computing the SOM for the random sample. There we go! Now we can continue putting the players in the right node. I think you can see more easily how homogeneous the grid nodes are with this plot. This very much the same code as used in the package. Below is the standard plot. Again, quite the same, except for the inverted color<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-24 00:00:00 &#43;0000 UTC" class="catalogue-time">January 24, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://saidejp.rbind.io">saidejp.rbind.io</a></span>
					<a href="http://saidejp.rbind.io"><h1 class="catalogue-title">Socioeconomic Factors of Poor Physical and Mental Health</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://saidejp.rbind.io/post/socioeconomic-factors-of-poor-physical-and-mental-health/">BRFSS is an ongoing surveillance system designed to measure behavioral risk factors for the non-institutionalized adult population (18 years of age and older) residing in the US. The BRFSS was initiated in 1984, with 15 states collecting surveillance data on risk behaviors through monthly telephone<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-22 00:00:00 &#43;0000 UTC" class="catalogue-time">January 22, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://linuxize.com">linuxize.com</a></span>
					<a href="http://linuxize.com"><h1 class="catalogue-title">Configure Odoo with with nginx as a reverse proxy.</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://linuxize.com/post/configure-odoo-with-nginx-as-a-reverse-proxy/">Odoo is one the of most popular business softwares in the world and it is packed with multiple useful modules like customer relationship management (CRM), point of sale, project management, inventory management, automated invoicing, accounting, e-commerce, inventory management and much more. This guide provides instructions on how to use Nginx as a reverse proxy to Odoo using HTTPS. Prerequisites Make sure that you have met the following prerequisites before continuing with this<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-22 00:00:00 &#43;0000 UTC" class="catalogue-time">January 22, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.gokhanciflikli.com">www.gokhanciflikli.com</a></span>
					<a href="http://www.gokhanciflikli.com"><h1 class="catalogue-title">Predicting Conflict Duration with (gg)plots using Keras</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://www.gokhan.io/post/keras-conflict/">An Unlikely Pairing Last week, Marc Cohen from Google Cloud was on campus to give a hands-on workshop on image classification using TensorFlow. Consequently, I spent most of my time thinking about how I can incorporate image classifiers in my work. As my research is primarily on forecasting armed conflict duration, it’s not really straightforward to make a connection between the<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-22 00:00:00 &#43;0000 UTC" class="catalogue-time">January 22, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://cevo.com.au">cevo.com.au</a></span>
					<a href="http://cevo.com.au"><h1 class="catalogue-title">Sending Watchmen into the Open</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://cevo.com.au/post/2018-01-22-opensource-watchmen/">Open source software is a decentralised development and distribution model that encourages collaboration in the public domain. Source code and other artefacts of the software development are made available to the public to use, copy and customise in any way to suit business needs. This is in contrast to traditional proprietary software, where software is under restrictive copyright and the source code is usually hidden from the<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-20 00:00:00 &#43;0000 UTC" class="catalogue-time">January 20, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://sciathlon.github.io">sciathlon.github.io</a></span>
					<a href="http://sciathlon.github.io"><h1 class="catalogue-title">Figure skating athletes&#39; personal best</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://Sciathlon.github.io/post/personal_best_figure_skating/">Today I am writing another piece about figure skating, also another piece about data analysis in this event. But I am not focusing solely on the Olympics this time but on the best scoring athletes and the best scoring event of each<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-20 00:00:00 &#43;0000 UTC" class="catalogue-time">January 20, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://sciathlon.github.io">sciathlon.github.io</a></span>
					<a href="http://sciathlon.github.io"><h1 class="catalogue-title">R figure skating analysis</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://Sciathlon.github.io/post/analysis_medal_per_athlete/">Analysing medals won per athlete/per country with R Today I am introducing a sneaky little data analysis using R on figure skating in the olympics. I have already written a piece on Figure skating and what I think is going to happen in the upcoming olympics. But I also want to look back at athletes who have competed and won a medal in the past Olympics. If you&rsquo;ve never heard of data science, this is how you can make very easy analysis of your favorite things in the<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-19 00:00:00 &#43;0000 UTC" class="catalogue-time">January 19, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://mouse-imaging-centre.github.io/blog">mouse-imaging-centre.github.io/blog</a></span>
					<a href="http://mouse-imaging-centre.github.io/blog"><h1 class="catalogue-title">StanCon Highlights</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://mouse-imaging-centre.github.io/blog/blog/post/2018-01-13_stancon-highlights/">Hi readers, Recently I got back from StanCon 2018 Ansilomar. I had a little time waiting for one of my flights and I thought I’d reflect on the conference. Last year I was lucky enough to go to the first StanCon and it was nice to be able to see how the conference has grown. This year it was three days of tutorials, talks, and networking. I had a<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-19 00:00:00 &#43;0000 UTC" class="catalogue-time">January 19, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://blog.schochastics.net">blog.schochastics.net</a></span>
					<a href="http://blog.schochastics.net"><h1 class="catalogue-title">Traveling Beerdrinker Problem</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://blog.schochastics.net/post/traveling-beerdrinker-problem/">Whenever I participate in a Science Slam, I try to work in an analysis of something typical for the respective city. My next gig will be in Munich, so there are two natural options: beer or football. In the end I choose both, but here I will focus on the former. In the next section, I briefly explain what we are going to do with the data. If you are already familiar with the traveling salesman problem, which in our case becomes the traveling beerdrinker problem, you can safely skip that<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-19 00:00:00 &#43;0000 UTC" class="catalogue-time">January 19, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://mouse-imaging-centre.github.io/blog">mouse-imaging-centre.github.io/blog</a></span>
					<a href="http://mouse-imaging-centre.github.io/blog"><h1 class="catalogue-title">Welcome</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://mouse-imaging-centre.github.io/blog/blog/post/welcome/">Hello World! Welcome to the new Mouse Imaging Centre Blog. We created this blog as a place to share things we’ve been thinking about lately. This blog will feature a mixture of technical writing about things we do in our lab including imaging, statistics, and biology. The blog will feature contributions from our staff, students, and PIs. We hope you enjoy our writings. To learn more about us please visit our website at<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-18 00:00:00 &#43;0000 UTC" class="catalogue-time">January 18, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.rdatagen.net">www.rdatagen.net</a></span>
					<a href="http://www.rdatagen.net"><h1 class="catalogue-title">Importance sampling adds an interesting twist to Monte Carlo simulation</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://www.rdatagen.net/post/importance-sampling-adds-a-little-excitement-to-monte-carlo-simulation/">Like many of the topics I’ve written about, this is a vast one that certainly warrants much, much more than a blog entry. MC simulation in particular, since it is so fundamental to the practice of statistics. MC methods are an essential tool to understand the behavior of statistical models. In fact, I’ve probably used MC simulations in just about all of my posts - to generate repeated samples from a model to explore bias, variance, and other distributional characteristics of a particular<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-17 00:00:00 &#43;0000 UTC" class="catalogue-time">January 17, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://emitanaka.github.io">emitanaka.github.io</a></span>
					<a href="http://emitanaka.github.io"><h1 class="catalogue-title">Curated Collection of Teaching Materials</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://emitanaka.github.io/post/teaching/">That infamous<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-17 00:00:00 &#43;0000 UTC" class="catalogue-time">January 17, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://cevo.com.au">cevo.com.au</a></span>
					<a href="http://cevo.com.au"><h1 class="catalogue-title">Replacing Packer With KitchenCI and a Rakefile</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://cevo.com.au/post/2018-01-17-replacing-packer-with-kitchen-and-a-rakefile/">Don&rsquo;t get me wrong, I love the HashiCorp products. I&rsquo;ve been a Vagrant user since way back in my BC (Before Cloud) days and have continued a strong run of success backing the use of HashiCorp product. But the biggest issue I have is ensuring that the images created through Packer are worthy of being promoted along a delivery pipeline. This post is about using KitchenCI, InSpec and a small Rakefile to create an enhanced AWS Machine Image (AMI) creation and validation<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-17 00:00:00 &#43;0000 UTC" class="catalogue-time">January 17, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://translatedmedicine.com">translatedmedicine.com</a></span>
					<a href="http://translatedmedicine.com"><h1 class="catalogue-title">The Digital Divide in the U.S.</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://translatedmedicine.netlify.com/post/the-digital-divide-in-the-u-s/">With the release of the American Community Survey, there was an opportunity to take a look at the digital divide in 2016. I was inspired to make a tilegram map similar to those create by NPR. I used the tilegramsR package by Bhaskar Karambelkar. First, here are the packages for the<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-16 00:00:00 &#43;0000 UTC" class="catalogue-time">January 16, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.mytinyshinys.com">www.mytinyshinys.com</a></span>
					<a href="http://www.mytinyshinys.com"><h1 class="catalogue-title">EPL Week 23</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://www.mytinyshinys.com/2018/01/16/epl-week-23/">Man City’s unbeaten run ended by a Coutinho-less Liverpool in seven goal thriller Match of the DaySubsOn Saturday an oddity occurred. The kind of ‘Dog didn’t bark in the night’ sort. Roy Hodgson, with his team hanging on to a precious three points for what would make a ’massive win&rdquo; failed to make a substitution: a norm for<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-16 00:00:00 &#43;0000 UTC" class="catalogue-time">January 16, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://sumprain.netlify.com">sumprain.netlify.com</a></span>
					<a href="http://sumprain.netlify.com"><h1 class="catalogue-title">Interpreting Results from Clinical Research</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://sumprain.netlify.com/post/clinical_research_results/">Estimation of effect size (ES) with confidence intervals (CI) of ES are much easy to understand and carry much more informations with them making them a preferable way to present results in clinical research. Hope you like the post. Feel free to post any<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-15 00:00:00 &#43;0000 UTC" class="catalogue-time">January 15, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.samabbott.co.uk">www.samabbott.co.uk</a></span>
					<a href="http://www.samabbott.co.uk"><h1 class="catalogue-title">Exploring Global Trends in Tuberculosis Incidence Rates - with GetTBinR</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://www.samabbott.co.uk/post/intro-gettbinr/">For this post I will be quickly diving into global trends in Tuberculosis incidence rates and exploring whether Tuberculosis eradication is on the horizon. Now to get started, the first step is to get the package (for this post we are using the development version from GitHub) and to load the other packages required for this analysis. The package is loaded, time to get the data. We download both the data itself and it’s accompanying data<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-15 00:00:00 &#43;0000 UTC" class="catalogue-time">January 15, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://yonicd.netlify.com">yonicd.netlify.com</a></span>
					<a href="http://yonicd.netlify.com"><h1 class="catalogue-title">RStudio Addin Manager</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://yonicd.netlify.com/post/rsam/">Via the command line you can manage the addins with greater<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-14 00:00:00 &#43;0000 UTC" class="catalogue-time">January 14, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://roelandtn.frama.io">roelandtn.frama.io</a></span>
					<a href="http://roelandtn.frama.io"><h1 class="catalogue-title">Update for the Mexico project</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://roelandtn.frama.io/post/update-for-the-mexico-project/">Hello, the project that I was talking about earlier is finally over. But it tooks me (and my colleagues) so much time to do that I wasn&rsquo;t able to post about it. Anyway, the project website is online and can be seen there: http://m2_projet_mexique.frama.io/website/ Ok, it is in French but, first, it is for a French diploma in a French university, so&hellip; And second, I&rsquo;ll make translations of the posts<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-12 00:00:00 &#43;0000 UTC" class="catalogue-time">January 12, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://thestudyofthehousehold.com">thestudyofthehousehold.com</a></span>
					<a href="http://thestudyofthehousehold.com"><h1 class="catalogue-title">A tidy game of life</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://thestudyofthehousehold.com/2018/01/12/2018-01-12-a-tidy-game-of-life/">Ever since I moved to France for my postdoc in September 2016, I’ve tried to practice French whenever I can. One easy way to do that is by consuming YouTube channels in French – great things to put on the the background while I make food for my son, or feed my son, or clean up after feeding my son, etc. One of my favourite chaînes de Youtube is Science Etonnante, by David<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-12 00:00:00 &#43;0000 UTC" class="catalogue-time">January 12, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.blog.rdata.lu">www.blog.rdata.lu</a></span>
					<a href="http://www.blog.rdata.lu"><h1 class="catalogue-title">Churn Analysis - Part 2</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://www.blog.rdata.lu/post/2018-01-12-churn-analysis2/">Hello everyone, Each customer has a score that corresponds to his probability to churn. Let’s see the score of the five first customers of our database. We draw a table where we show the maximum value for each indicator. Now we want to target a percentage of customers in our database. Let’s sort customers by their score. Then, we observe the churn rate in different percentile of our database. The best way to visualize the churn rate by percentile is to make a lift<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-11 00:00:00 &#43;0000 UTC" class="catalogue-time">January 11, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://sjfox.github.io">sjfox.github.io</a></span>
					<a href="http://sjfox.github.io"><h1 class="catalogue-title">Visualizing flight data with ggplot2</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://sjfox.github.io/post/world_map_flights/">This next part is the hard part. We need to combine and clean the two datasets. To begin we do two joins, because we need the lat and long data for both the source and the destination airports. After that I create a new column that captures the source and destination airports, remove duplicates, and create a variable to loosely capture the flights to and from Europe (You’ll see why at the<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-11 00:00:00 &#43;0000 UTC" class="catalogue-time">January 11, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://sciathlon.github.io">sciathlon.github.io</a></span>
					<a href="http://sciathlon.github.io"><h1 class="catalogue-title">What to Expect at Winter Olympics 2018 for figure skating</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://Sciathlon.github.io/post/what-to-expect-at-winter-olympics-2018/">The winter olympics are coming! It is an exciting time to celebrate our favorite sports and feel inspired to do better ourselves. It is going to be interesting this year with the doping ban for Russia as well as many unfortunate injuries and retirements. Figure skating is my favorite event because it is an incredibly beautiful and hard sport that I practised for a few years when I was<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-10 00:00:00 &#43;0000 UTC" class="catalogue-time">January 10, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.noahlandesberg.com">www.noahlandesberg.com</a></span>
					<a href="http://www.noahlandesberg.com"><h1 class="catalogue-title">8 Analytics Books I Read in 2017</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://noahlandesberg.com/post/8-analytics-books-i-read-in-2017/">This year I made a concerted effort to read more books related to my interests in analytics, math, and data science. I had the pleasure of reading most of these books with a group of people at work, and we met on a regular basis to discuss and gab. These books are casual, and not meant to be as strictly educational (or tedious) as reading a textbook. Without further ado&hellip; here are 8 analytics books I read this year: Dataclysm explores the data underlying human connections and<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-10 00:00:00 &#43;0000 UTC" class="catalogue-time">January 10, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://sciathlon.github.io">sciathlon.github.io</a></span>
					<a href="http://sciathlon.github.io"><h1 class="catalogue-title">A History of Skiing</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://Sciathlon.github.io/post/the-history-of-skiing/">I started skiing at the age of 3 at the station in the Alps called the &ldquo;Sept Laux&rdquo; next to Grenoble, France. It was natural to me, but until now I never wondered for how long people have done it. Here is a brief history of how it all began. The word ski comes from old Norse, a germanic language that was spoken in Scandinavia from the 8th to the late 14th<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-10 00:00:00 &#43;0000 UTC" class="catalogue-time">January 10, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://cevo.com.au">cevo.com.au</a></span>
					<a href="http://cevo.com.au"><h1 class="catalogue-title">Meltdown, Spectre and Linux on AWS</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://cevo.com.au/post/2018-01-10-ec2-pcid-instance-types/">Meltdown, Spectre and Linux on AWS: Security vs Performance? The recent announcement of the Meltdown and Spectre attacks against bugs in Intel (and other) CPUs has attracted rapid response from many vendors; Amazon Web Services&rsquo; (AWS) response shows that they&rsquo;ve already patched and protected their infrastructure but you still have work to<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-10 00:00:00 &#43;0000 UTC" class="catalogue-time">January 10, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.gokhanciflikli.com">www.gokhanciflikli.com</a></span>
					<a href="http://www.gokhanciflikli.com"><h1 class="catalogue-title">Quantitative Story Telling with Shiny</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://www.gokhan.io/post/lse-gender/">LSE IR Gender and Diversity Project Two shinydashboard posts in a row, that’s a first. As I mentioned on Twitter, I’m not really this productive; rather, the apps had been on the proverbial shelf for a while and I’m just releasing them now. In fact, this is one of my earlier works: quantifying the gender imbalance as it manifests itself in the LSE International Relations (IR) reading lists. You can access the app<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-10 00:00:00 &#43;0000 UTC" class="catalogue-time">January 10, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://thug-r.life">thug-r.life</a></span>
					<a href="http://thug-r.life"><h1 class="catalogue-title">Safe, Multiple String Substitutions with mgsub</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://thug-r.life/post/2018-01-10-safe-multiple-string-substitutions/">String substitutions Note - the package I wrote was originally inspired by a challenge a coworker tossed out. It also happened to provide a solution to this SO question which was really cool! Substitutions in strings are best handled with regular expressions which are an amazingly powerful and flexible tool. Regular expressions are a way of expressing patterns in strings. In the example below I want to find the four letters, “dopa” and replace them with<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-10 00:00:00 &#43;0000 UTC" class="catalogue-time">January 10, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://mlr-blog.netlify.com">mlr-blog.netlify.com</a></span>
					<a href="http://mlr-blog.netlify.com"><h1 class="catalogue-title">Stepwise Bayesian Optimization with mlrMBO</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="https://mlr-blog.netlify.com/post/2018-01-10-stepwise-bayesian-optimization-with-mlrmbo/">With the release of the new version of mlrMBO we added some minor fixes and added a practical feature called Human-in-the-loop MBO. It enables you to sequentially visualize the state of the surrogate model, obtain the suggested parameter configuration for the next iteration and update the surrogate model with arbitrary evaluations. In the following we will demonstrate this feature on a simple example. First we need an objective function we want to<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-10 00:00:00 &#43;0000 UTC" class="catalogue-time">January 10, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.rladiesnyc.org">www.rladiesnyc.org</a></span>
					<a href="http://www.rladiesnyc.org"><h1 class="catalogue-title">Workshop</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://www.rladiesnyc.org/post/workshop-functional-programming-with-purrr/">Join us for our first R Ladies NYC event of 2018! Date: Wednesday, January 10, 2018 Time: 6:30pm Instructor: Joyce Robbins Host: Schapiro Center Columbia<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
				<div>
				  <br>
          <time datetime="2018-01-09 00:00:00 &#43;0000 UTC" class="catalogue-time">January 9, 2018 via
          </time><span><a style="color:#36d;font-style:italic" href="http://www.datalorax.com">www.datalorax.com</a></span>
					<a href="http://www.datalorax.com"><h1 class="catalogue-title">A tidyeval use case</h1></a>
					<div class="catalogue-line"></div>


					<p>
						<p><a href="http://www.dandersondata.com/post/a-tidyeval-use-case/">A relatively routine process for me is to combine multiple files into a single data frame by row. For example, the data might be stored in separate CSV files by grade and content area, but I want to load them all and treat it as a single data frame with a grade and content indicator. A good default for this sort of process, is to keep all the variables that are present in any data file, and pad with missingness for the files that don&rsquo;t have that specific<i class="fas fa-external-link-alt"></i></a></p>

					</p>

				</div>
		
	</div>

	<div class="pagination">
		
			<a href="/page/12/" class="left arrow">&#8592;</a>
		
		
			<a href="/page/14/" class="right arrow">&#8594;</a>
		

		<span>13 / 20</span>
	</div>
</main>

		<footer>
			<span>
			&copy; <time datetime="2018-09-22 19:40:21.157369 -0500 CDT m=&#43;0.724737873">2018</time> . Made by <a href="https://mikewk.com">Michael W. Kearney</a>.
			</span>
		</footer>
  </body>
</html>

