<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Evangelinereynoldsnetlifycom on rscribers</title>
    <link>/tags/evangelinereynoldsnetlifycom/</link>
    <description>Recent content in Evangelinereynoldsnetlifycom on rscribers</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Sep 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/evangelinereynoldsnetlifycom/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Slow ggplot</title>
      <link>/post/slow-ggplot/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/slow-ggplot/</guid>
      <description>This post has lots in common with previous posts on “the layered presentation of graphics”. It is about building up plots, but now with a focus on this incramental change for teaching ggplot2. The rational is that observing the cause and effect of incremental change is easier to digest, and that the repetition in this approach means students have more chances to learn the ggplot2 functions. My recent tweet presented the technique: People reacted&amp;hellip;</description>
    </item>
    
    <item>
      <title>Visualizing Variance and Standard Deviation</title>
      <link>/post/visualizing-variance-and-stand/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/visualizing-variance-and-stand/</guid>
      <description>So this wasn’t on today’s to-do list, but there seems to be a cash prize associated with this rabbit hole due to this tweet: So here we go. I’m using the gapminder dataset which is ever-so-handy as it’s available in an R package (thanks Jenny Bryan). For the exercise I’ll just be looking at European countries in 2007, and focusing exclusively on the life expectancy variable. Let’s look at a plot of the data&amp;hellip;.</description>
    </item>
    
    <item>
      <title>National Anthems’ Sentiment Scores, Mapped and Interactive</title>
      <link>/post/national-anthems-sentiment-sco/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/national-anthems-sentiment-sco/</guid>
      <description>This post, as indicated in the title, is about an interactive mapping of sentiment scores calculated for national anthems. Text analysis is of growing interest for political researchers, and I count myself among the interested! The interactive plot at the end of the post is, I think, an ideal introduction sentiment analysis. It highlights opportunities, and also, perhaps, some pitfalls. I want to give quick background on how this happens to be in my blog, to give plenty of credit where it is&amp;hellip;</description>
    </item>
    
    <item>
      <title>Layered Presentation of Graphics, revised</title>
      <link>/post/layered-presentation-of-graphi/</link>
      <pubDate>Sun, 22 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/layered-presentation-of-graphi/</guid>
      <description>I think it is more straight forward than messing around with alpha. Several folks brought up geom_blank() having looked at the previous implementation, but I didn’t find it necessary in this case if you are using last_plot() which I think it makes sense to do in this context. Still, geom_blank is good to know about. This time around, I’ll do a little with labeling&amp;hellip;</description>
    </item>
    
    <item>
      <title>Where should you declare aesthetics?  Globally, or geom-by-geom?</title>
      <link>/post/where-should-you-declare-aesth/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/where-should-you-declare-aesth/</guid>
      <description>Where should you declare aesthetics? Globally or in the geom_*() function? The answer to this question, in some sense is personal preference, because there are simply different ways to get the same job done in the ggplot architecture. My preference is declaring all aesthetic mappings as global unless there are conflicts. Below is an example that, I hope, will persuade you to my preference. We graph the increase in life expectancy by year for three&amp;hellip;</description>
    </item>
    
    <item>
      <title>Tuition Increases for Tidy Tuesday</title>
      <link>/post/tuition-increases-for-tidy-tue/</link>
      <pubDate>Mon, 09 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/tuition-increases-for-tidy-tue/</guid>
      <description>Here’s the code for my first Tidy Tuesday&amp;hellip;</description>
    </item>
    
    <item>
      <title>Wide data to long using the tidyverse (tidyr&#39;s gather function)</title>
      <link>/post/wide-data-to-long-using-the-ti/</link>
      <pubDate>Fri, 06 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/wide-data-to-long-using-the-ti/</guid>
      <description>A wide data storage format is an efficient and compact way to store information. And this organization perhaps it makes data easier to inspect. We have wide monitors our laptops and destops. However, for visualization and analysis you generally need to transform this data from the wide format to a “tidy”, long format. We look at the case where just one variable is stored in a&amp;hellip;</description>
    </item>
    
    <item>
      <title>Selection effects</title>
      <link>/post/selection-effects/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/selection-effects/</guid>
      <description>My limited goals: Perhaps the central difference between working in the Stata environment and in R is that in R you always have to be declaring which data frame you are working with. In Stata, you just have one active data frame and then you can refer to the variables by their names alone. The tidyverse tools with piping make working in R feel more like working in Stata in my&amp;hellip;</description>
    </item>
    
    <item>
      <title>The visual taming of a paradox</title>
      <link>/post/the-visual-taming-of-a-paradox/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-visual-taming-of-a-paradox/</guid>
      <description>@drob has posted code to play with on Twitter today. To illustrate what he calls a veridical paradox he’s posted the set up, the code and result of a coin flipping experiment: There are some good and exact explanations in the thread, for this at-first-glance puzzle. But I didn’t see a visualization that might give you quick intuition about what is going on. So I prepare one here. We’ll use the tidyverse packages and stringr.</description>
    </item>
    
    <item>
      <title>Federalist Papers</title>
      <link>/post/federalist-papers/</link>
      <pubDate>Sat, 16 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/federalist-papers/</guid>
      <description>Every couple of weeks I like to explore data that’s brand new to me. I anticipate a one-hour, one-off project. Usually this turns out to be a beautiful lie, and the projects chew up much more time. Still, this enticing time-line is pulling me into new projects from time to time. Earlier this week, I heard about the dispute of authorship of some of the Federalist papers. I mentally flagged the topic for one a one-hour,&amp;hellip;</description>
    </item>
    
    <item>
      <title>Covariance -- A Visual Walk Through</title>
      <link>/post/covariance-a-visual-walk-throu/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/covariance-a-visual-walk-throu/</guid>
      <description>In a previous post, I’ve looked at walking through the calculation of variance and standard deviation, visualizing each step. This post is dedicated to the visualization of another statistic: covariance. Covariance is a measure of the joint variability of two random variables. And now lets apply the equation to the following case: Ready? Okay, now let’s walk through the calculation; there are 7 small steps: That’s&amp;hellip;</description>
    </item>
    
    <item>
      <title>Eat near the Big Ben?  That will cost you...</title>
      <link>/post/eat-near-the-big-ben-that-will/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/eat-near-the-big-ben-that-will/</guid>
      <description>#MakeoverMonday is a fun data visualization initiative; most participants use Tableau as their preferred visualization tool. But I’ve used R and ggplot() and the organizers and participants have been very welcoming. (Recently, I’ve noticed an initiative for R has sprouted up — #TidyTuesday, with a focus on visualization and data&amp;hellip;</description>
    </item>
    
    <item>
      <title>What’s the IGO dataset?</title>
      <link>/post/whats-the-igo-dataset/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/whats-the-igo-dataset/</guid>
      <description>This webpage is meant provide students and the curious with an visual, explorable introduction to the dataset. The number of IGOs observed over the time period of 1815 to 2005 has dramatically increased. At the beginning of this period there were just a handful, but now they number more than 300. The number of IGO-country memberships, likewise has also grown dramatically. Individual country affiliations with IGOs numbers more than&amp;hellip;</description>
    </item>
    
  </channel>
</rss>