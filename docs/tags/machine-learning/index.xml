<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on {&lt;span style=&#39;color:red&#39;&gt;data sc&lt;/span&gt;r&lt;span style=&#39;color:red&#39;&gt;i&lt;/span&gt;&lt;span style=&#39;color:red&#39;&gt;bers}</title>
    <link>/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on {&lt;span style=&#39;color:red&#39;&gt;data sc&lt;/span&gt;r&lt;span style=&#39;color:red&#39;&gt;i&lt;/span&gt;&lt;span style=&#39;color:red&#39;&gt;bers}</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Sep 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Data Science in Mental Health</title>
      <link>/post/data-science-in-mental-health/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/data-science-in-mental-health/</guid>
      <description>I came across two articles recently that I thought spoke to each other in an interesting way. The first was a New York Times piece about the failings of data science firms who try to identify school shootings before they happen by social media&amp;hellip;</description>
    </item>
    
    <item>
      <title>DL Indaba</title>
      <link>/post/dl-indaba/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/dl-indaba/</guid>
      <description>Vukosi and Yasin(i) share how Deep Learning Indaba is playing an important role to recognize and grow machine learning research and companies on the African continent. We also discuss Yasin(i)&amp;rsquo;s prototyped app, Tukuka, and how it won the Maathai Award which is given to individuals who are a positive force for&amp;hellip;</description>
    </item>
    
    <item>
      <title>Parallel Computing in R</title>
      <link>/post/parallel-computing-in-r/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/parallel-computing-in-r/</guid>
      <description>We&amp;rsquo;re excited to host Jared Lander, Chief Data Scientist of Lander Analytics, the organizer of the New York Open Statistical Programming Meetup and the New York R Conference, and author of R for Everyone, to talk about parallel computing in&amp;hellip;</description>
    </item>
    
    <item>
      <title>#GI2018 - Day Two</title>
      <link>/post/gi2018-day-two/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/gi2018-day-two/</guid>
      <description>Typos everywhere. Things may change dramatically over time as I scan back through notes. I’ve tried to respect #notwitter. Will be updated&amp;hellip;</description>
    </item>
    
    <item>
      <title>From Zero to GPU 2 - Squeezing Neural Network Performance on CPU</title>
      <link>/post/from-zero-to-gpu-2-squeezing-n/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/from-zero-to-gpu-2-squeezing-n/</guid>
      <description>Welcome to the second post in my From Zero to GPU series. Where I talk about aspects of neural network implementations. In the last post, we have: Trained a simple, feedforward network Deployed it in C++ Got abysmal performance compared to the reference implementation In this post, I&amp;rsquo;m going to investigate the different optimizations to speed up CPU&amp;hellip;</description>
    </item>
    
    <item>
      <title>Building Infrastructure with R</title>
      <link>/post/building-infrastructure-with-r/</link>
      <pubDate>Mon, 17 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/building-infrastructure-with-r/</guid>
      <description>For this event we will explore how to build tools and infrastructure with R. 6:15-6:30pm Introductions and Social 6:30- 6:45 pm NYT announcements (Data, Tech, HR) 6:45-6:55pm R-Ladies New York Announcements 6:55-7:25pm Object Oriented Programming in R 7:25-7:55pm Big Data in R with Small Prototypes: Scaling 8:00-8:15pm&amp;hellip;</description>
    </item>
    
    <item>
      <title>Tensorflow</title>
      <link>/post/tensorflow/</link>
      <pubDate>Mon, 17 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/tensorflow/</guid>
      <description>Explicitly naming nodes is nonessential, but can be very useful when debugging. Oftentimes, when your Tensorflow code crashes, the error trace will refer to a specific operation. If you have many operations of the same type, it can be tough to figure out which one is problematic. By explicitly naming each of your nodes, you can get much more informative error traces, and identify the issue more&amp;hellip;</description>
    </item>
    
    <item>
      <title>In Machine Learning Predictions for Health Care the Confusion Matrix is a Matrix of Confusion</title>
      <link>/post/in-machine-learning-prediction/</link>
      <pubDate>Tue, 28 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/in-machine-learning-prediction/</guid>
      <description>Machine Learning (ML) has already transformed e-commerce, web search, advertising, finance, intelligence, media, and more. ML is becoming ubiquitous and its centripetal gravity draws health care into the&amp;hellip;</description>
    </item>
    
    <item>
      <title>Moving beyond pattern-based analysis</title>
      <link>/post/moving-beyond-patternbased-ana/</link>
      <pubDate>Tue, 28 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/moving-beyond-patternbased-ana/</guid>
      <description>GeoPAT 2 gives its users a lot of freedom, having a large number of possible workflows: Some of them can consist of only one step, while others require several steps. However, that is not the end of GeoPAT 2 capabilities - it is also possible to extract spatial signature or calculate distance matrix and use these outputs in further analysis outside of GeoPAT&amp;hellip;</description>
    </item>
    
    <item>
      <title>Neural Processes as distributions over functions</title>
      <link>/post/neural-processes-as-distributi/</link>
      <pubDate>Fri, 10 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/neural-processes-as-distributi/</guid>
      <description>Neural Processes (NPs) caught my attention as they essentially are a neural network (NN) based probabilistic model which can represent a distribution over stochastic processes. So NPs combine elements from two worlds: Both have their advantages and drawbacks. In the limited data regime, GPs are preferable due to their probabilistic nature and ability to capture&amp;hellip;</description>
    </item>
    
    <item>
      <title>Everything I Know About Machine Learning I Learned from Making Soup</title>
      <link>/post/everything-i-know-about-machin/</link>
      <pubDate>Mon, 06 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/everything-i-know-about-machin/</guid>
      <description>Introduction In this post, I’m going to make the claim that we can simplify some parts of the machine learning process by using the analogy of making soup. I think this analogy can improve how a data scientist explains machine learning to a broad audience, and it provides a helpful framework throughout the model building&amp;hellip;</description>
    </item>
    
    <item>
      <title>More on Graph Inspection</title>
      <link>/post/more-on-graph-inspection/</link>
      <pubDate>Sun, 05 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/more-on-graph-inspection/</guid>
      <description>The computational graph is not just a nebulous, immaterial abstraction; it is a computational object that exists, and can be inspected. Complicated graphs are difficult to debug if we are representing them entirely in our heads, but inspecting and debugging the actual graph object makes thigs much&amp;hellip;</description>
    </item>
    
    <item>
      <title>Announcing</title>
      <link>/post/announcing/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/announcing/</guid>
      <description>Richard Feynmann 1 has once said: What I cannot create, I do not understand. To understand Neural Networks, and how the recent Machine Learning evolution happened. I&amp;rsquo;ve decided to go back to basics, and write a Neural Network library from&amp;hellip;</description>
    </item>
    
    <item>
      <title>From Zero to GPU 1 - A new neural network is born</title>
      <link>/post/from-zero-to-gpu-1-a-new-neura/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/from-zero-to-gpu-1-a-new-neura/</guid>
      <description>Welcome to the first post in my From Zero to GPU series. Where I talk about aspects of neural network implementations. This blog post was actually finished all the way back in July, due to some unforseen delays, I&amp;rsquo;ve only gotten around to publishing it now, my&amp;hellip;</description>
    </item>
    
    <item>
      <title>Tensorflow</title>
      <link>/post/tensorflow/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/tensorflow/</guid>
      <description>This post is my attempt to fill this gap. Rather than focusing on a specific task, I take a more general approach, and explain the fundamental abstractions underpinning Tensorflow. With a good grasp of these concepts, deep learning with Tensorflow becomes intuitive and straightforward. Most Python libraries are written to be natural extensions of&amp;hellip;</description>
    </item>
    
    <item>
      <title>Day 36-37: Concerned DALEX</title>
      <link>/post/day-3637-concerned-dalex/</link>
      <pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/day-3637-concerned-dalex/</guid>
      <description>I was working on a longer post continuing the metaprogramming series, and realised I wasn’t going to get it done this evening. But it’s been a couple of days since I tried out something new, so I resorted to the twitters to find&amp;hellip;</description>
    </item>
    
    <item>
      <title>My First Post</title>
      <link>/post/my-first-post/</link>
      <pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/my-first-post/</guid>
      <description>Welcome to my blog! I plan to use this website to present data explorations and analyses in a way that’s understandable to a broad audience. I hope to demonstrate the utility of applying ideas like machine learning, data visualization, and exploratory data analysis to day-to-day life to improve decision-making processes. I was inspired to create a blog after reading this post by David&amp;hellip;</description>
    </item>
    
    <item>
      <title>The Genetics of Magic</title>
      <link>/post/the-genetics-of-magic/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-genetics-of-magic/</guid>
      <description>Last spring, I took a class on Bayesian statistics at the University of Chicago that had several exercises focused on building a model to classify species based on their genome. The basic setup was that you were given a data set of salmon, their genome sequencing data, and which sub-population they belonged to. From this data, we needed to build a model to classify new salmon into the&amp;hellip;</description>
    </item>
    
    <item>
      <title>Testing machine learning models with testthat</title>
      <link>/post/testing-machine-learning-model/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/testing-machine-learning-model/</guid>
      <description>Automated testing is a huge part of software development. Once a project reaches a certain level of complexity, the only way that it can be maintained is if it has a set of tests that identify the main functionality and allow you to verify that functionality is&amp;hellip;</description>
    </item>
    
    <item>
      <title>Road Map for Choosing Between Statistical Modeling and Machine Learning</title>
      <link>/post/road-map-for-choosing-between-/</link>
      <pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/road-map-for-choosing-between-/</guid>
      <description>Data analysis methods may be described by their areas of applications, but for this article I&amp;rsquo;m using definitions that are strictly&amp;hellip;</description>
    </item>
    
    <item>
      <title>Yet Another Caret Workshop</title>
      <link>/post/yet-another-caret-workshop/</link>
      <pubDate>Thu, 19 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/yet-another-caret-workshop/</guid>
      <description>Intro Yesterday I gave a workshop on applied predictive modelling1 with caret at the 1st LSE Computational Social Science hackathon. Organiser privileges. I put together some introductory code and started a simple GitHub repo for the participants, so I thought I’d share it here as&amp;hellip;</description>
    </item>
    
    <item>
      <title>YMMV: non-profit data science</title>
      <link>/post/ymmv-nonprofit-data-science/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/ymmv-nonprofit-data-science/</guid>
      <description>Feeling inspired by some recent data science collaborations, on Friday I released the following tweet into the wild: Publicly it seemed to garner a good deal of positive attention, although I did also receive some valid criticism via&amp;hellip;</description>
    </item>
    
    <item>
      <title>NVIDIA and Deep Learning Research with Bryan Catanzaro</title>
      <link>/post/nvidia-and-deep-learning-resea/</link>
      <pubDate>Wed, 21 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/nvidia-and-deep-learning-resea/</guid>
      <description>Bryan Catanzaro is VP of Applied Deep Learning Research at NVIDIA, where he leads a team solving problems in domains ranging from video games to chip design using deep learning. Bryan earned his PhD from Berkeley, where he focused on parallel computing, machine learning, and programming&amp;hellip;</description>
    </item>
    
    <item>
      <title>Cloud AI with Dr. Fei-Fei Li</title>
      <link>/post/cloud-ai-with-dr-feifei-li/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/cloud-ai-with-dr-feifei-li/</guid>
      <description>Additional sample resources on Dr. Fei-Fei Li: Where can I learn more about machine learning? Listing of some of the many resources out there in no particular order: Sample of recent women in tech events to keep on radar for next&amp;hellip;</description>
    </item>
    
    <item>
      <title>Are you in genomics and building models? Stop using ROC - use PR</title>
      <link>/post/are-you-in-genomics-and-buildi/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/are-you-in-genomics-and-buildi/</guid>
      <description>Area Under the Curve (AUC) of Receiver Operating Characteristic (ROC) is a terrible metric for a genomics problem. Do not use it. This metric also goes by AUC or AUROC. Use Precision Recall AUC. First, you do have to use them because everyone uses them and expects them, but try to move them in the supplementary&amp;hellip;</description>
    </item>
    
    <item>
      <title>Let’s Plot 4</title>
      <link>/post/lets-plot-4/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/lets-plot-4/</guid>
      <description>The battle that we’ve all been waiting for. Excel vs. R. Bar plot versus a plot that actually shows the data. Yeah, this isn’t a fair fight. Bar plots are terrible. Why? Simple. They don’t show what your data looks like. A bar plot gives you zero idea how many data points there are. You can add error bars, but you don’t know if you are looking at standard error or standard&amp;hellip;</description>
    </item>
    
    <item>
      <title>Interpretable Machine Learning with iml and mlr</title>
      <link>/post/interpretable-machine-learning/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/interpretable-machine-learning/</guid>
      <description>Machine learning models repeatedly outperform interpretable, parametric models like the linear regression model. The gains in performance have a price: The models operate as black boxes which are not interpretable. Fortunately, there are many methods that can make machine learning models&amp;hellip;</description>
    </item>
    
    <item>
      <title>Training Courses for mlr</title>
      <link>/post/training-courses-for-mlr/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/training-courses-for-mlr/</guid>
      <description>The mlr: Machine Learning in R package provides a generic, object-oriented and extensible framework for classification, regression, survival analysis and clustering for the statistical programming language&amp;hellip;</description>
    </item>
    
    <item>
      <title>Supervised vs. Unsupervised Learning</title>
      <link>/post/supervised-vs-unsupervised-lea/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/supervised-vs-unsupervised-lea/</guid>
      <description>Outcome Supervision Yesterday I was part of an introductory session on machine learning and unsurprisingly, the issue of supervised vs. unsupervised learning came up. In social sciences, there is a definite tendency for the former; there is more or less always a target outcome or measure that we want to optimise the performance of our models&amp;hellip;</description>
    </item>
    
    <item>
      <title>Flagging toxic comments with Tidytext and Keras</title>
      <link>/post/flagging-toxic-comments-with-t/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/flagging-toxic-comments-with-t/</guid>
      <description>The task here is to try to determine how likely a string is to have a particular set of labels. We can take a look at the data The first step for looking at the actual text is to split up the strings into words and then remove stop words. Stop words like “the” and “a” are unlikely to provide much information about the toxicity of the comment, so we can take them&amp;hellip;</description>
    </item>
    
    <item>
      <title>Predicting Conflict Duration with (gg)plots using Keras</title>
      <link>/post/predicting-conflict-duration-w/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/predicting-conflict-duration-w/</guid>
      <description>An Unlikely Pairing Last week, Marc Cohen from Google Cloud was on campus to give a hands-on workshop on image classification using TensorFlow. Consequently, I spent most of my time thinking about how I can incorporate image classifiers in my work. As my research is primarily on forecasting armed conflict duration, it’s not really straightforward to make a connection between the&amp;hellip;</description>
    </item>
    
    <item>
      <title>Cloud AutoML Vision with Amy Unruh and Sara Robinson</title>
      <link>/post/cloud-automl-vision-with-amy-u/</link>
      <pubDate>Wed, 17 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/cloud-automl-vision-with-amy-u/</guid>
      <description>Cloud AutoML is a suite of products enabling developers with limited ML expertise to build high quality models using transfer learning and Neural Architecture Search techniques. AutoML Vision is the first product out the gate with a focus on making it easy to train customized vision&amp;hellip;</description>
    </item>
    
    <item>
      <title>Team Rtus wins Munich Re Datathon with mlr</title>
      <link>/post/team-rtus-wins-munich-re-datat/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/team-rtus-wins-munich-re-datat/</guid>
      <description>On the weekend of November 17. - 19. five brave data-knights from team “Rtus and the knights of the data.table” took on the challenge to compete in a datathon organized by Munich Re in its Munich-based innovation lab. Team Rtus was formed in April this year by a bunch of statistics students from LMU with the purpose to prove their data-skills in competitions with other teams from various&amp;hellip;</description>
    </item>
    
    <item>
      <title>Explainers</title>
      <link>/post/explainers/</link>
      <pubDate>Mon, 04 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/explainers/</guid>
      <description>When working on Machine Learning for classification and predictive models we tend to use the well known packages as randomforest, caret, xgboost, gbm and such. The issue is when the user needs explanation about how we get these results. The easy part is to explain a Tree. Pretty neat is you use the FFTrees package, that gives a cool output that needs a very short&amp;hellip;</description>
    </item>
    
    <item>
      <title>Automated and Unmysterious Machine Learning in Cancer Detection</title>
      <link>/post/automated-and-unmysterious-mac/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/automated-and-unmysterious-mac/</guid>
      <description>First, let&amp;rsquo;s load the data: .. and do some data cleaning: change column names, get rid of the order in factor levels and remove rows with empty cells: That&amp;rsquo;s better! Now, let&amp;rsquo;s set up the local H2O instance&amp;hellip; &amp;hellip; and split the data into training, validation and testing&amp;hellip;</description>
    </item>
    
    <item>
      <title>Sydney Region with Andrew Walker and Graham Polley</title>
      <link>/post/sydney-region-with-andrew-walk/</link>
      <pubDate>Wed, 11 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/sydney-region-with-andrew-walk/</guid>
      <description>Andrew is the founder of 3wks who have delivered 190 projects on Google Cloud platform for enterprise customers in Australia. He loves everything serverless, from App Engine through to BigQuery. Graham is a senior software engineer based out of Melbourne Australia, and works for Shine Solutions. Shine are a enterprise digital consultancy with offices in Melbourne &amp;amp;&amp;hellip;</description>
    </item>
    
    <item>
      <title>OpenML Workshop 2017</title>
      <link>/post/openml-workshop-2017/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/openml-workshop-2017/</guid>
      <description>What is OpenML? The field of Machine Learning has grown tremendously over the last years, and is a key component of data-driven science. Data analysis algorithms are being invented and used every day, but their results and experiments are published almost exclusively in journals or separated repositories. However, data by itself has no&amp;hellip;</description>
    </item>
    
    <item>
      <title>Advice for non-traditional data scientists</title>
      <link>/post/advice-for-nontraditional-data/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/advice-for-nontraditional-data/</guid>
      <description>I have a pretty strange background for a data scientist. In my career I’ve sold electric razors, worked on credit derivatives during the 2008 financial crash, written market reports on orthopaedic biomaterials, and practiced law. I started programming in R during law school, partly as a way to learn more about data visualization and partly to help analyze youth criminal justice&amp;hellip;</description>
    </item>
    
    <item>
      <title>Basecamp Networks with Craig Ganssle</title>
      <link>/post/basecamp-networks-with-craig-g/</link>
      <pubDate>Wed, 17 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/basecamp-networks-with-craig-g/</guid>
      <description>Craig Ganssle is the Founder and CEO of Basecamp Networks. With over 20 years in the technology industry, Craig has extensive experience developing and deploying wireless networks and designing predictive learning solutions for complex problem&amp;hellip;</description>
    </item>
    
    <item>
      <title>shinyMlr</title>
      <link>/post/shinymlr/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/shinymlr/</guid>
      <description>shinyMlr is a web application, built with the R-package “shiny” that provides a user interface for mlr. By wrapping the main functionalities of mlr into our app, as well as implementing additional features for data visualisation and data preprocessing, we built a widely usable application for your day to day machine learning tasks, which we would like to present to you&amp;hellip;</description>
    </item>
    
    <item>
      <title>Cloud Functions with Bret McGowen</title>
      <link>/post/cloud-functions-with-bret-mcgo/</link>
      <pubDate>Wed, 19 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/cloud-functions-with-bret-mcgo/</guid>
      <description>Bret is on the Google Cloud Platform team at Google, focusing on developer-oriented products like Google Cloud Functions, App Engine, Firebase, machine learning APIs, and more. He&amp;rsquo;s currently an aspiring Node.js developer. Prior to Google, Bret worked in the cloud industry at Rackspace as a software engineer building the RackConnect hybrid hosting&amp;hellip;</description>
    </item>
    
    <item>
      <title>Cloud Machine Learning Engine with Yufeng Guo</title>
      <link>/post/cloud-machine-learning-engine-/</link>
      <pubDate>Wed, 05 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/cloud-machine-learning-engine-/</guid>
      <description>Cloud Machine Learning Engine offers a managed platform for training and serving Tensorflow models. Kubernetes 1.6: Recapping Google Next &amp;lsquo;17 by Kalev Leetaru: What are API keys and when should I use&amp;hellip;</description>
    </item>
    
    <item>
      <title>Most Popular Learners in mlr</title>
      <link>/post/most-popular-learners-in-mlr/</link>
      <pubDate>Thu, 30 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/most-popular-learners-in-mlr/</guid>
      <description>For the development of mlr as well as for an “machine learning expert” it can be handy to know what are the most popular learners used. Not necessarily to see, what are the top notch performing methods but to see what is used “out there” in the real world. Thanks to the nice little package cranlogs from metacran you can at least get a slight estimate as I will show in the&amp;hellip;</description>
    </item>
    
    <item>
      <title>Parallel benchmarking with OpenML and mlr</title>
      <link>/post/parallel-benchmarking-with-ope/</link>
      <pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/parallel-benchmarking-with-ope/</guid>
      <description>With this post I want to show you how to benchmark several learners (or learners with different parameter settings) using several data sets in a structured and parallelized fashion. For this we want to use batchtools. The data that we will use here is stored on the open machine learning platform openml.org and we can download it together with information on what to do with it in form of a&amp;hellip;</description>
    </item>
    
    <item>
      <title>OpenML tutorial at useR!2017 Brussels</title>
      <link>/post/openml-tutorial-at-user2017-br/</link>
      <pubDate>Thu, 02 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/openml-tutorial-at-user2017-br/</guid>
      <description>What is OpenML? Conducting research openly and reproducibly is becoming the gold standard in academic research. Practicing open and reproducible research, however, is hard. OpenML.org (Open Machine Learning) is an online platform that aims at making the part of research involving data and analyses&amp;hellip;</description>
    </item>
    
    <item>
      <title>mlr Google Summer of Code 2017</title>
      <link>/post/mlr-google-summer-of-code-2017/</link>
      <pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/mlr-google-summer-of-code-2017/</guid>
      <description>We are happy to announce that we applied for a another Google Summer of Code project in 2017. Operator Based Machine Learning Pipeline Construction We aim to change the way we are currently doing data preprocessing in mlr. Have a look at the proposal linked above for more details. If you are interested in doing this project, have a look at the tests and&amp;hellip;</description>
    </item>
    
    <item>
      <title>SRE II with Paul Newson</title>
      <link>/post/sre-ii-with-paul-newson/</link>
      <pubDate>Wed, 01 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/sre-ii-with-paul-newson/</guid>
      <description>Before joining Google, he cofounded a tiny game technology startup, sold it to Microsoft, where he then worked on DirectX, Xbox, Xbox Live, and Forza Motorsport, before spending some time working on interesting machine learning problems in Microsoft Research. Outside of work he enjoys rock climbing, motorcycling, and other activities that demand complete&amp;hellip;</description>
    </item>
    
    <item>
      <title>A Year in Review</title>
      <link>/post/a-year-in-review/</link>
      <pubDate>Wed, 14 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/a-year-in-review/</guid>
      <description>Spotify is now on Google Cloud Platform: Kubernetes and Google Container Engine Education: Multiple General Availabilities Machine Learning and Big Data Google Cloud Platform Community Slack We&amp;rsquo;ll be back on January 18th, 2017 - See you all&amp;hellip;</description>
    </item>
    
    <item>
      <title>Paper published</title>
      <link>/post/paper-published/</link>
      <pubDate>Thu, 20 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/paper-published/</guid>
      <description>We are happy to announce that we can finally answer the question on how to cite mlr properly in publications. Our paper on mlr has been published in the open-access Journal of Machine Learning Research (JMLR) and can be downloaded on the journal home page. The paper gives a brief overview of the features of mlr and also includes a comparison with similar&amp;hellip;</description>
    </item>
    
    <item>
      <title>mlr loves OpenML</title>
      <link>/post/mlr-loves-openml/</link>
      <pubDate>Fri, 09 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/mlr-loves-openml/</guid>
      <description>OpenML stands for Open Machine Learning and is an online platform, which aims at supporting collaborative machine learning online. It is an Open Science project that allows its users to share data, code and machine learning experiments. At the time of writing this blog I am in Eindoven at an OpenML workshop, where developers and scientists meet to work on improving the&amp;hellip;</description>
    </item>
    
    <item>
      <title>Descartes Labs with Tim Kelton</title>
      <link>/post/descartes-labs-with-tim-kelton/</link>
      <pubDate>Wed, 31 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/descartes-labs-with-tim-kelton/</guid>
      <description>Tim is a co-founder of Descartes Labs focuses on building distributed systems using cloud architecture to better see how the earth changes every day. Prior to Descartes Labs, Tim was a Research and Development engineer for 15 years at Los Alamos National Laboratory working on problem areas such as deep learning, space systems, nuclear non-proliferation, and&amp;hellip;</description>
    </item>
    
    <item>
      <title>How to win a drone in 20 lines of R code</title>
      <link>/post/how-to-win-a-drone-in-20-lines/</link>
      <pubDate>Tue, 23 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-win-a-drone-in-20-lines/</guid>
      <description>Or a less clickbaity title: Model based optimization of machine learning models with mlr and mlrMBO. I recently participated in the #TEFDataChallenge a datathon organized by Wayra. The first price was a drone for every team member, which is a pretty awesome&amp;hellip;</description>
    </item>
    
    <item>
      <title>Exploring and Understanding Hyperparameter Tuning</title>
      <link>/post/exploring-and-understanding-hy/</link>
      <pubDate>Sun, 21 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/exploring-and-understanding-hy/</guid>
      <description>Learners use hyperparameters to achieve better performance on particular datasets. When we use a machine learning package to choose the best hyperparmeters, the relationship between changing the hyperparameter and performance might not be&amp;hellip;</description>
    </item>
    
    <item>
      <title>Site Reliability Engineering with Paul Newson</title>
      <link>/post/site-reliability-engineering-w/</link>
      <pubDate>Wed, 10 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/site-reliability-engineering-w/</guid>
      <description>Before joining Google, Paul founded a startup which was acquired by Microsoft, where he worked on DirectX, Xbox, Xbox Live, and Forza Motorsport, before spending time working on machine learning problems at Microsoft&amp;hellip;</description>
    </item>
    
    <item>
      <title>TensorFlow with Eli Bixby</title>
      <link>/post/tensorflow-with-eli-bixby/</link>
      <pubDate>Wed, 22 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/tensorflow-with-eli-bixby/</guid>
      <description>Eli is a Developer Programs Engineer at Google. He joined in 2014 and currently develops on Google Cloud Platform&amp;rsquo;s machine learning and big data offerings, Tensorflow in particular. Eli is an all-purpose nerd, having dabbled in several research areas, including biophysics, algorithmic game theory, and computational biology, before a recent dive into machine&amp;hellip;</description>
    </item>
    
    <item>
      <title>Storage with Paul Newson</title>
      <link>/post/storage-with-paul-newson/</link>
      <pubDate>Wed, 24 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/storage-with-paul-newson/</guid>
      <description>Paul currently focuses on helping developers harness the power of Google Cloud Platform to solve their big data problems. Previously, he was an engineer on Google Cloud Storage. Before joining Google, Paul founded a startup which was acquired by Microsoft, where he worked on DirectX, Xbox, Xbox Live, and Forza Motorsport, before spending time working on machine learning problems at Microsoft&amp;hellip;</description>
    </item>
    
    <item>
      <title>Cloud Vision API with Ram Ramanathan</title>
      <link>/post/cloud-vision-api-with-ram-rama/</link>
      <pubDate>Wed, 20 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/cloud-vision-api-with-ram-rama/</guid>
      <description>Ram Ramanathan joined Google in 2014 where he’s been working on leading the machine learning efforts for Google Cloud Platform, and has been a large part of launching the new Google Cloud Vision API. He comes with a great deal of experience in the industry after working for other big players such as GE Healthcare and&amp;hellip;</description>
    </item>
    
  </channel>
</rss>