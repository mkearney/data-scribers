<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mlrblognetlifycom on {data-scribers}</title>
    <link>https://data-scribers.mikewk.com/tags/mlrblognetlifycom/</link>
    <description>Recent content in Mlrblognetlifycom on {data-scribers}</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Jul 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://data-scribers.mikewk.com/tags/mlrblognetlifycom/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Visualization of spatial cross-validation partitioning</title>
      <link>https://data-scribers.mikewk.com/post/visualization-of-spatial-cross/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/visualization-of-spatial-cross/</guid>
      <description>Introduction In July mlr got a new feature that extended the support for spatial data: The ability to visualize spatial partitions in cross-validation (CV) 9d4f3&amp;hellip;</description>
    </item>
    
    <item>
      <title>Why R Conference</title>
      <link>https://data-scribers.mikewk.com/post/why-r-conference/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/why-r-conference/</guid>
      <description>This July we had the great honor to present mlr and its ecosystem at the WhyR 2018 Conference in Wroclaw in Poland&amp;hellip;</description>
    </item>
    
    <item>
      <title>Interpretable Machine Learning with iml and mlr</title>
      <link>https://data-scribers.mikewk.com/post/interpretable-machine-learning/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/interpretable-machine-learning/</guid>
      <description>Machine learning models repeatedly outperform interpretable, parametric models like the linear regression model. The gains in performance have a price: The models operate as black boxes which are not interpretable&amp;hellip;</description>
    </item>
    
    <item>
      <title>Training Courses for mlr</title>
      <link>https://data-scribers.mikewk.com/post/training-courses-for-mlr/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/training-courses-for-mlr/</guid>
      <description>The mlr: Machine Learning in R package provides a generic, object-oriented and extensible framework for classification, regression, survival analysis and clustering for the statistical programming language&amp;hellip;</description>
    </item>
    
    <item>
      <title>Stepwise Bayesian Optimization with mlrMBO</title>
      <link>https://data-scribers.mikewk.com/post/stepwise-bayesian-optimization/</link>
      <pubDate>Wed, 10 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/stepwise-bayesian-optimization/</guid>
      <description>With the release of the new version of mlrMBO we added some minor fixes and added a practical feature called Human-in-the-loop MBO. It enables you to sequentially visualize the state of the surrogate model, obtain the suggested parameter configuration for the next iteration and update the surrogate model with arbitrary evaluations&amp;hellip;</description>
    </item>
    
    <item>
      <title>Team Rtus wins Munich Re Datathon with mlr</title>
      <link>https://data-scribers.mikewk.com/post/team-rtus-wins-munich-re-datat/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/team-rtus-wins-munich-re-datat/</guid>
      <description>On the weekend of November 17. - 19. five brave data-knights from team “Rtus and the knights of the data.table” took on the challenge to compete in a datathon organized by Munich Re in its Munich-based innovation lab&amp;hellip;</description>
    </item>
    
    <item>
      <title>OpenML Workshop 2017</title>
      <link>https://data-scribers.mikewk.com/post/openml-workshop-2017/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/openml-workshop-2017/</guid>
      <description>What is OpenML? The field of Machine Learning has grown tremendously over the last years, and is a key component of data-driven science. Data analysis algorithms are being invented and used every day, but their results and experiments are published almost exclusively in journals or separated repositories&amp;hellip;</description>
    </item>
    
    <item>
      <title>Parameter tuning with mlrHyperopt</title>
      <link>https://data-scribers.mikewk.com/post/parameter-tuning-with-mlrhyper/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/parameter-tuning-with-mlrhyper/</guid>
      <description>Hyperparameter tuning with mlr is rich in options as they are multiple tuning methods: Simple Random Search Grid Search Iterated F-Racing (via irace) Sequential Model-Based Optimization (via mlrMBO) Also the search space is easily definable and customizable for each of the 60+ learners of mlr using the ParamSets from the ParamHelpers&amp;hellip;</description>
    </item>
    
    <item>
      <title>shinyMlr</title>
      <link>https://data-scribers.mikewk.com/post/shinymlr/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/shinymlr/</guid>
      <description>shinyMlr is a web application, built with the R-package “shiny” that provides a user interface for mlr&amp;hellip;</description>
    </item>
    
    <item>
      <title>Most Popular Learners in mlr</title>
      <link>https://data-scribers.mikewk.com/post/most-popular-learners-in-mlr/</link>
      <pubDate>Thu, 30 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/most-popular-learners-in-mlr/</guid>
      <description>For the development of mlr as well as for an “machine learning expert” it can be handy to know what are the most popular learners used. Not necessarily to see, what are the top notch performing methods but to see what is used “out there” in the real world&amp;hellip;</description>
    </item>
    
    <item>
      <title>Multilabel Classification with mlr</title>
      <link>https://data-scribers.mikewk.com/post/multilabel-classification-with/</link>
      <pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/multilabel-classification-with/</guid>
      <description>Multilabel classification has lately gained growing interest in the research community. We implemented several methods, which make use of the standardized mlr framework&amp;hellip;</description>
    </item>
    
    <item>
      <title>New mlr Logo</title>
      <link>https://data-scribers.mikewk.com/post/new-mlr-logo/</link>
      <pubDate>Fri, 24 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/new-mlr-logo/</guid>
      <description>We at mlr are currently deciding on a new logo, and in the spirit of open-source, we would like to involve the community in the voting process! You can vote for your favorite logo on GitHub by reacting to the logo with a +1&amp;hellip;</description>
    </item>
    
    <item>
      <title>Parallel benchmarking with OpenML and mlr</title>
      <link>https://data-scribers.mikewk.com/post/parallel-benchmarking-with-ope/</link>
      <pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/parallel-benchmarking-with-ope/</guid>
      <description>With this post I want to show you how to benchmark several learners (or learners with different parameter settings) using several data sets in a structured and parallelized fashion. For this we want to use batchtools. The data that we will use here is stored on the open machine learning platform openml&amp;hellip;</description>
    </item>
    
    <item>
      <title>Use mlrMBO to optimize via command line</title>
      <link>https://data-scribers.mikewk.com/post/use-mlrmbo-to-optimize-via-com/</link>
      <pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/use-mlrmbo-to-optimize-via-com/</guid>
      <description>Many people who want to apply Bayesian optimization want to use it to optimize an algorithm that is not implemented in R but runs on the command line as a shell script or an executable. We recently published mlrMBO on CRAN&amp;hellip;</description>
    </item>
    
    <item>
      <title>First release of mlrMBO - the toolbox for (Bayesian) Black-Box Optimization</title>
      <link>https://data-scribers.mikewk.com/post/first-release-of-mlrmbo-the-to/</link>
      <pubDate>Mon, 13 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/first-release-of-mlrmbo-the-to/</guid>
      <description>We are happy to finally announce the first release of mlrMBO on cran after a quite long development time. For the theoretical background and a nearly complete overview of mlrMBOs capabilities you can check our paper on mlrMBO that we presubmitted to arxiv. The key features of mlrMBO are: Global optimization of expensive Black-Box functions&amp;hellip;</description>
    </item>
    
    <item>
      <title>Being successful on Kaggle using mlr</title>
      <link>https://data-scribers.mikewk.com/post/being-successful-on-kaggle-usi/</link>
      <pubDate>Thu, 09 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/being-successful-on-kaggle-usi/</guid>
      <description>Achieving a good score on a Kaggle competition is typically quite difficult. This blog post outlines 7 tips for beginners to improve their ranking on the Kaggle leaderboards&amp;hellip;</description>
    </item>
    
    <item>
      <title>OpenML tutorial at useR!2017 Brussels</title>
      <link>https://data-scribers.mikewk.com/post/openml-tutorial-at-user2017-br/</link>
      <pubDate>Thu, 02 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/openml-tutorial-at-user2017-br/</guid>
      <description>What is OpenML? Conducting research openly and reproducibly is becoming the gold standard in academic research. Practicing open and reproducible research, however, is hard. OpenML&amp;hellip;</description>
    </item>
    
    <item>
      <title>mlr 2.10</title>
      <link>https://data-scribers.mikewk.com/post/mlr-210/</link>
      <pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/mlr-210/</guid>
      <description>mlr 2.10 is now on CRAN&amp;hellip;</description>
    </item>
    
    <item>
      <title>mlr Google Summer of Code 2017</title>
      <link>https://data-scribers.mikewk.com/post/mlr-google-summer-of-code-2017/</link>
      <pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/mlr-google-summer-of-code-2017/</guid>
      <description>We are happy to announce that we applied for a another Google Summer of Code project in 2017. Operator Based Machine Learning Pipeline Construction We aim to change the way we are currently doing data preprocessing in mlr. Have a look at the proposal linked above for more details&amp;hellip;</description>
    </item>
    
    <item>
      <title>mlr Workshop 2017</title>
      <link>https://data-scribers.mikewk.com/post/mlr-workshop-2017/</link>
      <pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/mlr-workshop-2017/</guid>
      <description>When and Where? In 2017, we are hosting the workshop at LMU Munich. The workshop will run from 6 March to 10 March 2017 (potentially including the sunday before and the saturday at the end), hosted by the Ludwig-Maximilians-University Munich. Important Dates: Address: Geschwister-Scholl-Platz 1, Room: M203&amp;hellip;</description>
    </item>
    
    <item>
      <title>Paper published</title>
      <link>https://data-scribers.mikewk.com/post/paper-published/</link>
      <pubDate>Thu, 20 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/paper-published/</guid>
      <description>We are happy to announce that we can finally answer the question on how to cite mlr properly in publications. Our paper on mlr has been published in the open-access Journal of Machine Learning Research (JMLR) and can be downloaded on the journal home page&amp;hellip;</description>
    </item>
    
    <item>
      <title>mlr loves OpenML</title>
      <link>https://data-scribers.mikewk.com/post/mlr-loves-openml/</link>
      <pubDate>Fri, 09 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/mlr-loves-openml/</guid>
      <description>OpenML stands for Open Machine Learning and is an online platform, which aims at supporting collaborative machine learning online. It is an Open Science project that allows its users to share data, code and machine learning experiments&amp;hellip;</description>
    </item>
    
    <item>
      <title>How to win a drone in 20 lines of R code</title>
      <link>https://data-scribers.mikewk.com/post/how-to-win-a-drone-in-20-lines/</link>
      <pubDate>Tue, 23 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/how-to-win-a-drone-in-20-lines/</guid>
      <description>Or a less clickbaity title: Model based optimization of machine learning models with mlr and mlrMBO. I recently participated in the #TEFDataChallenge a datathon organized by Wayra&amp;hellip;</description>
    </item>
    
    <item>
      <title>Exploring and Understanding Hyperparameter Tuning</title>
      <link>https://data-scribers.mikewk.com/post/exploring-and-understanding-hy/</link>
      <pubDate>Sun, 21 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/exploring-and-understanding-hy/</guid>
      <description>Learners use hyperparameters to achieve better performance on particular datasets&amp;hellip;</description>
    </item>
    
    <item>
      <title>Result of the mlr summer workshop in Palermo</title>
      <link>https://data-scribers.mikewk.com/post/result-of-the-mlr-summer-works/</link>
      <pubDate>Mon, 15 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/result-of-the-mlr-summer-works/</guid>
      <description>The mlr developer team is quite international: Germany, USA, Canada. The time difference between these countries sometimes makes it hard to communicate and develop new features&amp;hellip;</description>
    </item>
    
    <item>
      <title>Benchmarking mlr (default) learners on OpenML</title>
      <link>https://data-scribers.mikewk.com/post/benchmarking-mlr-default-learn/</link>
      <pubDate>Thu, 11 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/benchmarking-mlr-default-learn/</guid>
      <description>There are already some benchmarking studies about different classification algorithms out there. The probably most well known and most extensive one is the Do we Need Hundreds of Classifers to Solve Real World Classication Problems? paper&amp;hellip;</description>
    </item>
    
    <item>
      <title>Exploring Learner Predictions with Partial Dependence and Functional ANOVA</title>
      <link>https://data-scribers.mikewk.com/post/exploring-learner-predictions-/</link>
      <pubDate>Thu, 11 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/exploring-learner-predictions-/</guid>
      <description>Learners use features to make predictions but how those features are used is often not apparent. mlr can estimate the dependence of a learned function on a subset of the feature space using generatePartialDependenceData&amp;hellip;</description>
    </item>
    
    <item>
      <title>Visualization of predictions</title>
      <link>https://data-scribers.mikewk.com/post/visualization-of-predictions/</link>
      <pubDate>Tue, 28 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>https://data-scribers.mikewk.com/post/visualization-of-predictions/</guid>
      <description>In this post I want to shortly introduce you to the great visualization possibilities of mlr. Within the last months a lot of work has been put into that field&amp;hellip;</description>
    </item>
    
  </channel>
</rss>