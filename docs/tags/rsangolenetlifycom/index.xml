<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rsangolenetlifycom on rscribers</title>
    <link>/tags/rsangolenetlifycom/</link>
    <description>Recent content in Rsangolenetlifycom on rscribers</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/rsangolenetlifycom/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Performance Benchmarking for Date-Time conversions</title>
      <link>/post/performance-benchmarking-for-d/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/performance-benchmarking-for-d/</guid>
      <description>Motivation Performance comparison Packages compared Results Motivation Once more, there’s was an opportunity at work to optimize code and reduce run-time. The last time was for dummy-variable creation. Upon querying large data from our hive tables, the returned dataframe contains values of class character. Thus, everything has to be first type converted before any processing can be done. The most time consuming of these has been character to date-time conversion for which I traditionally used&amp;hellip;</description>
    </item>
    
    <item>
      <title>Yet Another Titanic Solve</title>
      <link>/post/yet-another-titanic-solve/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/yet-another-titanic-solve/</guid>
      <description>Objectives Read in the dataset Train-Test Split Missing values analysis EDA Target Variable Predictor Variables Univariate &amp;amp; Bivariate Multivariate Analyses Data Preparation Missing Values Imputation Derived Variables Final Data Review Modeling Extreme Gradient Boosting Elastinet k-NN SVM C5.0 Averaged Neural Networks Conditional Inference Random Forests Compare models Test Set Evaluation Create test set Predict test results Kaggle Performance tl;dr: Another titanic&amp;hellip;</description>
    </item>
    
    <item>
      <title>Books I Reference</title>
      <link>/post/books-i-reference/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/books-i-reference/</guid>
      <description>The full list of the books in my shelf is on my Goodreads account 1. The ones I refer to the most are listed here: Deep Learning Deep Learning with R Francois Chollet Handbook Of Neural Computing Applications Alianna J Maren Deep Learning Ian Goodfellow LSTM with Python Jason Brownlee GLM Generalized Additive Models: An Introduction with R, Second Edition Simon Wood Applied Regression Modeling Iain Pardoe Generalized Linear Models John&amp;hellip;</description>
    </item>
    
    <item>
      <title>First foray into Shiny</title>
      <link>/post/first-foray-into-shiny/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/first-foray-into-shiny/</guid>
      <description>Visualising Distributions Visualising Linear Discriminant Analysis Shiny had interested me for a while for it’s power to quickly communicate and vizualise data and models. I hadn’t delved into it due to lack of time to do so, until now. Two quick visualizations I’ve created as my 1st foray into R Shiny. Nothing earth shattering, but was helpful to learn the tool. Visualising Distributions Hosted on shinyapps for free, at link Github code&amp;hellip;</description>
    </item>
    
    <item>
      <title>Performance Benchmarking for Dummy Variable Creation</title>
      <link>/post/performance-benchmarking-for-d/</link>
      <pubDate>Wed, 27 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/performance-benchmarking-for-d/</guid>
      <description>Motivation Why do we need dummy variables? Ways to create dummy variables in R stats package dummies package dummy package caret package Performance comparison Smaller datasets Large datasets Conclusion Qs Motivation Very recently, at work, we got into a discussion about creation of dummy variables in R code. We were dealing with a fairly large dataset of roughly 500,000 observations for roughly 120 predictor&amp;hellip;</description>
    </item>
    
    <item>
      <title>Pur(r)ify Your Carets</title>
      <link>/post/purrify-your-carets/</link>
      <pubDate>Sun, 17 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/purrify-your-carets/</guid>
      <description>The motivation An example using BostonHousing data Load libs &amp;amp; data Create a starter dataframe Select the models Create data-model combinations Solve the models Extract results In conclusion tl;dr: You’ll learn how to use purrr, caret and list-cols to quickly create hundreds of dataset + model combinations, store data &amp;amp; model objects neatly in one tibble, and post process programatically. These tools enable succinct functional programming in which a lot gets done with just a few lines of&amp;hellip;</description>
    </item>
    
    <item>
      <title>Finite Mixture Modeling using Flexmix</title>
      <link>/post/finite-mixture-modeling-using-/</link>
      <pubDate>Wed, 01 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/finite-mixture-modeling-using-/</guid>
      <description>Model Based Clustering Quick EDA Model building Mixtures of Regressions Quick EDA Model Building Results Further investigation Notes References This page replicates the codes written by Grun &amp;amp; Leish (2007) in ‘FlexMix: An R package for finite mixture modelling’, University of Wollongong, Australia. My intent here was to learn the flexmix package by replicating the results by the authors. Model Based Clustering The model based clustering on the whiskey&amp;hellip;</description>
    </item>
    
  </channel>
</rss>