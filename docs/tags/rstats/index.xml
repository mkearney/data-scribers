<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rstats on DATA SCrIbers</title>
    <link>/tags/rstats/</link>
    <description>Recent content in Rstats on DATA SCrIbers</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Sep 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/rstats/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Scoping Rules and NSE</title>
      <link>/post/scoping-rules-and-nse/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/scoping-rules-and-nse/</guid>
      <description>Earlier this week, I wrote some tweets about how you have to be careful about scopes when you do non-standard evaluation. I cover this in both Metaprogramming in R and Domain-Specific Languages in R, but this</description>
    </item>
    
    <item>
      <title>Parallel Computing in R</title>
      <link>/post/parallel-computing-in-r/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/parallel-computing-in-r/</guid>
      <description>We&amp;rsquo;re excited to host Jared Lander, Chief Data Scientist of Lander Analytics, the organizer of the New York Open Statistical Programming Meetup and the New York R Conference, and author of R for Everyone, to talk about parallel computing in</description>
    </item>
    
    <item>
      <title>where is here?</title>
      <link>/post/where-is-here/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/where-is-here/</guid>
      <description>As I add new projects to my rstats portfolio and work collaboratively on projects with students the issue of working directories is becoming more and more complicated. Not really understanding how working directories and file paths actually work, I have been relying on the beginner logic… Everything will be just fine as long as you keep your datafiles in the same folder as your .rmd file Here is how it works.</description>
    </item>
    
    <item>
      <title>Building Infrastructure with R</title>
      <link>/post/building-infrastructure-with-r/</link>
      <pubDate>Mon, 17 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/building-infrastructure-with-r/</guid>
      <description>For this event we will explore how to build tools and infrastructure with R. 6:15-6:30pm Introductions and Social 6:30- 6:45 pm NYT announcements (Data, Tech, HR) 6:45-6:55pm R-Ladies New York Announcements 6:55-7:25pm Object Oriented Programming in R 7:25-7:55pm Big Data in R with Small Prototypes: Scaling 8:00-8:15pm Networking. In this talk, Soumya will provide an introduction to using these programming techniques in workflows and project</description>
    </item>
    
    <item>
      <title>R4DS (v1 &amp; v2)</title>
      <link>/post/r4ds-v1-v2/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/r4ds-v1-v2/</guid>
      <description>As all amazing opportunities in my life are wont to do, it started with a tweet: It’s rare that I find myself dealing with imposter syndrome, but I did spend Thursday night eating all of my feelings of doubt and</description>
    </item>
    
    <item>
      <title>A personal essay on Bayes factors</title>
      <link>/post/a-personal-essay-on-bayes-fact/</link>
      <pubDate>Sat, 15 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/a-personal-essay-on-bayes-fact/</guid>
      <description>’Cause you’re hot then you’re cold You’re yes then you’re no You’re in then you’re out You’re up then you’re down You’re wrong when it’s right It’s black and it’s white - Katy Perry Or, in something closer to every day language: What’s not to love? Oh, you sweet summer child. I’m feelin’ electric tonight Cruisin’ down the coast, goin’ about 99 Got my bad baby by my heavenly side I know if I go, I’ll die happy tonight - Lana Del Rey It hasn’t yet, but I’m still hoping it</description>
    </item>
    
    <item>
      <title>How to Install R on CentOS 7</title>
      <link>/post/how-to-install-r-on-centos-7/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-install-r-on-centos-7/</guid>
      <description>R is a fast growing open source programming language and free environment that specializes in statistical computing and graphics representation. It is supported by the R Foundation for Statistical Computing and mainly used by statisticians and data miners for developing statistical software and performing data analysis. This tutorial will teach you how to install R on an CentOS 7 and how to install R packages from the official Comprehensive R Archive Network</description>
    </item>
    
    <item>
      <title>Slow ggplot</title>
      <link>/post/slow-ggplot/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/slow-ggplot/</guid>
      <description>This post has lots in common with previous posts on “the layered presentation of graphics”. It is about building up plots, but now with a focus on this incramental change for teaching ggplot2. The rational is that observing the cause and effect of incremental change is easier to digest, and that the repetition in this approach means students have more chances to learn the ggplot2 functions. My recent tweet presented the technique: People reacted</description>
    </item>
    
    <item>
      <title>Stress based graph layouts</title>
      <link>/post/stress-based-graph-layouts/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/stress-based-graph-layouts/</guid>
      <description>I academically grew up among graph drawers, that is, computer scientists and mathematicians interested in deriving two-dimensional depictions of graphs. One may despicably call it pixel science, yet a lot of hard theoretical work is put into producing pretty graph layouts. Although I am not at all an expert in this field, I have learned a thing or two about that subject. As such, I have always been surprised why one of the (potentially) best algorithms is not implemented in</description>
    </item>
    
    <item>
      <title>next up anova</title>
      <link>/post/next-up-anova/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/next-up-anova/</guid>
      <description>Next I need learn how to conduct ANOVA in R. the formula- specify which variable is your outcome and which are your grouping variables the data- which dataframe are you analysing In a clinical trial where you are looking to see if the drug improved mood scores you might specify&amp;hellip; As always,you can shortcut that by saying Or by specifying which variables to analyse using</description>
    </item>
    
    <item>
      <title>Generate animated tracking maps for hurricanes and typhoons</title>
      <link>/post/generate-animated-tracking-map/</link>
      <pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/generate-animated-tracking-map/</guid>
      <description>Further data cleaning is needed to reformat the datetime and rename a column. We can also save the animation into gif files, instead of embedding the animation. R and related packages are able to conveniently draw both static and animated maps for tracking hurricanes or typhoons. Further analysis, such as real-time tracking of hurricanes, will be conducted in the</description>
    </item>
    
    <item>
      <title>sabre</title>
      <link>/post/sabre/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/sabre/</guid>
      <description>Creating or determination of regions is a useful way to describe the world. Regionalization does not only allow for a quicker understanding of spatial patterns but also can influence how regions are managed. Regions are created in various disciplines. We can delineate regions based on a single property (e.g. landform regions or climate regions) or several factors (e.g. ecoregions). There are also political regions divided by borders that are established through political or social</description>
    </item>
    
    <item>
      <title>testing out t-tests</title>
      <link>/post/testing-out-ttests/</link>
      <pubDate>Sat, 08 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/testing-out-ttests/</guid>
      <description>Here is what I learned about t-tests from doing the analysis below. The AFL data that comes with Dani’s book includes attendance and score information for home and away teams over regular and finals games for years and years. Disclaimer- I know nothing about AFL. Maybe we know that the average AFL team scores around 100 points in a game. Do home teams score more than 100? Interesting, on average yes, the home team does score more than</description>
    </item>
    
    <item>
      <title>using R for analysis</title>
      <link>/post/using-r-for-analysis/</link>
      <pubDate>Sat, 08 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/using-r-for-analysis/</guid>
      <description>I am feeling more confident about my resolution to get rid of Excel and only use R for data wrangling and visualisation. Next steps&amp;hellip; analysis. I&amp;rsquo;m starting simple (I presume) with t-tests. Mostly commonly I want to determine whether there is a difference in the performance of independent groups of kids, or a difference between kids&amp;rsquo; performance on two different conditions, or whether kids are just guessing (i.e. whether their performance differs significantly</description>
    </item>
    
    <item>
      <title>I don’t like cats much</title>
      <link>/post/i-dont-like-cats-much/</link>
      <pubDate>Wed, 05 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/i-dont-like-cats-much/</guid>
      <description>Tom Kelly pointed me towards the @swcarpentry resources You can use dplyr::bind_rows() instead of reduce(rbind()). BUT if you want them all in one frame at the end you probably just want purrr::map_dfr(), which is a map and bind combo function. So many options! that&amp;rsquo;s actually half the problem with going #noloops. My most commonly used fns in purrr are map(), pmap(), walk(), iwalk() and every() maybe that helps narrow it down a bit.</description>
    </item>
    
    <item>
      <title>The Usage of ANSI C Escape Sequences in Various Programing Languages</title>
      <link>/post/the-usage-of-ansi-c-escape-seq/</link>
      <pubDate>Tue, 04 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-usage-of-ansi-c-escape-seq/</guid>
      <description>An escape sequence is a sequence of characters that does not represent itself when used inside a character or string literal, but is translated into another character or a sequence of characters that may be difficult or impossible to represent directly. Escape sequences are widely used in C and many other languages, such as R, (Postgre)SQL and</description>
    </item>
    
    <item>
      <title>lesser known stars of the tidyverse</title>
      <link>/post/lesser-known-stars-of-the-tidy/</link>
      <pubDate>Thu, 30 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/lesser-known-stars-of-the-tidy/</guid>
      <description>Tibble = modern dataframe. Use instead of printing your dataset to the console. summarise(numberNA = sum(is.na(variable)) map_df(~sum(is.na(.))) na_if(&amp;ldquo;&amp;rdquo;) When you want help, if it helpful to helpers if you create a minimal reproudicule example so that they can see and run the code using your data. www.r4ds.co.nz R for Data Science Twitter #rstats Rstats cheat sheets</description>
    </item>
    
    <item>
      <title>Readiness or Between-player normalisation</title>
      <link>/post/readiness-or-betweenplayer-nor/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/readiness-or-betweenplayer-nor/</guid>
      <description>We need to load the good library into R - we only need tidyverse to work around the database and openxlsx to load our .xls file where we store the data. I upload the data into R and visualize the format of my database. Now we can see how my database is done. It is a rectangular base with 1 column for position group, one for the drill category, one for the date, the Player name or Id and my GPS variables - I chose only the distance covered above the maximal aerobic velocity and mechanical</description>
    </item>
    
    <item>
      <title>Welcome</title>
      <link>/post/welcome/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/welcome/</guid>
      <description>I’m Mathieu Lacome, a sports scientist working in elite football with over 10 years of experience in team-sport. A part of my job is to think about how we can improve the way we are collecting data, what we can do with it and how to report findings to the coaching staff or players. We then store these data in databases that can be as simple as excel sheet to more complex and powerful databases such as</description>
    </item>
    
    <item>
      <title>dirty data</title>
      <link>/post/dirty-data/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/dirty-data/</guid>
      <description>I have been doing lots of data wrangling recently and decided a needed a quick rundown of data cleaning in R. Turns out www.DataCamp.com has a course called exactly that. Here are notes on useful things I learned. Histogram: to get an idea of the distribution of data in a particular variable use. Can use optional breaks argument to specify how many buckets the data are broken</description>
    </item>
    
    <item>
      <title>Exploring London Crime with R heat maps</title>
      <link>/post/exploring-london-crime-with-r-/</link>
      <pubDate>Sun, 26 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/exploring-london-crime-with-r-/</guid>
      <description>Here’s a sweet collection of packages required to run this analysis: First thing</description>
    </item>
    
    <item>
      <title>Writing an R package from scratch</title>
      <link>/post/writing-an-r-package-from-scra/</link>
      <pubDate>Sun, 26 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/writing-an-r-package-from-scra/</guid>
      <description>Anyone who has created their own R package has probably come across Hilary Parker’s awesome blogpost, that walks you through creating your very first R package. The comprehensive detail on everything R packages can be found in Hadley Wickham’s superb book. In this post I am going to walk through some of the developments in the package development space since Hilary wrote her blog four years ago, in particular focussing on the relatively recent usethis</description>
    </item>
    
    <item>
      <title>OsloBnB</title>
      <link>/post/oslobnb/</link>
      <pubDate>Sat, 25 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/oslobnb/</guid>
      <description>library(here) library(tidyverse) library(polite) library(rvest) library(mapview) library(sf) library(raster) library(fasterize) library(RPostgreSQL) library(rpostgis) library(mapsapi) library(patchwork) library(ggmap) library(ggrepel) library(plotly) library(lubridate) library(hrbrthemes) Challenge A friend of mine is coming over to Oslo in couple of weeks time and he asked me if I could recommend a good place for him to stay in</description>
    </item>
    
    <item>
      <title>Record linkage</title>
      <link>/post/record-linkage/</link>
      <pubDate>Sat, 25 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/record-linkage/</guid>
      <description>I recently encountered a problem that had a surprisingly elegant solution. I struggled a lot with solving this issue, so hopefully in writing this post I can save someone else the trouble! For reasons that are irrelevant, I wanted to track the performance of youth fencers across time. National ranking lists are posted each year, but the fencers’ names frequently change from year to</description>
    </item>
    
    <item>
      <title>Simple example of fitting splines with mixed models</title>
      <link>/post/simple-example-of-fitting-spli/</link>
      <pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/simple-example-of-fitting-spli/</guid>
      <description>I thought it might be value to provide some code showing how splines can be fit using mixed</description>
    </item>
    
    <item>
      <title>How to Install R on Ubuntu 18.04</title>
      <link>/post/how-to-install-r-on-ubuntu-180/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-install-r-on-ubuntu-180/</guid>
      <description>R is a fast growing open source programming language and free environment that specializes in statistical computing and graphics representation. It is supported by the R Foundation for Statistical Computing and mainly used by statisticians and data miners for developing statistical software and performing data analysis. This tutorial will guide you through the steps of installing R on an Ubuntu 18.04 machine. Prerequisites Before you get started with this tutorial, you&amp;rsquo;ll need an Ubuntu</description>
    </item>
    
    <item>
      <title>Reanimating the Datasaurus</title>
      <link>/post/reanimating-the-datasaurus/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/reanimating-the-datasaurus/</guid>
      <description>Whilst browsing twitter last night I came upon this tweet by the currrent author of gganimate: I&amp;rsquo;ve started a gganimate wiki page in order to collect examples. If you want to showcase your animations and help others learn in the process, consider submitting an issue as described on the main page #rstats https://t.co/VrT5IV2izr — Thomas Lin Pedersen (@thomasp85) August 16, 2018 Now I’ve been experimenting a lot with creating animations with R, and I absolutely love using</description>
    </item>
    
    <item>
      <title>Simple mapping with {sf}</title>
      <link>/post/simple-mapping-with-sf/</link>
      <pubDate>Thu, 16 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/simple-mapping-with-sf/</guid>
      <description>This post is based on a notebook I started about R spatial analysis for the project OSGeoLive It aims to provide a quick introduction to R spatial analysis and cartography and will be extended. R is a language dedicated to statistics and data analysis. It has also a lot of strong packages for spatial analysis. Recent packages like {sf} allows easy Simple Features manipulation. This document aims to complete the R Overview and R</description>
    </item>
    
    <item>
      <title>Visualizing Variance and Standard Deviation</title>
      <link>/post/visualizing-variance-and-stand/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/visualizing-variance-and-stand/</guid>
      <description>So this wasn’t on today’s to-do list, but there seems to be a cash prize associated with this rabbit hole due to this tweet: So here we go. I’m using the gapminder dataset which is ever-so-handy as it’s available in an R package (thanks Jenny Bryan). For the exercise I’ll just be looking at European countries in 2007, and focusing exclusively on the life expectancy variable. Let’s look at a plot of the data.</description>
    </item>
    
    <item>
      <title>Topic Modelling of Trustpilot Reviews with R and tidytext</title>
      <link>/post/topic-modelling-of-trustpilot-/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/topic-modelling-of-trustpilot-/</guid>
      <description>Improving the look of figures in ggplot2 is fairly simple. For consistency, we’ll create a clean and simple theme based on the APA theme from the jtools package and change some of the features. The background colour will be set to a light grey hue. The grid lines are omitted in the APA theme. Given that our reviews are in Danish, we can use the happyorsad package to compute a sentiment score for each review.</description>
    </item>
    
    <item>
      <title>Dot plot challenge</title>
      <link>/post/dot-plot-challenge/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/dot-plot-challenge/</guid>
      <description>Getting and reshaping the data The Dot Plot The August edition of the Storytelling with Data challenge #SWDchallenge stars the dot plot. Here is a simple plot of the gender gap in voting in national elections using the most recent 8th Round of the European Social Survey,</description>
    </item>
    
    <item>
      <title>National Anthems’ Sentiment Scores, Mapped and Interactive</title>
      <link>/post/national-anthems-sentiment-sco/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/national-anthems-sentiment-sco/</guid>
      <description>This post, as indicated in the title, is about an interactive mapping of sentiment scores calculated for national anthems. Text analysis is of growing interest for political researchers, and I count myself among the interested! The interactive plot at the end of the post is, I think, an ideal introduction sentiment analysis. It highlights opportunities, and also, perhaps, some pitfalls. I want to give quick background on how this happens to be in my blog, to give plenty of credit where it is</description>
    </item>
    
    <item>
      <title>Day 99-100: Small Steps</title>
      <link>/post/day-99100-small-steps/</link>
      <pubDate>Fri, 03 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/day-99100-small-steps/</guid>
      <description>Not surprisingly most of the posts (about 75% of them) were written in the first half of the project. That’s partly the inevitable consequence of the novelty wearing off, but it also there have been a few other things that have come up along the way… One big thing that interacted with this 100Days project in positive way is my teaching</description>
    </item>
    
    <item>
      <title>I (Heart Emoji) Statistics</title>
      <link>/post/i-heart-emoji-statistics/</link>
      <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/i-heart-emoji-statistics/</guid>
      <description>We learned so much from Hamdan Azhar&amp;rsquo;s awesome Prismoji tutorial after seeing his wonderful talk at the Southern Data Science Conference. In order to better aquaint ourselves with messy twitter data, we performed a simple search of the emojis associated with #womeninstem. There&amp;rsquo;s minimal statistics in this post, but it&amp;rsquo;s maximally adorable! # grab all the packages we&amp;rsquo;ll be using library(twitteR) #interface twitter web API library(data.table) #aggregate large data ## Warning: package</description>
    </item>
    
    <item>
      <title>Reading vintage magazines with `hocr`</title>
      <link>/post/reading-vintage-magazines-with/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/reading-vintage-magazines-with/</guid>
      <description>library(tidyverse) library(tesseract) library(pdftools) library(hocr) library(here) library(fs) library(hunspell) library(hrbrthemes) library(patchwork) Challenge This post is inspired by recent tweet by Paige Bailey about vintage computer magazines made available for free download on archive.org. A number of people picked up on the idea of checking out some of the old magazines from the time they can remeber starting with</description>
    </item>
    
    <item>
      <title>Text Mining</title>
      <link>/post/text-mining/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/text-mining/</guid>
      <description>As a part of the R4DS June Challenge and the “Summer of Data Science” Twitter initiative started by Data Science Renee, I decided to improve my text mining skills by working my way through Tidy Text Mining with R by Julia Silge and David Robinson. I wanted a fun dataset to use as I made my way through the book, so I decided to use every line from The</description>
    </item>
    
    <item>
      <title>Day 82-94</title>
      <link>/post/day-8294/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/day-8294/</guid>
      <description>So this is a post about how I set up one part of my workflow. I feel nervous about it for two reasons: Yes, I realise that I’m setting myself up to feel bad. I should stop</description>
    </item>
    
    <item>
      <title>An unmet need for data science training</title>
      <link>/post/an-unmet-need-for-data-science/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/an-unmet-need-for-data-science/</guid>
      <description>The aim is to try to define the problem(s) a bit better and also a bit of a cry for help. I appreciate that none of this may be novel, but I needed to get it written down and out of my head. Learning R and about the related data science issues through the community has completely changed the way I work. Secondly, I&amp;rsquo;ve currently got four related soapbox issues: The first and second issues are the subject of this post as they are so closely</description>
    </item>
    
    <item>
      <title>Visualization of spatial cross-validation partitioning</title>
      <link>/post/visualization-of-spatial-cross/</link>
      <pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/visualization-of-spatial-cross/</guid>
      <description>Introduction In July mlr got a new feature that extended the support for spatial data: The ability to visualize spatial partitions in cross-validation (CV) 9d4f3. When one uses the resampling descriptions “SpCV” or “SpRepCV” in mlr, the k-means clustering approach after Brenning (2005) is used to partition the dataset into equally sized, spatially disjoint subsets. See also this post on r-spatial.org and the mlr vignette about spatial data for more</description>
    </item>
    
    <item>
      <title>Late start</title>
      <link>/post/late-start/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/late-start/</guid>
      <description>This blog is going to be mostly about my adventures with R, primarily using survey data, and usually somewhat related to my social science interests; for the fun of it, to share code and hopefully get feedback. How it all started General law of academia: The capacity for generating ideas is greater than the capacity of developing ideas into papers. So why write a blog and not keep a diary or a plain text file sitting safely on your hard drive,</description>
    </item>
    
    <item>
      <title>Layered Presentation of Graphics, revised</title>
      <link>/post/layered-presentation-of-graphi/</link>
      <pubDate>Sun, 22 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/layered-presentation-of-graphi/</guid>
      <description>I think it is more straight forward than messing around with alpha. Several folks brought up geom_blank() having looked at the previous implementation, but I didn’t find it necessary in this case if you are using last_plot() which I think it makes sense to do in this context. Still, geom_blank is good to know about. This time around, I’ll do a little with labeling</description>
    </item>
    
    <item>
      <title>Finding Modes Using Kernel Density Estimates</title>
      <link>/post/finding-modes-using-kernel-den/</link>
      <pubDate>Thu, 19 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/finding-modes-using-kernel-den/</guid>
      <description>First, lets do this in R. Need some values to work with. Plot the density estimate with the mode location. Lets do something similar in Python. Start by generating a set of random values. Plot to show indeed we have it right. Note we sort the values first so the PDF looks</description>
    </item>
    
    <item>
      <title>Where should you declare aesthetics?  Globally, or geom-by-geom?</title>
      <link>/post/where-should-you-declare-aesth/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/where-should-you-declare-aesth/</guid>
      <description>Where should you declare aesthetics? Globally or in the geom_*() function? The answer to this question, in some sense is personal preference, because there are simply different ways to get the same job done in the ggplot architecture. My preference is declaring all aesthetic mappings as global unless there are conflicts. Below is an example that, I hope, will persuade you to my preference. We graph the increase in life expectancy by year for three</description>
    </item>
    
    <item>
      <title>Day 67-81</title>
      <link>/post/day-6781/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/day-6781/</guid>
      <description>The motivation to face the fear is similarly straightforward: my R code runs too slowly for some of the problems I care about. It doesn’t come up that often, to be honest. Most problems I work on are small enough that it really doesn’t matter that my R code is slow. Other problems are standard enough that I can rely on other people’s compiled code to do all the work (e.</description>
    </item>
    
    <item>
      <title>how should I get started with R?</title>
      <link>/post/how-should-i-get-started-with-/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-should-i-get-started-with-/</guid>
      <description>Here’s some evergreen advice from David Robinson: Many of the folks I talk to about learning R have little or no experience with “real” programming languages, which described myself when I first installed the language. If you’re in this camp, I have a few recommendations to get started. The second thing I’d suggest is starting a GitHub account, and to begin curating some of your</description>
    </item>
    
    <item>
      <title>Generate a reproducible map for county-level fertilizer estimation data in U.S.A. using R</title>
      <link>/post/generate-a-reproducible-map-fo/</link>
      <pubDate>Fri, 13 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/generate-a-reproducible-map-fo/</guid>
      <description>More than 70% of researchers have tried and failed to reproduce another scientist’s experiments, and more than half have failed to reproduce their own experiments. There are also some packages required to reproduce this post. If you have not installed them, please run the following codes. After installing all the libraries, we should include them in the R session to run the following codes. The map actually is a ggplot2 object and users can modified most of the components using ggplot2</description>
    </item>
    
    <item>
      <title>Interaction Plots with Continuous Moderators in R</title>
      <link>/post/interaction-plots-with-continu/</link>
      <pubDate>Wed, 11 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/interaction-plots-with-continu/</guid>
      <description>Long ago (the first half of my grad school life), I created a model for a manuscript I submitted. The paper was focused on adolescents’ appraisals of their relationships with their mothers, fathers, and best</description>
    </item>
    
    <item>
      <title>A note on ggplot code style</title>
      <link>/post/a-note-on-ggplot-code-style/</link>
      <pubDate>Fri, 06 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/a-note-on-ggplot-code-style/</guid>
      <description>I&amp;rsquo;ve got some opinions about how to write ggplot code. So, if there are more than two sections in a function, these should be separated on a newline. Ideally, all functions should have their argument names listed: Applying this same principle to ggplot2 code, we have the following, with the additional rule: But putting it onto one line, this is where I think it is not a good idea It is certainly great to be able to express the code so elegantly, but I&amp;rsquo;m just not that sold on the</description>
    </item>
    
    <item>
      <title>Linear Models</title>
      <link>/post/linear-models/</link>
      <pubDate>Fri, 06 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/linear-models/</guid>
      <description>Introduction library(tidyverse) library(matlib) library(knitr) library(RColorBrewer) The purpose of this document is to understand the parameter and residuals error estimates in a basic linear regression model when working with binary categorical variables. Recall the general model definition: [ \mathbf{y} = \mathbf{X}\mathbf{\beta} + \mathbf{e}] where (\mathbf{X}) is the design matrix and (\mathbf{\beta}) is a ((p+1))-vector of coefficients/parameters, including the intercept</description>
    </item>
    
    <item>
      <title>Day 63-66: Learning to skim</title>
      <link>/post/day-6366-learning-to-skim/</link>
      <pubDate>Sat, 30 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/day-6366-learning-to-skim/</guid>
      <description>But everything is “under control” now, at least for a very expansive definition of “control”. The kids are keeping themselves occupied, I’ve responded to some overdue emails, and I’m making inroads into the Saturday morning laundry mountain. So… about that long-overdue R post… The report is a pdf document that contains all the raw data as a table that runs from pages 6 to 10; there does not seem to be any other publicly accessible version of the</description>
    </item>
    
    <item>
      <title>Benjana Guraziu</title>
      <link>/post/benjana-guraziu/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/benjana-guraziu/</guid>
      <description>R is an awesome language, but I wouldn’t be this excited about it if I weren’t so excited about the people that are in this community. NYR was a great conference that really highlighted the strength of the R community. A telling example of this is the community&amp;rsquo;s constant drive to improve. As Brooke Watson commented, it was very exciting that there was now a line for the women&amp;rsquo;s bathroom! Indeed, gender diversity among speakers was better than many other technical conferences I’ve</description>
    </item>
    
    <item>
      <title>Day 55-62: R: The Boring Bits</title>
      <link>/post/day-5562-r-the-boring-bits/</link>
      <pubDate>Tue, 26 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/day-5562-r-the-boring-bits/</guid>
      <description>The “random walk on CRAN” project, however, has been on hold for a bit - and in truth today’s post is a bit of a cop out because there’s no package here at all and barely anything resembling code. Instead, it’s some initial thoughts about how to revisit some of my teaching material. For today though, I have a different goal… But still, it’s nice to think about what we might do if we have more</description>
    </item>
    
    <item>
      <title>Re-referencing factor levels to estimate standard errors when there is interaction turns out to be a really simple solution</title>
      <link>/post/rereferencing-factor-levels-to/</link>
      <pubDate>Tue, 26 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/rereferencing-factor-levels-to/</guid>
      <description>Maybe this should be filed under topics that are so obvious that it is not worth writing about. But, I hate to let a good simulation just sit on my computer. I was recently working on a paper investigating the relationship of emotion knowledge (EK) in very young kids with academic performance a year or two later. The idea is that kids who are more emotionally intelligent might be better prepared to</description>
    </item>
    
    <item>
      <title>Selection effects</title>
      <link>/post/selection-effects/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/selection-effects/</guid>
      <description>My limited goals: Perhaps the central difference between working in the Stata environment and in R is that in R you always have to be declaring which data frame you are working with. In Stata, you just have one active data frame and then you can refer to the variables by their names alone. The tidyverse tools with piping make working in R feel more like working in Stata in my</description>
    </item>
    
    <item>
      <title>Solution to a frustrating rJava problem</title>
      <link>/post/solution-to-a-frustrating-rjav/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/solution-to-a-frustrating-rjav/</guid>
      <description>Go to the command line and run: According to the solution at the aforementioned link, this will “create a link to libjvm.dylib inside R’s lib folder”. I can’t tell you much more, but it took me waaaay too long to find this so I hope this post makes it easier for the next person with this</description>
    </item>
    
    <item>
      <title>R-Ladies Sydney Launch!</title>
      <link>/post/rladies-sydney-launch/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/rladies-sydney-launch/</guid>
      <description>I thought I would spend all my PhD reading textbooks and learning new R techiniques (see below). However research, admin, and teaching can get in the way! I learned how to develop packages to complement my research and to also improve workflow Learn from examples! Eg, this presentation was based off Alison Hill’s R Ladies talk about blogdown! Work smart, not hard. Having a mentor is extremely</description>
    </item>
    
    <item>
      <title>Naming Things</title>
      <link>/post/naming-things/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/naming-things/</guid>
      <description>The oldSchool namer generally mixes case in an R package, often capitalising the &amp;ldquo;R&amp;rdquo;, or going all in on ALL CAPS. Examples: Although personally I wouldn&amp;rsquo;t use this style as it can make it difficult to type, they have a certain charm, and are easy to google - provided you spell it right. And these are still seriously useful - Matrix provides extensive support for modelling, UpSetR produces great plots as an alternative to venn diagrams.</description>
    </item>
    
    <item>
      <title>Looking into #KeepFamiliesTogether</title>
      <link>/post/looking-into-keepfamiliestoget/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/looking-into-keepfamiliestoget/</guid>
      <description>This week I&amp;rsquo;m at the Seattle branch of the Summer Institute on Computational Social Science. Today, we discussed digital trace data and spent some time thinking about different sources of digital trace data. One of the easiest sources is twitter, and thanks to Mike Kearney, it&amp;rsquo;s easily accessible in R via the {rtweet} package! I joined a group addressing a topic I find myself dwelling on throughout the day - the immigration crisis at the</description>
    </item>
    
    <item>
      <title>The visual taming of a paradox</title>
      <link>/post/the-visual-taming-of-a-paradox/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-visual-taming-of-a-paradox/</guid>
      <description>@drob has posted code to play with on Twitter today. To illustrate what he calls a veridical paradox he’s posted the set up, the code and result of a coin flipping experiment: There are some good and exact explanations in the thread, for this at-first-glance puzzle. But I didn’t see a visualization that might give you quick intuition about what is going on. So I prepare one here. We’ll use the tidyverse packages and stringr.</description>
    </item>
    
    <item>
      <title>Behind the Viz</title>
      <link>/post/behind-the-viz/</link>
      <pubDate>Sat, 16 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/behind-the-viz/</guid>
      <description>Lots of packages here: The gather() function pivots the data, we name “episodes” as the key (what the column names will be called) and rankings as the values (what the data in those columns will now be called), while telling the function to not mess with the columns user, other, or id. Now that we have long data, we’ll calculate what percentage of 1st place votes each episode recieved, and then plot that in a</description>
    </item>
    
    <item>
      <title>Re-introduction to gghighlight</title>
      <link>/post/reintroduction-to-gghighlight/</link>
      <pubDate>Sat, 16 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/reintroduction-to-gghighlight/</guid>
      <description>But, please forget about that gghighlight; gghighlight has become far more powerful and simple! So, let me re-introduce about gghighlight. What do you do when you explore a data that is too large to print? OK, good. But, what about ggplot2? For a data that has too many series, it is almost impossible to identify a series by its colour as their differences are so subtle. In my understanding, one of the main purposes of visualization is to get the overview of a</description>
    </item>
    
    <item>
      <title>Covariance -- A Visual Walk Through</title>
      <link>/post/covariance-a-visual-walk-throu/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/covariance-a-visual-walk-throu/</guid>
      <description>In a previous post, I’ve looked at walking through the calculation of variance and standard deviation, visualizing each step. This post is dedicated to the visualization of another statistic: covariance. Covariance is a measure of the joint variability of two random variables. And now lets apply the equation to the following case: Ready? Okay, now let’s walk through the calculation; there are 7 small steps: That’s</description>
    </item>
    
    <item>
      <title>Day 47-50: Paletter</title>
      <link>/post/day-4750-paletter/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/day-4750-paletter/</guid>
      <description>Okay! It’s a Thursday evening. Solo parenting is over. My partner is back in town. The kids are in bed. Tina Turner is playing over the wireless. I’m the last one awake. Time for an R post, because that’s just the kind of girl I</description>
    </item>
    
    <item>
      <title>Uncertainty and Sample Size</title>
      <link>/post/uncertainty-and-sample-size/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/uncertainty-and-sample-size/</guid>
      <description>As a hungry botanist I couldn&amp;rsquo;t think of a more a-peel-ing metaphor than fruit. Let&amp;rsquo;s say we have a fruit bowl consisting of strawberries, raspberries, blueberries, and blackberries. There are 50 strawberries, 20 blueberries, 15 raspberries, and 15 blackberries. We can simulate this delicious bowl in r by creating a vector where we repeat (rep) each fruit the number of times they occur in our true, fruit bowl</description>
    </item>
    
    <item>
      <title>Eat near the Big Ben?  That will cost you...</title>
      <link>/post/eat-near-the-big-ben-that-will/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/eat-near-the-big-ben-that-will/</guid>
      <description>#MakeoverMonday is a fun data visualization initiative; most participants use Tableau as their preferred visualization tool. But I’ve used R and ggplot() and the organizers and participants have been very welcoming. (Recently, I’ve noticed an initiative for R has sprouted up — #TidyTuesday, with a focus on visualization and data</description>
    </item>
    
    <item>
      <title>Day 39-46</title>
      <link>/post/day-3946/</link>
      <pubDate>Sun, 10 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/day-3946/</guid>
      <description>This series of posts has been on hold for the last few days because I’ve been solo parenting and had a few deadlines at work. I have no idea how single parents</description>
    </item>
    
    <item>
      <title>Could an Independent Yorkshire Win the World Cup - Simulate World Cups</title>
      <link>/post/could-an-independent-yorkshire/</link>
      <pubDate>Sat, 09 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/could-an-independent-yorkshire/</guid>
      <description>Now that we have the teams for each county, we want to work out how well they would do at a world cup. For this, we need to know roughly what their ranking would be compared to actual nations. Two sources of rankings of nations are the official FIFA world rankings, and also the world ELO ratings of each nation at www.eloratings.net. I scraped both of these (accurate to mid-May) and cleaned the data to match the nation names to those in the player dataset we’re</description>
    </item>
    
    <item>
      <title>Peeking behind the curtain with {slidex}</title>
      <link>/post/peeking-behind-the-curtain-wit/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/peeking-behind-the-curtain-wit/</guid>
      <description>I gave a lightning talk (slides here) this past weekend at the second annual Cascadia R Conference that was focused on creating and contributing new themes to the {xaringan} package, which is essentially a really well thought out and well-organized R Markdown wrapper around the remark.js package for producing beautiful HTML</description>
    </item>
    
    <item>
      <title>One Year Anniversary</title>
      <link>/post/one-year-anniversary/</link>
      <pubDate>Wed, 06 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/one-year-anniversary/</guid>
      <description>In a nice little coincidence this is the 11th post to the blog and pushes my first introductory post to the second page of blog entries. I am looking forward to the next year of continuing to learn more about digital humanities and R and writing about my experiences on this blog, pushing more and more posts to the second page and</description>
    </item>
    
    <item>
      <title>Day 38: Algorithmic complexity</title>
      <link>/post/day-38-algorithmic-complexity/</link>
      <pubDate>Sun, 03 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/day-38-algorithmic-complexity/</guid>
      <description>can be produced with a very short R program: whereas a random-looking string like However, if I use R as the compressing language, there is a very short program that produces it: All of which is by way of background. And calling it… Not surprisingly, complexity increases as a sequence becomes longer, even if it’s the the same symbol being</description>
    </item>
    
    <item>
      <title>Day 36-37: Concerned DALEX</title>
      <link>/post/day-3637-concerned-dalex/</link>
      <pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/day-3637-concerned-dalex/</guid>
      <description>I was working on a longer post continuing the metaprogramming series, and realised I wasn’t going to get it done this evening. But it’s been a couple of days since I tried out something new, so I resorted to the twitters to find inspiration. As always, the wonderful twitter rstats folks rose to the occasion: If I’ve understood this correctly, what the figure is showing me is what happens to the model prediction as I add the predictors in one by</description>
    </item>
    
    <item>
      <title>Setting Up R</title>
      <link>/post/setting-up-r/</link>
      <pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/setting-up-r/</guid>
      <description>This is one of a series of posts where I document software configurations for personal reference. This post documents the configurations for R. This post will concentrate on user- or project-specific files, so all the files mentioned below should be placed in a user’s home directory or in the working directory of a project. Global Options -&amp;gt; General:</description>
    </item>
    
    <item>
      <title>Building my website with blogdown</title>
      <link>/post/building-my-website-with-blogd/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/building-my-website-with-blogd/</guid>
      <description>This is my third attempt at building a website, including an (overly?) ambitious idea to document all of the #Rcats and #Rdogs (and #Rchickens Lucy!) on twitter. After two false starts caused by a combination of teaching responsibilities, making time to snuggle my doggos, and some general anxiety, I think this time is my proverbial charm. First, I took the excellent advice of keeping my theme simple in order to spend my time on content at</description>
    </item>
    
    <item>
      <title>My favourite snippets</title>
      <link>/post/my-favourite-snippets/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/my-favourite-snippets/</guid>
      <description>A hidden gem from Rstudio is snippets feature. A well known option in any other editor (Atom, VS Code, Notepad ++&amp;hellip;.) seems that for R people is not a very used tool. For what I know some developers tend to code a full Add-in for things that can be achieved easily just adding a snippet to your Rstudio configuration. Doing this is easy. The graphical way is getting to Rstudio Tools &amp;gt; Global Options &amp;gt; Code &amp;gt; Enable Code Snippets (Edit</description>
    </item>
    
    <item>
      <title>An Introduction to the kmeans Algorithm</title>
      <link>/post/an-introduction-to-the-kmeans-/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/an-introduction-to-the-kmeans-/</guid>
      <description>This post will provide an R code-heavy, math-light introduction to selecting the (k) in k means. It presents the main idea of kmeans, demonstrates how to fit a kmeans in R, provides some components of the kmeans fit, and displays some methods for selecting k. In addition, the post provides some helpful functions which may make fitting kmeans a bit easier. kmeans clustering is an example of unsupervised learning, where we do not have an output we’re explicitly trying to</description>
    </item>
    
    <item>
      <title>c2d4u Update</title>
      <link>/post/c2d4u-update/</link>
      <pubDate>Sun, 27 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/c2d4u-update/</guid>
      <description>On the c2d4u PPAs, my goal is to update and add new packages (from CRAN Task Views) on a weekly basis, usually on the weekend. While I was building c2d4u3.5, I put this on hold, as I didn’t want to build new (to the PPA) packages at the same time as checking old ones. For this update, 230 R packages were either updated or added as new. At this time, I don’t provide information that distinguishes between updated or new, but that feature may be added in the</description>
    </item>
    
    <item>
      <title>epldata Package</title>
      <link>/post/epldata-package/</link>
      <pubDate>Sun, 27 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/epldata-package/</guid>
      <description>I have been collating data from the English Premier League since it began in 1992 and have a complete database of every players appearances in league games, details of goals scored and assists made. This has formed the backend of both the premiersoccerstats shiny web site and the weekly blog posts on this site for the 38 rounds of thw 2017&amp;frasl;18</description>
    </item>
    
    <item>
      <title>trekfont</title>
      <link>/post/trekfont/</link>
      <pubDate>Thu, 24 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/trekfont/</guid>
      <description>First use base graphics. Did you ever think you would be annotating your plots in Vulcan and Klingon? Next use ggplot2. If you have trouble with the fonts not displaying and are receiving warnings such</description>
    </item>
    
    <item>
      <title>Introducing altair, an R interface to the Altair Python Package</title>
      <link>/post/introducing-altair-an-r-interf/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/introducing-altair-an-r-interf/</guid>
      <description>Introducing altair, an R package to work with the Python package Altair, which you can use to build and render Vega-Lite chart-specifications: https://vegawidget.github.io/altair Vega-Lite offers an implementation of an interactive grammar of graphics. The vocabulary and syntax of this grammar is different from that used by ggplot2. However, the fundamental ideas are very much the same: ggplot2 offers aesthetics, geoms, and scales; Vega-Lite offers marks, encondings, and</description>
    </item>
    
    <item>
      <title>Update on the Move to R 3.5.0</title>
      <link>/post/update-on-the-move-to-r-350/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/update-on-the-move-to-r-350/</guid>
      <description>One of the challenges with using Launchpad is that once a package is built, it needs to be published. This takes some time (around 20 minutes). Therefore, you can’t just push a series of packages to Launchpad and walk away. In order to ensure the dependencies are built, you need to wait until they have been published in the PPA. This is on top of determining the build order based on</description>
    </item>
    
    <item>
      <title>Welcome to vegawidget</title>
      <link>/post/welcome-to-vegawidget/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/welcome-to-vegawidget/</guid>
      <description>The effort to bring Vega-Lite to the R community is collaborative; so it appropriate that the altair package be hosted by an organization. The altair R package uses the Altair Python package to create Vega-Lite specifications for interactive charts. This group is named vegawidget, after the altair::vegawidget() function, which is used to render Vega and Vega-Lite chart specifications into HTML. In the not-so-distant future, this renderer will have its own package, also hosted by this</description>
    </item>
    
    <item>
      <title>What is going on in OPP? a quick summary of the first five months</title>
      <link>/post/what-is-going-on-in-opp-a-quic/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/what-is-going-on-in-opp-a-quic/</guid>
      <description>To achieve this goal, OPP evolved to: We were surprised by a quick reaction and initial engagement in our Slack workspace where several channels were created to accommodate smaller groups with a specific interest including #epidemictheory, #phytopathometry, #reproducibility, #teaching and #r-pkg-dev, as among the more active. There have been a lot of interactions and collaborations are on the</description>
    </item>
    
    <item>
      <title>Is Your Hospital Closer to a Dunkin or Starbucks? (MA edition)</title>
      <link>/post/is-your-hospital-closer-to-a-d/</link>
      <pubDate>Sun, 13 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/is-your-hospital-closer-to-a-d/</guid>
      <description>This post is inspired by #tidytuesday. Coffee is the life force for many healthcare workers. Here too, the age old question arises: Dunkin or Starbucks? Sometimes, it just comes down to proximity. We need coffee and we need it now! So, I decided to see what chain was closest to each hospital in Massachusetts. Data Sources Starbucks locations: Dunkin locations: Hospital locations: The Packages library(tidyverse) library(tidycensus) library(jsonlite) library(geosphere) The Data starb =</description>
    </item>
    
    <item>
      <title>Mapping the Tunisian Revolution</title>
      <link>/post/mapping-the-tunisian-revolutio/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/mapping-the-tunisian-revolutio/</guid>
      <description>R provides a growing number of mapping packages. In this post I document my workflow for producing a map of the diffusion of protest during the Tunisian Revolution. The following packages will be required for anyone who has similar mapping requirements and wishes to follow the same steps: But that was in January and I hadn’t yet been introduced to the potential of R for mapping tasks. The map serves a purpose but there are problems with</description>
    </item>
    
    <item>
      <title>#BoG18: Talk Notes</title>
      <link>/post/bog18-talk-notes/</link>
      <pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/bog18-talk-notes/</guid>
      <description>Typos everywhere. Things may change dramatically over time as I scan back through notes. I’ve tried to respect #notwitter. Will be updated periodically. Speaker (Last Author) 80+% complete for each of the</description>
    </item>
    
    <item>
      <title>R4DS May Challenge</title>
      <link>/post/r4ds-may-challenge/</link>
      <pubDate>Sat, 05 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/r4ds-may-challenge/</guid>
      <description>Sure, we could do something similar to the first iteration of our online learning community and say we’re going to cover a specified amount of material each week, but instead we’re going to try something new! By signing up for office hours, you are making a commitment to show up during the office hours</description>
    </item>
    
    <item>
      <title>Riddler 27th April 2018</title>
      <link>/post/riddler-27th-april-2018/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/riddler-27th-april-2018/</guid>
      <description>Formally this is phrased as: Some number, N, of people need to pee, and there is some number, M, of urinals in a row in a men’s room. The people always follow a rule for which urinal they select: The first person goes to one on either far end of the row, and the rest try to maximize the number of urinals between them and any other person. So the second person will go on the other far end, the third person in the middle, and so</description>
    </item>
    
    <item>
      <title>Writing an R Package Basics (and why I think you should)</title>
      <link>/post/writing-an-r-package-basics-an/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/writing-an-r-package-basics-an/</guid>
      <description>On April 10, 2018, I gave a talk entitled Developing your first R package: A case study with esvis for the Eugene R Users Group. Although I discussed my esvis package, the focus of the talk was really on tools and tips for developing R pacakges. In this post, I&amp;rsquo;ll go over some of the content in that talk, and discuss why I think you should develop an R</description>
    </item>
    
    <item>
      <title>dockerterm</title>
      <link>/post/dockerterm/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/dockerterm/</guid>
      <description>As seen in the clip above, this initial proof of concept works well, at least on my machine. There are some definite drawbacks and limitations that need to be addressed, but for the most part, I’m pleased with the initial functionality. Now, this integration between Docker and RStudio has some major (current) limitations. First and foremost, RStudio and the Docker container aren’t really aware of each</description>
    </item>
    
    <item>
      <title>A Shiny App to Visualize and Share My Dogs’ Medical History</title>
      <link>/post/a-shiny-app-to-visualize-and-s/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/a-shiny-app-to-visualize-and-s/</guid>
      <description>As a digital nomad traveling with 2 dogs, keeping track of all their medical and vaccine records has been challenging. Especially since one of our dogs has had some recent health issues. I needed a way to organize all the vet visits, test results, vaccine certificates, etc. as well as be able to share them with new vets and our primary vet back in Colorado. Thus, an R Shiny app was</description>
    </item>
    
    <item>
      <title>Coursera R-Programming</title>
      <link>/post/coursera-rprogramming/</link>
      <pubDate>Sat, 14 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/coursera-rprogramming/</guid>
      <description>Over the past several weeks I have been helping students, career professionals, and people of other backgrounds learn R. During this time one this has become apparent, people are teaching the old paradigm of R and avoiding the tidyverse all together. The zip file contains 332 comma-separated-value (CSV) files containing pollution monitoring data for fine particulate matter (PM) air pollution at 332 locations in the United</description>
    </item>
    
    <item>
      <title>New Website Theme!</title>
      <link>/post/new-website-theme/</link>
      <pubDate>Sat, 14 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/new-website-theme/</guid>
      <description>This post has needed to be writtend for a little while, but I&amp;rsquo;ve been busy with the actual work of redesigning my website (in fact, I have a number of posts that are backlogged). This post will have a little bit of code (all of it CSS, rather than R), but mostly it&amp;rsquo;s just about my journey and things I&amp;rsquo;ve learned. Getting started with Blogdown In Yihui&amp;rsquo;s introduction to blogdown he advocates for simpler</description>
    </item>
    
    <item>
      <title>Stan Basics</title>
      <link>/post/stan-basics/</link>
      <pubDate>Sat, 14 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/stan-basics/</guid>
      <description>I attended a great short course on bayesian workflow using Stan at the New England Statistics Symposium yesterday. If you don’t know, Stan is “a state-of-the-art platform for statistical modeling and high-performance statistical computation”. You can easily interface with Stan through R (or python or a bunch of other languages). I figured it would be valuable for myself, and possibly others, to work through a few different problems in Stan and share my</description>
    </item>
    
    <item>
      <title>#TidyTuesday</title>
      <link>/post/tidytuesday/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday/</guid>
      <description>I do not update this site as much as I would like. Interacting through twitter and the #R4DS slack channel has been my main contributions as of late to being more active in the #rstats community. I make plans to get to things like posting, then end up with other work, a neat idea, or just decide spend time with my family. Worthy endeavors all of them. Anyways, Thomas Mock (@thomasmock), has started up #tidytuesday out of the mentorship pilot program in</description>
    </item>
    
    <item>
      <title>Analyzing Sleep Data with R</title>
      <link>/post/analyzing-sleep-data-with-r/</link>
      <pubDate>Fri, 06 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/analyzing-sleep-data-with-r/</guid>
      <description>I’ve been using the iOS Sleep Cycle app to track my sleeping since late 2014 and have accumulated quite a bit of information about my sleeping habits. I wanted to see if I could do some exploratory data analysis and try out some different packages to clean up and visualize my data. The data from the app comes in a csv file and contains information like date, sleep quality, sleep duration, and more recently it can integrate with the pedometer so you can get the number of steps in a given</description>
    </item>
    
    <item>
      <title>Kaggle panel recap</title>
      <link>/post/kaggle-panel-recap/</link>
      <pubDate>Wed, 04 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/kaggle-panel-recap/</guid>
      <description>Short answer: Twitter. I don’t always tweet about career transitions in data science, but I do keep my Twitter bio section pretty focused on what I do and how I got there: Short answer: sheer dumb luck. Long answer: I “found” data science when I was at an incredibly low point in my life. It was 2013, and I had just impulsively moved cross-country (from NYC to Seattle) with a boyfriend I started having second thoughts about the moment we left</description>
    </item>
    
    <item>
      <title>Introducing Git &#43; Github</title>
      <link>/post/introducing-git-github/</link>
      <pubDate>Tue, 03 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/introducing-git-github/</guid>
      <description>Something helpful that came out of this exercise was that it really made me sit down and think about how exactly version control is useful to applied economists and how it can be made to feel as accessible as possible. If you haven’t read David’s blog posts, my takeaway from them is that the earlier you can get students to the payoff, the</description>
    </item>
    
    <item>
      <title>TidyTuesday</title>
      <link>/post/tidytuesday/</link>
      <pubDate>Tue, 03 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/tidytuesday/</guid>
      <description>In the first quarter of 2018, I focused my data science education on expanding my R programming skills and setting up this blog in Hugo. I developed my first R package, an API wrapper to the U.S. National Provider Identification (NPI) registry, and created an R-powered Power BI custom visual for a client. Although I still plan to continue my work on these projects, I’m ready to start a new</description>
    </item>
    
    <item>
      <title>Note to Self</title>
      <link>/post/note-to-self/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/note-to-self/</guid>
      <description>This is the first post in a series where I write to myself regarding the various data science spells I’m learning. Today’s spell: dplyr’s filter function. For some reason, upon learning how to filter data with the dplyr package, I thought that function was designed to only remove or discard data, specifically columns. That is not the case and I’m writing this blog post to try and correct this automatic thinking in my brain.</description>
    </item>
    
    <item>
      <title>Plotting multiple lines on the y axis of a ggplot graph</title>
      <link>/post/plotting-multiple-lines-on-the/</link>
      <pubDate>Sat, 31 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/plotting-multiple-lines-on-the/</guid>
      <description>I wanted to plot the yearly sales of three different types of hybrid and electric vehicles on the same graph. The dataset was originally wide with years as columns and the types of cars as rows. After cleaning the data (making it skinner by switching cars to columns and years to rows) and saving it to the name “ev_csv_3”, it was time to plot. In order to have multiple y-axis lines, simply skip entering a y argument in the aes function in the first line of the ggplot</description>
    </item>
    
    <item>
      <title>Introducing tabr</title>
      <link>/post/introducing-tabr/</link>
      <pubDate>Mon, 19 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/introducing-tabr/</guid>
      <description>While music can be quite complex and a full score will be much longer, something as simple as the following code snippet produces the music notation in the accompanying image. You can install tabr from GitHub with: Finally, there are nonetheless limitations to LilyPond itself. It has been developed for sheet music in general and guitar tablature features were added as a relative afterthought. There are plenty of features I have not yet developed R wrappers</description>
    </item>
    
    <item>
      <title>Brooke Watson</title>
      <link>/post/brooke-watson/</link>
      <pubDate>Sun, 18 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/brooke-watson/</guid>
      <description>Open source software is made for remixing. When I first switched from STATA to R, I was comfortable using predefined packages and commands, but it quickly became apparent that R’s appeal lies in the power to write custom functions and packages. What’s more, because R is open source, these packages don’t have to be built from scratch. They’re best when they sample from others. For my beepr remix, I wanted to use ad libs from rap</description>
    </item>
    
    <item>
      <title>Exploring the underlying theory of the chi-square test through simulation - part 1</title>
      <link>/post/exploring-the-underlying-theor/</link>
      <pubDate>Sun, 18 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/exploring-the-underlying-theor/</guid>
      <description>Kids today are so sophisticated (at least they are in New York City, where I live). While I didn’t hear about the chi-square test of independence until my first stint in graduate school, they’re already talking about it in high school. When my kids came home and started talking about it, I did what I usually do when they come home asking about a new statistical concept. I opened up R and started generating some</description>
    </item>
    
    <item>
      <title>Functional programming in R with Purrr</title>
      <link>/post/functional-programming-in-r-wi/</link>
      <pubDate>Sun, 18 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/functional-programming-in-r-wi/</guid>
      <description>When you first started in R you likely were writing simple code to generate one outcome. This is great, you are learning about strings, math, and vectors in R! Then you get started with some basic analyses. You want to see if you can find the mean of some</description>
    </item>
    
    <item>
      <title>Prime hints for running a data project in R</title>
      <link>/post/prime-hints-for-running-a-data/</link>
      <pubDate>Sun, 18 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/prime-hints-for-running-a-data/</guid>
      <description>I’ve been asked more and more for hints and best practices when working with R. It can be a daunting task, depending on how deep or specialised you want to be. So I tried to keep it as balanced as I could and mentioned point that definitely helped me in the last couple of years. Finally, there’s lots (and I mean, LOTS) of good advice out there that you should definitely check out - see some examples in the Quick Reference section below.</description>
    </item>
    
    <item>
      <title>Building a package that uses pattern matching</title>
      <link>/post/building-a-package-that-uses-p/</link>
      <pubDate>Sat, 17 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/building-a-package-that-uses-p/</guid>
      <description>After a week spend programming string algorithms in C—for teaching purposes, I am not working on a new read-mapper—it is nice to get back to programming in R. I made a new release of tailr today, so that is good, but what I really wanted to work on was</description>
    </item>
    
    <item>
      <title>A gentle guide to Tidy statistics in R</title>
      <link>/post/a-gentle-guide-to-tidy-statist/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/a-gentle-guide-to-tidy-statist/</guid>
      <description>We will be using MMSE (mini-mental status exam) scores to assess the degree of cognitive impairment. In a real clinical trial, many other variables would be recorded, but for the sake of a straightforward but multi-variate example we will stick to just MMSE. We will be working through loading, plotting, analyzing, and saving the outputs of our analysis through the tidyverse, an “opinionated collection of R packages” designed for data</description>
    </item>
    
    <item>
      <title>Getting Global Fishing Watch Data from Google Big Query using R</title>
      <link>/post/getting-global-fishing-watch-d/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/getting-global-fishing-watch-d/</guid>
      <description>Now we are all set to start querying and analyzing Global Fishing Watch’s data. There are a couple of approaches to do this and whichever you use depends primarily on: 1) your experience with SQL, 2) how much you dislike SQL, and 3) how much you use R notebooks as opposed to classic R</description>
    </item>
    
    <item>
      <title>Contra JFK, use R because it is easy, not because it is hard</title>
      <link>/post/contra-jfk-use-r-because-it-is/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/contra-jfk-use-r-because-it-is/</guid>
      <description>There’s an attitude that I believe is reasonably common among applied economists, that coding is the easy part of what we do and where we add the least value. If we were building a house, coding is like laying bricks - it’s the “menial” and “boring” part of the job (no slight meant against actual bricklayers) - and we add the most value as the architect by coming up with an interesting research question, thinking about endogeneity and so</description>
    </item>
    
    <item>
      <title>Mapping the Global Network of Transnational Fisheries</title>
      <link>/post/mapping-the-global-network-of-/</link>
      <pubDate>Thu, 15 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/mapping-the-global-network-of-/</guid>
      <description>All the analysis is done in R, with Studio, using the following packages: Here is snippet of the dataset: where: We have excluded here 1) the connections between EU members states 2) the EU Northern agreements with Norway, and Iceland, 3) connections between sovereign states, e,g: France and Reunion and 4) disputed or jointly managed marine territories. We now have our paths right, however, we still need to visualize the directionality.</description>
    </item>
    
    <item>
      <title>Linked lists in matchbox</title>
      <link>/post/linked-lists-in-matchbox/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/linked-lists-in-matchbox/</guid>
      <description>I have started playing with data structures in matchbox and the first structure I implement had to be linked lists. That is the most versatile data structure I use and it is missing from</description>
    </item>
    
    <item>
      <title>Workshop materials</title>
      <link>/post/workshop-materials/</link>
      <pubDate>Fri, 09 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/workshop-materials/</guid>
      <description>The real reason that Sally and I decided not to present, instead seeking out other women in the community to do so, was that we simply knew these women were out there and wanted them to join our group. We were hopeful that, with just the right amount of pleading balanced with what we perceived to be the obvious inherent value of what we were offering, the R-savvy women in our lives (or soon to be in our lives) would agree to</description>
    </item>
    
    <item>
      <title>Help Me Choose a Package Name</title>
      <link>/post/help-me-choose-a-package-name/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/help-me-choose-a-package-name/</guid>
      <description>What&amp;rsquo;s in a name? That which we call a rose By any other word would smell as sweet — William Shakespeare, Romeo and Juliet I have plans for re-implementing several of the data structures I wrote about in Functional Data Structures in</description>
    </item>
    
    <item>
      <title>Working With Messy Text</title>
      <link>/post/working-with-messy-text/</link>
      <pubDate>Tue, 06 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/working-with-messy-text/</guid>
      <description>Heyo! I am doing my best to procrastinate here on a blustery Tuesday afternoon. So, I decided to share some code I&amp;rsquo;ve put together that solves problems in R that I used to do in perl. HTML or C++ was probably my first real language, but I love the heck out of perl. It&amp;rsquo;s never done me wrong (unlike you PHP). Anyways! The context of this project is that we are developing a dictionary of words to complement the work done by Jonathan Haidt and Jesse Graham - learn</description>
    </item>
    
    <item>
      <title>Designing a DSL for dynamic programming</title>
      <link>/post/designing-a-dsl-for-dynamic-pr/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/designing-a-dsl-for-dynamic-pr/</guid>
      <description>I&amp;rsquo;m working on an example for one of the chapters of Domain Specific Languages in R that will appear in the printed version but weren&amp;rsquo;t included in the earlier e-book. The plan is to have one to three extra example chapters, depending on how much I can do before my deadline on April</description>
    </item>
    
    <item>
      <title>Something Different</title>
      <link>/post/something-different/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/something-different/</guid>
      <description>title: ‘Something Different: Automated Neighborhood Traffic Monitoring’ author: David McGaughey date: ‘2018-03-03’ slug: traffic-monitoring-intro categories: - R - python - raspberry - pi tags: - R - python - raspberry - pi — This is, obviously, a personal project. Traffic is a concern in my town. Cut-through, speeding,</description>
    </item>
    
    <item>
      <title>tailr — Tail Recursion Optimisation</title>
      <link>/post/tailr-tail-recursion-optimisat/</link>
      <pubDate>Fri, 02 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/tailr-tail-recursion-optimisat/</guid>
      <description>Believe it or not, all the bother with setting up this blog was such that I could write this post easier than I could on Wordpress. So now, let us get to some actual R</description>
    </item>
    
    <item>
      <title>First Post</title>
      <link>/post/first-post/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/first-post/</guid>
      <description>This is my first attempt at a Hugo+Blogdown blog. I got tired of struggling with formatting R code on my Wordpress blog, so figured it would make sense to use RMarkdown to write about R</description>
    </item>
    
    <item>
      <title>Let’s Plot 4</title>
      <link>/post/lets-plot-4/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/lets-plot-4/</guid>
      <description>The battle that we’ve all been waiting for. Excel vs. R. Bar plot versus a plot that actually shows the data. Yeah, this isn’t a fair fight. Bar plots are terrible. Why? Simple. They don’t show what your data looks like. A bar plot gives you zero idea how many data points there are. You can add error bars, but you don’t know if you are looking at standard error or standard</description>
    </item>
    
    <item>
      <title>Interpretable Machine Learning with iml and mlr</title>
      <link>/post/interpretable-machine-learning/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/interpretable-machine-learning/</guid>
      <description>Machine learning models repeatedly outperform interpretable, parametric models like the linear regression model. The gains in performance have a price: The models operate as black boxes which are not interpretable. Fortunately, there are many methods that can make machine learning models</description>
    </item>
    
    <item>
      <title>Training Courses for mlr</title>
      <link>/post/training-courses-for-mlr/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/training-courses-for-mlr/</guid>
      <description>The mlr: Machine Learning in R package provides a generic, object-oriented and extensible framework for classification, regression, survival analysis and clustering for the statistical programming language R. The package targets practitioners who want to quickly apply machine learning algorithms, as well as researchers who want to implement, benchmark, and compare their new methods in a structured environment. We are happy to announce that we now offer training courses specialized on</description>
    </item>
    
    <item>
      <title>r-tip</title>
      <link>/post/rtip/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/rtip/</guid>
      <description>I&amp;rsquo;ve picked up a few tips along the way, and I wanted to share a couple of things I think give you a nice return on</description>
    </item>
    
    <item>
      <title>New Publication - Detect Low Quality Data</title>
      <link>/post/new-publication-detect-low-qua/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/new-publication-detect-low-qua/</guid>
      <description>My coauthor John Scofield and I just had a publication accepted at Behavior Research Methods - you can check out the publication preprint at OSF. We thew together a website for the paper that summarizes everything we found, as well as puts all the materials together in one place - check it out. We create a really nice R function to help you detect low quality data, which you can find on GitHub, and I even made a video that explains all the parts to the function at</description>
    </item>
    
    <item>
      <title>Citations in R Markdown &#43; Papaja</title>
      <link>/post/citations-in-r-markdown-papaja/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/citations-in-r-markdown-papaja/</guid>
      <description>Heyo! I wanted to write a post about some of the quirky things I&amp;rsquo;ve found with writing manuscripts in R Markdown, as well as provide a solution to a problem that someone else might be having. Update: The csl file I describe below is a special formatted one, which was shared with me. You can download it from GitHub to try the suggestions below. Update 2: Turns out, potentially, the suggestions from the manual are not working correctly, as Frederik has checked it out and opened an issue on</description>
    </item>
    
    <item>
      <title>Competitive Steak Eating and Gender</title>
      <link>/post/competitive-steak-eating-and-g/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/competitive-steak-eating-and-g/</guid>
      <description>Before we get too far down the trail on this, I’ll warn readers that this is a pink and blue post. It’s simple prediction using an interesting R package. It’s important to consider the stakes (pun intended), when “enriching” a dataset with information that might introduce bias. Here, inaccuracies can occur by simple misspelling or just a slightly higher probability for the years selected…or other things. That said, I wanted to get an idea of gender diversity in competitive steak eating</description>
    </item>
    
    <item>
      <title>Speeding up spatial analyses by integrating `sf` and `data.table`</title>
      <link>/post/speeding-up-spatial-analyses-b/</link>
      <pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/speeding-up-spatial-analyses-b/</guid>
      <description>However, this starts to have problems over really large datasets, because the total number of comparisons to be done still rapidly increase besides the use of spatial indexes. A test done by changing the number of points in the above example in the range 25000 - 475000 shows for example this kind of behavior, for two different values of maxdist (500 and 2000 m): On the test dataset, the relationships are almost perfectly quadratic (due to the uniform distribution of</description>
    </item>
    
    <item>
      <title>Parallelization of Simulations with the foreach Package and Missing Data in R</title>
      <link>/post/parallelization-of-simulations/</link>
      <pubDate>Sun, 18 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/parallelization-of-simulations/</guid>
      <description>Come out to our March event to hear talks from two great R Ladies! First we&amp;rsquo;ll learn about parallelization of simulations with the foreach R package, with applications to progression free survival assessed using electronic health records. Then we&amp;rsquo;ll get an introduction to methods for handling missing data in R. Date: Tuesday, March 20, 2018 Time: 6:30pm Speakers: Elizabeth Sweeney and Mine</description>
    </item>
    
    <item>
      <title>Football Fans</title>
      <link>/post/football-fans/</link>
      <pubDate>Sat, 17 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/football-fans/</guid>
      <description>This was a project that I originally did for my Data Warehousing class in grad school using Microsoft SQL server and SSIS. I’ve been taking a lot of datacamp courses lately and wanted to put what I learned about the tidyverse into action. This project has a lot of data manipulation and cleanup tasks, so I thought it would be a good candidate to convert what I did in grad school to R and</description>
    </item>
    
    <item>
      <title>Measuring URL health in R</title>
      <link>/post/measuring-url-health-in-r/</link>
      <pubDate>Sat, 17 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/measuring-url-health-in-r/</guid>
      <description>Motivation I’m working on auditing Canada’s open data portal. One issue that comes up: how to verify if a link to a dataset is useful? It may redirect, it may return 404, it may return an R error, or an R warning, and the otherwise great URL packages don’t have a simple way of getting all the possible errors and warnings in one command. Data Here are some possible URLs you’ll run in to; some work, some</description>
    </item>
    
    <item>
      <title>Taking flight with R</title>
      <link>/post/taking-flight-with-r/</link>
      <pubDate>Sat, 17 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/taking-flight-with-r/</guid>
      <description>Inspired by the current exhibit on ART ∩ MATH at Seattle’s Center on Contemporary Cart (COCA), I decided to replicate one of the pieces by the very talanted Iranian mathematical artist, Hamid Naderi Yeganeh. Yeganeh provided the full mathematical equation as a caption to his piece, “Bird,” and I thought it would be fun to give it a test flight in R. This turned out to be straightforward thanks to R’s native</description>
    </item>
    
    <item>
      <title>Scraping NIH PIs with rvest</title>
      <link>/post/scraping-nih-pis-with-rvest/</link>
      <pubDate>Thu, 15 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/scraping-nih-pis-with-rvest/</guid>
      <description>Background: I was doing some exploratory work for a potential project looking at intramural investigators at the NIH. Eventually I decided to put it aside for the time being, but here is some cleaned up code that came out of it, along with some basic descriptives. I’m going to do this in two broad steps: Selectorgadget is a javascript bookmarklet that allows you to interactively figure out what css selector you need to extract desired components from a</description>
    </item>
    
    <item>
      <title>Licensing R Packages that Include Others Code</title>
      <link>/post/licensing-r-packages-that-incl/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/licensing-r-packages-that-incl/</guid>
      <description>If you include others code in your own R package, list them as contributors with comments about what they contributed, and add a license statement in the file that includes their code. Note that all significant contributors must be included: if you wrote an R wrapper for the work of others included in the src directory, you are not the sole (and maybe not even the main) author. I am the main author and maintainer of the new package, that is</description>
    </item>
    
    <item>
      <title>Teaching Luxembourgish to my computer</title>
      <link>/post/teaching-luxembourgish-to-my-c/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/teaching-luxembourgish-to-my-c/</guid>
      <description>Today we reveal a project that Kevin and myself have been working on for the past 2 months, Liss. Liss is a sentiment analysis artificial intelligence; you can let Liss read single words or whole sentences, and Liss will tell you if the overall sentiment is either positive or negative. Such tools are used in marketing, to determine how people perceive a certain brand or new products for instance. The originality of Liss, is that it works on Luxembourguish</description>
    </item>
    
    <item>
      <title>Second star to the right and straight on &#39;til morning</title>
      <link>/post/second-star-to-the-right-and-s/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/second-star-to-the-right-and-s/</guid>
      <description>The strength of R doesn’t lie in a single programming paradigm, it lies within the warm, welcoming and ecclectic community of useRs. Like anyone who gets introduced to R, you start to look on the web for other like minded people. Upon doing so, you find a vibrant community with very knowledgeable and helpful people. Bob Rudis (@hrbrmstr) is one of those people, doling out R wisdom, visualization, typography, culinary and infosec goodness on the</description>
    </item>
    
    <item>
      <title>The FutuRe is Bright</title>
      <link>/post/the-future-is-bright/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-future-is-bright/</guid>
      <description>I’ve been a (usually) silent observer of the rstats community via twitter. Occasionally I’ll jump in and share thoughts or retweet something I found particularly helpful or inspiring, but for the most part I just sit back and observe. I’ve always admired the fact that, online, the R community seems helpful, kind, and aware of one another. This conference only further solidified that view. I made it a point during the conference to find and talk to individuals who are R rockstars in my</description>
    </item>
    
    <item>
      <title>dplyr Doesn&#39;t Provide Full Support For S4 (For Now?)</title>
      <link>/post/dplyr-doesnt-provide-full-supp/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/dplyr-doesnt-provide-full-supp/</guid>
      <description>I&amp;rsquo;ve seen sooo many (duplicated) issues on this topic were opened on dplyr&amp;rsquo;s repo and lubridate&amp;rsquo;s repo. So, apparently, the content of this post won&amp;rsquo;t stay useful over time. But, for now, I feel this temporal &amp;ldquo;known issue&amp;rdquo; should be well-known, at least among those who suffers from this issue. I hope this post will be outdated</description>
    </item>
    
    <item>
      <title>Sharing some functions from my personal R package</title>
      <link>/post/sharing-some-functions-from-my/</link>
      <pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/sharing-some-functions-from-my/</guid>
      <description>In this post I basically just wanted to share some recent developments that I&amp;rsquo;ve made to my personal R package {sundry}. All of the recent advancements have been made to work with the tidyverse, so things like group_by should work seamlessly. If you feel like giving the package a whirl, I&amp;rsquo;d love any feedback you have or bugs you may find. At this point the package is only on</description>
    </item>
    
    <item>
      <title>How I use Rmarkdown</title>
      <link>/post/how-i-use-rmarkdown/</link>
      <pubDate>Fri, 09 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/how-i-use-rmarkdown/</guid>
      <description>Last week or so, I achieved a wonderous thing. A trivial thing. I acheived a wondrous, trivial thing: I wrote my most popular tweet ever: My new thing is ending every Rmd with a list of links to the forums / SO questions / blogs / github repos that I used to solve the problem #rstats pic.twitter.com/U51KT9kiym - Andrew MacDonald (@polesasunder) January 26, 2018 That’s right! Dr. MacDonald going viral on the internet by urging people to</description>
    </item>
    
    <item>
      <title>Prep Your Hugo Blog for R-bloggers</title>
      <link>/post/prep-your-hugo-blog-for-rblogg/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/prep-your-hugo-blog-for-rblogg/</guid>
      <description>Get Ready for R-Bloggers There are lots of reasons to write a technical blog. Getting practice writing, thinking through ideas, etc. are all fulfilling reasons on their own. But life is always better with an audience. Well, not always. But for a blog it is. R-bloggers is a great platform to find an audience and share your writing with the world. If you’re writing with Hugo via blogdown though, there’s a hurdle you’ll need to</description>
    </item>
    
    <item>
      <title>Triathlon pubmed analysis</title>
      <link>/post/triathlon-pubmed-analysis/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/triathlon-pubmed-analysis/</guid>
      <description>Today I am using the RISmed package for R to analyze publications about triathlon. It is an amazing package to look through the Pubmed database for what they have on a certain subject. Pubmed is a NIH (USA) funded database which hosts articles about medicine and biology. Today, I am looking at studies that have been done on injuries, disease and human physiology that have to do with triathlon. I am not a triathlete yet, I am just focusing on running this year but it is on my</description>
    </item>
    
    <item>
      <title>Introduction to R</title>
      <link>/post/introduction-to-r/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/introduction-to-r/</guid>
      <description>R is great for doing any kind of slicing and dicing with data. However the barrier to entry can be high, especially for people that come from a non-data background. I know that it took me quite some time to grasp just how R does its magic. When you do though, it really is a &amp;ldquo;that&amp;rsquo;s damn awesome&amp;rdquo; moment. Rather than running through all of the basics of R, I put together a script that takes you through some of the features in the context of analysing EC2 pricing</description>
    </item>
    
    <item>
      <title>First foray into Shiny</title>
      <link>/post/first-foray-into-shiny/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/first-foray-into-shiny/</guid>
      <description>Visualising Distributions Visualising Linear Discriminant Analysis Shiny had interested me for a while for it’s power to quickly communicate and vizualise data and models. I hadn’t delved into it due to lack of time to do so, until now. Two quick visualizations I’ve created as my 1st foray into R Shiny. Nothing earth shattering, but was helpful to learn the tool. Visualising Distributions Hosted on shinyapps for free, at link Github code</description>
    </item>
    
    <item>
      <title>Geocomputation with R - the intermission</title>
      <link>/post/geocomputation-with-r-the-inte/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/geocomputation-with-r-the-inte/</guid>
      <description>Both chapters apply command-line based geocomputation introduced in chapters 1-6 to the real world, and answer relevant questions in a reproducible manner with the help of open data and</description>
    </item>
    
    <item>
      <title>Linear Models</title>
      <link>/post/linear-models/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/linear-models/</guid>
      <description>Preamble The purpose of this post is to elucidate some of the concepts associated with statistical linear models. Let’s start by loading some libraries. library(ggplot2) library(datasets) Background Theory The basic idea is as follows: Given two variables, (x) and (y), for which we’ve measured a set of data points ({x_i, y_i}) with (i = 1, &amp;hellip;, n), we want to estimate a function, (f(x)), such that [y_i = f(x_i) +</description>
    </item>
    
    <item>
      <title>SOMs and ggplot</title>
      <link>/post/soms-and-ggplot/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/soms-and-ggplot/</guid>
      <description>We will, however, only use a random sample of the 75,000 players, for computational convenience. We start by computing the SOM for the random sample. There we go! Now we can continue putting the players in the right node. I think you can see more easily how homogeneous the grid nodes are with this plot. This very much the same code as used in the package. Below is the standard plot.</description>
    </item>
    
    <item>
      <title>R figure skating analysis</title>
      <link>/post/r-figure-skating-analysis/</link>
      <pubDate>Sat, 20 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/r-figure-skating-analysis/</guid>
      <description>Analysing medals won per athlete/per country with R Today I am introducing a sneaky little data analysis using R on figure skating in the olympics. I have already written a piece on Figure skating and what I think is going to happen in the upcoming olympics. But I also want to look back at athletes who have competed and won a medal in the past Olympics. If you&amp;rsquo;ve never heard of data science, this is how you can make very easy analysis of your favorite things in the</description>
    </item>
    
    <item>
      <title>Workshop</title>
      <link>/post/workshop/</link>
      <pubDate>Wed, 10 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/workshop/</guid>
      <description>Join us for our first R Ladies NYC event of 2018! Date: Wednesday, January 10, 2018 Time: 6:30pm Instructor: Joyce Robbins Host: Schapiro Center Columbia</description>
    </item>
    
    <item>
      <title>Crimes in Somerville (Time Series)</title>
      <link>/post/crimes-in-somerville-time-seri/</link>
      <pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/crimes-in-somerville-time-seri/</guid>
      <description>I recently spotted a time series heat map. So I started on a quest to make my own. Luckily, I found some local data to start with: crimes in Somerville, MA. This data set includes selected crimes in Somerville from 2005-2017. Handy Packages library(tidyverse) library(lubridate) library(ggthemes) library(plotly) Getting the Data somerville = read.csv(&amp;ldquo;Police_-_Selected_Criminal_Incidents.csv&amp;rdquo;) Cleaning the Data Remove 2018 data since the year has just</description>
    </item>
    
    <item>
      <title>Data Science with R</title>
      <link>/post/data-science-with-r/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/data-science-with-r/</guid>
      <description>It always starts with a DM on Twitter, where someone shares with me their personal data science ambitions, where they currently are in their plans, and then they follow up with a request for me to help them figure out where to go</description>
    </item>
    
    <item>
      <title>Map unemployment using R with ggplot2</title>
      <link>/post/map-unemployment-using-r-with-/</link>
      <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/map-unemployment-using-r-with-/</guid>
      <description>In this blog post, I show various ways to create maps using R. You’ll need to install a lot of packages and download two data sets; the unemployment rate in Luxembourg as well as a shapefile. These lines scrape the data off STATEC’s (the national institute of statistics) public tables and puts the raw data into a tidy data</description>
    </item>
    
    <item>
      <title>End of Year thoughts</title>
      <link>/post/end-of-year-thoughts/</link>
      <pubDate>Fri, 29 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/end-of-year-thoughts/</guid>
      <description>I&amp;rsquo;m a list-person. Totally. I love ticking off boxes, feeling that I&amp;rsquo;ve achieved a lot every day. At the same time, working full time in London (meaning work + non-negligible commute) while having two small children (2 and 4 years old) leaves me with very little spare time (usually in the evenings). Fortunately, my work as a data scientist and this blog give me lots of opportunities to solve problems and deliver something tangible in defined time</description>
    </item>
    
    <item>
      <title>Launching your shiny app in 2 clicks</title>
      <link>/post/launching-your-shiny-app-in-2-/</link>
      <pubDate>Tue, 26 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/launching-your-shiny-app-in-2-/</guid>
      <description>Hello everyone, It’s fast and useful if you work with colleagues that don’t have a clue about R and just want to use your shiny app. Open a text editor and write the following lines : Open a text editor and write the following lines: if it doesn’t work, check your pandoc location. And now it’s</description>
    </item>
    
    <item>
      <title>R4DS: the next iteration</title>
      <link>/post/r4ds-the-next-iteration/</link>
      <pubDate>Fri, 22 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/r4ds-the-next-iteration/</guid>
      <description>Like most online learning endeavors, we had a massive surge of interest at the onset, with exponential drop-offs week after week as we progressively worked through each chapter based on an established schedule. Although everyone who messaged me had their own individual reasons for dropping out, the underlying premise was the same: the pace of the group was too</description>
    </item>
    
    <item>
      <title>How to follow and engage with the R community</title>
      <link>/post/how-to-follow-and-engage-with-/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-follow-and-engage-with-/</guid>
      <description>&amp;ldquo;R is not just a programming language, but it is also an interactive environment for doing data science.&amp;rdquo; &amp;ldquo;Investing a little time in learning R each day will pay off handsomely in the long run.&amp;rdquo;- Hadley Wickham and Garret Grolemund in R for Data Science. When i have heard for the first time about R, i was a student in Bsc in agronomy in Ivory</description>
    </item>
    
    <item>
      <title>rvest &#43; imdb -&gt; explore Friends episode titles</title>
      <link>/post/rvest-imdb-explore-friends-epi/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/rvest-imdb-explore-friends-epi/</guid>
      <description>I always wanted to be a scriptwriter. But my approach to doing creative things is “find the secret, program it, retire”. So what’s the secret to a successful Friends episode? [Really, I want to write/experience a gentle introduction to rvest, and later tidytext and language data science.] Get data I’ll get data on Friends episodes from IMDB via rvest (see here for tutorials and</description>
    </item>
    
    <item>
      <title>A wild R package appears! Pokemon/Gameboy inspired plots in R</title>
      <link>/post/a-wild-r-package-appears-pokem/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/a-wild-r-package-appears-pokem/</guid>
      <description>The package is only available via github so far. The Package comes with a dataset on 801 pokemon with a rich set of attributes. The package includes three main themes for ggplot. If you want to get nostalgic. If you want to get nostalgic, but not too much, use the Gameboy Advanced theme. Let’s look what all time favorite Pikachu looks like. Another thing we can do is to compare the starter Pokemon of all 7</description>
    </item>
    
    <item>
      <title>Functional programming #rstats</title>
      <link>/post/functional-programming-rstats/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/functional-programming-rstats/</guid>
      <description>. Your situation: you have a big data frame you want to apply a (pretty complex) function to each row you are on a Windows server For example, you know baby names are much cooler when they have no vowels and no uppercase letters. # a dataset of babynames library(babynames) # a function that drops vowels from names drop_vowels &amp;lt;- function(text) { gsub(&amp;rdquo;[aeiou]&amp;ldquo;, &amp;ldquo;&amp;rdquo;, text) } mutate_names &amp;lt;- function(tbl) { # names are cooler with no vowels and no capital</description>
    </item>
    
    <item>
      <title>Team Rtus wins Munich Re Datathon with mlr</title>
      <link>/post/team-rtus-wins-munich-re-datat/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/team-rtus-wins-munich-re-datat/</guid>
      <description>On the weekend of November 17. - 19. five brave data-knights from team “Rtus and the knights of the data.table” took on the challenge to compete in a datathon organized by Munich Re in its Munich-based innovation lab. Team Rtus was formed in April this year by a bunch of statistics students from LMU with the purpose to prove their data-skills in competitions with other teams from various</description>
    </item>
    
    <item>
      <title>Writing a paper with RStudio</title>
      <link>/post/writing-a-paper-with-rstudio/</link>
      <pubDate>Sat, 09 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/writing-a-paper-with-rstudio/</guid>
      <description>This semester I had to write a paper for my Financial Econometrics class. My topic was on analyzing the volatility of Bitcoin using GARCH modeling. I’m not particularly interested in Bitcoin, but with all the recent news around it, and with its highly volatile characteristics, I figured it would be a good candidate for analysis. I did the analysis in R, but I wanted to take it a step further. Could I write the entire paper in R and RStudio in a fairly professional format?</description>
    </item>
    
    <item>
      <title>SparkR vs sparklyr for interacting with Spark from R</title>
      <link>/post/sparkr-vs-sparklyr-for-interac/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/sparkr-vs-sparklyr-for-interac/</guid>
      <description>This post grew out of some notes I was making on the differences between SparkR and sparklyr, two packages that provide an R interface to Spark. I’m currently working on a project where I’ll be interacting with data in Spark, so wanted to get a sense of options using R. Those unfamiliar with sparklyr might benefit from reading the first half of this previous post, where I cover the idea of having R objects for connections to Spark</description>
    </item>
    
    <item>
      <title>A Tidytext Analysis of the Weinstein Effect</title>
      <link>/post/a-tidytext-analysis-of-the-wei/</link>
      <pubDate>Sun, 03 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/a-tidytext-analysis-of-the-wei/</guid>
      <description>Quantifying He-Said, She-Said: Newspaper Reporting I have been meaning to get into quantitative text analysis for a while. I initially planned this post to feature a different package (that I wanted to showcase), however I ran into some problems with their .json parsing methods and currently waiting for the issue to be solved on their end. The great thing about doing data science with R is that there are multiple avenues leading you to the same destination, so let’s take advantage of</description>
    </item>
    
    <item>
      <title>EPL week 12</title>
      <link>/post/epl-week-12/</link>
      <pubDate>Tue, 21 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/epl-week-12/</guid>
      <description>Match of the DayFollowing a defeat to North London rivals, Spurs now talking top 4, not title Pulis is outStodgy football and a points-per-game average lower than Steve Clarke will do that for you. His spell at WBA ended with the lowest ppg average of any of his three clubs. The Welsh managership may come calling See the</description>
    </item>
    
    <item>
      <title>Atom for R</title>
      <link>/post/atom-for-r/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/atom-for-r/</guid>
      <description>Last week I was working on some projects involving Posix and R code. I tend to use Atom Editor for such code instead of Rstudio, and sometimes I think the one an only valid contender against Rstudio is Atom Editor. With Hydrogen, Linter, and R language Syntax/autocomplete addins is a full featured editor. Plus, dark mode rocks! One of the most useful features Atom has and Rstudio hasn&amp;rsquo;t is setting syncs via</description>
    </item>
    
    <item>
      <title>Data Cleaning Practice Pt1 - Steak Stats</title>
      <link>/post/data-cleaning-practice-pt1-ste/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/data-cleaning-practice-pt1-ste/</guid>
      <description>For miles down I-40 you&amp;rsquo;ll see billboards for this restaurant and brewery advertising a free 72oz steak, if you can eat it. An office debate erupted amongst two of my colleagues over just what types of people end up beating the beast. They argued. I fired up rvest. Now we have a great starting point for answering some questions, but you may notice a few issues. It&amp;rsquo;s almost like this contest is for fun or something.</description>
    </item>
    
    <item>
      <title>An Example Usage of ggplot_add()</title>
      <link>/post/an-example-usage-of-ggplotadd/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/an-example-usage-of-ggplotadd/</guid>
      <description>You may wonder why this can&amp;rsquo;t be written like this: Let me explain a bit. If ggplot2 were designed pipe-friendly, this Let&amp;rsquo;s remember this</description>
    </item>
    
    <item>
      <title>Firearms Sourced and Recovered in the United States and Territories 2010-2016</title>
      <link>/post/firearms-sourced-and-recovered/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/firearms-sourced-and-recovered/</guid>
      <description>I want to try and probe a question that was raised since Las Vegas and now revived due to the tragedy in Sutherland Springs,TX: Given the free trade between states, can a state unilaterally regulate firearms. This post will try to start to give an answer to this question using R. The shiny app can be run directly We read in the data sources In the app it is easy to see that since the Sandy Hook mass shooting high regulation has caused a large net inflow of firearms into</description>
    </item>
    
    <item>
      <title>Tidyverse Case Study</title>
      <link>/post/tidyverse-case-study/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/tidyverse-case-study/</guid>
      <description>&amp;hellip; data sets regarding songs on the Billboard Hot 100 list from 1960 to 2016, including ranks for the given year, musical features, and lyrics. So, this blogpost walks through how you might start to unpack the data, clean it, and draw some interesting conclusions. I also wanted to avoid the &amp;ldquo;draw the rest of the fucking owl&amp;rdquo; problem. This means that we don&amp;rsquo;t start with a perfectly clean dataset, and I try to take a bit of time to walk through some of the</description>
    </item>
    
    <item>
      <title>esvis: Part 1</title>
      <link>/post/esvis-part-1/</link>
      <pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/esvis-part-1/</guid>
      <description>This is the first of a series of posts to introduce my new esvis R package, why I think it&amp;rsquo;s important, and some of its capabilities. As of this writing the current version on CRAN is 0.0.1, so it&amp;rsquo;s obviously still fresh and may have some bugs. If you find any, please let me know. You can install the package like you would any other on R install.packages(&amp;ldquo;esvis&amp;rdquo;) or if you&amp;rsquo;d prefer the sometimes buggy but more feature-heavy development version, install from github with</description>
    </item>
    
    <item>
      <title>Machine learning and k-fold cross validation with sparklyr</title>
      <link>/post/machine-learning-and-kfold-cro/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/machine-learning-and-kfold-cro/</guid>
      <description>In this post I’m going to run through a brief example of using sparklyr in R. This package provides a way to connect to Spark from within R, while using the dplyr functions we all know and love. I was entirely new to Spark, and databases in general, before having a play with sparklyr. Seemingly its main rival is the more mature SparkR package. Interestingly, SparkR has a number of functions that look very similar to dplyr</description>
    </item>
    
    <item>
      <title>Rocker: Docker for Rstats</title>
      <link>/post/rocker-docker-for-rstats/</link>
      <pubDate>Fri, 27 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/rocker-docker-for-rstats/</guid>
      <description>Last Tuesday (October 24th) I was at Madrid R User Group to give a tech talk about using Docker for automating our setup with Rstudio. Using Rocker images for easy and quick deployment. Here, the slides hoping someone will find it useful.</description>
    </item>
    
    <item>
      <title>Scraping data from the local elections</title>
      <link>/post/scraping-data-from-the-local-e/</link>
      <pubDate>Fri, 27 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/scraping-data-from-the-local-e/</guid>
      <description>One of my journalist friend was looking at the result of the local election in Luxembourg and he was dissatisfied because he was unable to compare the results of all the communes. In fact, he wanted to compare the number of women that were candidates in each commune. So I asked him to hold on and I came back one hour later with this script that enables him to collect results of all communes in one</description>
    </item>
    
    <item>
      <title>So, you’ve decided to change your r package name</title>
      <link>/post/so-youve-decided-to-change-you/</link>
      <pubDate>Fri, 27 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/so-youve-decided-to-change-you/</guid>
      <description>I&amp;rsquo;ve had to change my R package names a few times. Every time I&amp;rsquo;ve had to do this, there were a few things I had to remember to do. Here&amp;rsquo;s a blog post that describes how to do that. When you change your package name, here is a list of things you need to do. And that&amp;rsquo;s basically it! Hooray, now to handle the git business. Now, with this final setup, what you want to do is go into your github repo, go to settings, then change the repo</description>
    </item>
    
    <item>
      <title>Publish R Markdown to Medium via An RStudio Addin</title>
      <link>/post/publish-r-markdown-to-medium-v/</link>
      <pubDate>Thu, 26 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/publish-r-markdown-to-medium-v/</guid>
      <description>mediumr allows you to knit and post R Markdown to Medium. You can install mediumr from github with: The addin knits the Rmd and shows the preview dialog. If it looks ok, click &amp;ldquo;Publish&amp;rdquo;: After successfully uploading the content to Medium, the addin launches a web browser and jumps to the</description>
    </item>
    
    <item>
      <title>Extending slackr</title>
      <link>/post/extending-slackr/</link>
      <pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/extending-slackr/</guid>
      <description>This lets us interact with R and Slack in new ways, by getting active updates on long simulations directly to your (and your team’s) mobile device and multitask away from your computer. Create text progress bar that is sent directly to a Slack channel. This is useful for letting you know when a simulation is done, but also to be able to send to the Slack channel a relevant summary to see that the simulation did as</description>
    </item>
    
    <item>
      <title>dplyr</title>
      <link>/post/dplyr/</link>
      <pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/dplyr/</guid>
      <description>Some of my friends didn&amp;rsquo;t aware that dplyr now accepts characters. Did you? For example, this expression can be also written in this way: or in this way: You may want to write some code that selects columns programmatically using</description>
    </item>
    
    <item>
      <title>jsTree htmlwidget</title>
      <link>/post/jstree-htmlwidget/</link>
      <pubDate>Tue, 24 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/jstree-htmlwidget/</guid>
      <description>jsTree is a R package that is a standalone htmlwidget for the jsTree JavaScript library. It can be run from the R console directly into the Rstudio Viewer, be used in a Shiny application or be part of an Rmarkdown html output. jsTree can be used in Shiny applications and supplies observers so the Shiny can react to the</description>
    </item>
    
    <item>
      <title>liftr (Rmarkdown using docker)</title>
      <link>/post/liftr-rmarkdown-using-docker/</link>
      <pubDate>Sun, 22 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/liftr-rmarkdown-using-docker/</guid>
      <description>I recently discover a R package, called liftr package. It allows the build of pdf document (and html files, but i didn&amp;rsquo;t test it) from a Rmarkdown file. Fully integrated in RStudio, the R code is executed (and other code as well, I tried python) and results are displayed. You don&amp;rsquo;t even need to have LaTeX on your computer, since the document compilation take place in a docker</description>
    </item>
    
    <item>
      <title>The Value of Learning the Basics</title>
      <link>/post/the-value-of-learning-the-basi/</link>
      <pubDate>Wed, 18 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/the-value-of-learning-the-basi/</guid>
      <description>Learning the hard way About a month ago David Robinson made a tweet that I both agree and disagree with. New blog post: “Don&amp;rsquo;t teach students the hard way first” https://t.co/X2drh1tQe5 #rstats pic.twitter.com/GXAEpx5eET — David Robinson (@drob) September 21, 2017 His example is simple enough - you’re going to a friends new house and are provided with directions involving a lot of back roads, twisting and turning. When you arrive you’re told to just take the highway back because it’s</description>
    </item>
    
    <item>
      <title>Bayesian Estimation of Signal Detection Models, Part 3</title>
      <link>/post/bayesian-estimation-of-signal-/</link>
      <pubDate>Mon, 16 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-estimation-of-signal-/</guid>
      <description>This post is the third part in a series of blog posts on Signal Detection models: In the first part, I described how to estimate the equal variance Gaussian SDT (EVSDT) model for a single participant, using Bayesian (generalized linear and nonlinear) modeling techniques. In the second part, I described how to estimate the equal variance Gaussian SDT model for multiple participants simultaneously, using hierarchical Bayesian</description>
    </item>
    
    <item>
      <title>Bayesian Estimation of Signal Detection Models, Part 2</title>
      <link>/post/bayesian-estimation-of-signal-/</link>
      <pubDate>Thu, 12 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-estimation-of-signal-/</guid>
      <description>This post is the second part of a series of three blog posts: In the first part, I described how to estimate the equal variance Gaussian SDT (EVSDT) model for a single participant, using Bayesian (generalized linear and nonlinear) modeling techniques. In the third part, I describe how to estimate the unequal variance Gaussian SDT model as a nonlinear Bayesian</description>
    </item>
    
    <item>
      <title>Searching Stack Overflow</title>
      <link>/post/searching-stack-overflow/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/searching-stack-overflow/</guid>
      <description>Rstudio has recently launched a community site and it seems to be providing a great forum already. One of the topics with over 60 contributions is Choosing between this sitre and StackOverflow for posting a question As long threads tend to do, it went off at a bit of a tangent and following a comment I made, Edward Visel produced some code for reporting on recent posts on ’tidyverse which I have generalized into a shiny app - shown</description>
    </item>
    
    <item>
      <title>Bayesian Estimation of Signal Detection Models, Part 1</title>
      <link>/post/bayesian-estimation-of-signal-/</link>
      <pubDate>Mon, 09 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-estimation-of-signal-/</guid>
      <description>This post is the first part of a series of three blog posts: In the second part, I describe how to estimate the equal variance Gaussian SDT model for multiple participants simultaneously, using hierarchical Bayesian models. In the third part, I describe how to estimate the unequal variance Gaussian SDT model as a hierarchical nonlinear Bayesian</description>
    </item>
    
    <item>
      <title>Introduction to gghighlight</title>
      <link>/post/introduction-to-gghighlight/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/introduction-to-gghighlight/</guid>
      <description>Suppose we have a data that has too many series like this: For such data, it is almost impossible to identify a series by its colour as their differences are so subtle. So, I am motivated to filter data and map colour only on that, using dplyr: (Does &amp;ldquo;non-logical predicate&amp;rdquo; make sense&amp;hellip;? Due to my poor English skill, I couldn&amp;rsquo;t come up with a good term other than this. Any suggestions are wellcome.</description>
    </item>
    
    <item>
      <title>climbing into the crater</title>
      <link>/post/climbing-into-the-crater/</link>
      <pubDate>Sun, 01 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/climbing-into-the-crater/</guid>
      <description>Anyways, given that more waves are available, we don’t have to look at a single comparison between 2007 and 2016, if we want to push Bruenig’s work a little further. The SCF is conducted every 3 years (typically), so we can add two more lines to Bruenig’s graphs to look at 2010 and 2013 as well. Bruenig mentioned on Twitter that the overall patterns came out the same, but I wanted to dig into this on my own as a learning</description>
    </item>
    
    <item>
      <title>Performance Benchmarking for Dummy Variable Creation</title>
      <link>/post/performance-benchmarking-for-d/</link>
      <pubDate>Wed, 27 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/performance-benchmarking-for-d/</guid>
      <description>Motivation Why do we need dummy variables? Ways to create dummy variables in R stats package dummies package dummy package caret package Performance comparison Smaller datasets Large datasets Conclusion Qs Motivation Very recently, at work, we got into a discussion about creation of dummy variables in R code. We were dealing with a fairly large dataset of roughly 500,000 observations for roughly 120 predictor</description>
    </item>
    
    <item>
      <title>Writing your thesis with bookdown</title>
      <link>/post/writing-your-thesis-with-bookd/</link>
      <pubDate>Mon, 25 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/writing-your-thesis-with-bookd/</guid>
      <description>This post details some tips and tricks for writing a thesis/dissertation using the bookdown R package by Yihui Xie. The idea of this post is to supplement the fantastic book that Xie has written about bookdown, which can be found here. I will assume that readers know a bit about R Markdown; a decent knowledge of R Markdown is going to be essential to using bookdown. The first thing to highlight is that I’m not a pandoc or LaTeX</description>
    </item>
    
    <item>
      <title>A pesky piping bug with RStudio and the tidyverse</title>
      <link>/post/a-pesky-piping-bug-with-rstudi/</link>
      <pubDate>Thu, 21 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/a-pesky-piping-bug-with-rstudi/</guid>
      <description>You have a data frame you want to alter using piping, something like this. As far as bugs go, this is fairly inconsequential. However, it took me a while to debug the error on a somewhat complicated 15 line pipe with ggplot, because of the inconsistency in the error R spat out as well as the innocuousness of the causitive code. Do you get the same errors as I do? If so, should it be fixed, or is there a purpose I’m not</description>
    </item>
    
    <item>
      <title>Little&#39;s MCAR test at different sample sizes</title>
      <link>/post/littles-mcar-test-at-different/</link>
      <pubDate>Thu, 21 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/littles-mcar-test-at-different/</guid>
      <description>TLDR: Little&amp;rsquo;s MCAR test is unable to tell data that are MCAR from data that are MAR in small samples, but maintains the nominal error rate when null is true across a wide range of sample sizes. I just found out about the R simglm package and decided to do a small simulation to test Little&amp;rsquo;s MCAR test1 under different sample sizes. I could have investigated heteroskedasticity in linear regression instead, and I probably will in the</description>
    </item>
    
    <item>
      <title>GG what!</title>
      <link>/post/gg-what/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/gg-what/</guid>
      <description>The ggplot2 package and its extensions dominate the R visualization landscape, particularly for static charts It got me thinking about how rare was that combination of two ’g’s to start a word - at least in the English language. Luckily, there is a source on github extracted from an infochimps source Not exactly a mind-blowing exercise, but a useful way to use a few techniques from the</description>
    </item>
    
    <item>
      <title>Hvordan klarer de politiske partier sig på Facebook?</title>
      <link>/post/hvordan-klarer-de-politiske-pa/</link>
      <pubDate>Tue, 19 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/hvordan-klarer-de-politiske-pa/</guid>
      <description>På de respektive facebook-sider kan vi naturligvis også finde antallet af følgere - dem gemmer vi også lige, da vi skal bruge dem senere. Vi har altså en del data på hvert post - hvornår den er afsendt, hvilken type post (video, tekst, billede) samt hvor mange likes, kommentarer og delinger der er. Især den sidste del er interessant for at undersøge hvor godt de forskellige partier præsterer på Facebook. Med disse data i hånden er det nu en smal sag at begynde selve</description>
    </item>
    
    <item>
      <title>Linear regression with violation of heteroskedasticity with small samples</title>
      <link>/post/linear-regression-with-violati/</link>
      <pubDate>Tue, 19 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/linear-regression-with-violati/</guid>
      <description>TLDR: In small samples, the wild bootstrap implemented in the R hcci package is a good bet when heteroskedasticity is a concern. Today while teaching the multiple regression lab, I showed the class the standardized residuals versus standardized predictor plot SPSS lets you produce. It is the plot we typically use to assess homoskedasticity. The sample size for the analysis was 44. I mentioned how the regression slopes are fine under heteroskedasticity, but inference $(t, SE, pvalue)$ may be</description>
    </item>
    
    <item>
      <title>Automating roxygen2 package documentation</title>
      <link>/post/automating-roxygen2-package-do/</link>
      <pubDate>Mon, 18 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/automating-roxygen2-package-do/</guid>
      <description>Quick example, run it in R: or document functions interactively with the shiny gadget: Let me explain by example&amp;hellip; This gets me on my way, but there is information nested within the function itself that can be useful to document and manage the namespace I could just add that manually but this is just a toy example, actual functions have many parameters and you can import many functions from a number of different</description>
    </item>
    
    <item>
      <title>Examining Variability in Physical Activity Data with R</title>
      <link>/post/examining-variability-in-physi/</link>
      <pubDate>Sun, 10 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/examining-variability-in-physi/</guid>
      <description>Earlier this summer, while I was traveling to a conference I came across an interesting paper published by a group from the University of South Florida that explored strategies for interpreting highly variable data from long-term use of a Fitbit. I’ll let them explain: It’s an interesting paper, with some general, easy-to-use, methods of visualizing daily-scale time series data. While reading it, I got to thinking that all of the methods they explored should be able to be easily reproducible in</description>
    </item>
    
    <item>
      <title>Bucket List</title>
      <link>/post/bucket-list/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/bucket-list/</guid>
      <description>Bucket List Most people end up having a list of things they’d like to do in their life before they ‘kick the bucket’. Often this is made up of big events - a foreign trip, some daredevil adventure. But sometimes that list is a bunch of little things. R I’ve published a package on CRAN - readOffice - which was designed to enable the importing of text from modern Microsoft Word and PowerPoint</description>
    </item>
    
    <item>
      <title>Advice for non-traditional data scientists</title>
      <link>/post/advice-for-nontraditional-data/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/advice-for-nontraditional-data/</guid>
      <description>I have a pretty strange background for a data scientist. In my career I’ve sold electric razors, worked on credit derivatives during the 2008 financial crash, written market reports on orthopaedic biomaterials, and practiced law. I started programming in R during law school, partly as a way to learn more about data visualization and partly to help analyze youth criminal justice data. Over time I came to enjoy programming more than law and decided to make the switch to data work about three years</description>
    </item>
    
    <item>
      <title>Selecting packages while coding</title>
      <link>/post/selecting-packages-while-codin/</link>
      <pubDate>Tue, 29 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/selecting-packages-while-codin/</guid>
      <description>Sometimes, you must choose a package to achieve some results while you&amp;rsquo;re coding. Let&amp;rsquo;s say, you&amp;rsquo;re wrangling data and noticed you need a quick way of getting the mode of a vector. Base R does not provides such a method/function, but we can get a package to make our life easier (mode is not a hard working function you can code, but let&amp;rsquo;s use it for the sake of the hint described</description>
    </item>
    
    <item>
      <title>Financial Numerical Methods - Part 1</title>
      <link>/post/financial-numerical-methods-pa/</link>
      <pubDate>Mon, 28 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/financial-numerical-methods-pa/</guid>
      <description>Where: Interestingly, we actually have the solution to this equation (one of the few we have analytical solutions for): More generally, this can be written as a formula providing us with the recursive equation: I was given some starting parameters: We all know loops are to be avoided when you can in R, and that you should instead vectorize the operations. At first, I thought this wasn’t going to be possible, as this is a recursive type of formula where the next value relies on the previous</description>
    </item>
    
    <item>
      <title>First post !</title>
      <link>/post/first-post-/</link>
      <pubDate>Sun, 20 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/first-post-/</guid>
      <description>First of all, welcome to this site ! As the about says, this blog purpose is to talking about OpenGIS, Python, R, data nalysis and stuff like that. I will be probably publishing learning notebooks as i do them to improve my knowledge. When possible, I&amp;rsquo;ll publish original stuff, depends on current affairs. Cheers !</description>
    </item>
    
    <item>
      <title>Which RStudio blog posts “pleased” Hadley? A tidytext &#43; web scraping analysis</title>
      <link>/post/which-rstudio-blog-posts-pleas/</link>
      <pubDate>Wed, 16 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/which-rstudio-blog-posts-pleas/</guid>
      <description>Awhile back, I saw a conversation on twitter about how Hadley uses the word “pleased” very often when introducing a new blog post (I couldn’t seem to find this tweet anymore. Can anyone help?). Out of curiousity, and to flex my R web scraping muscles a bit, I’ve decided to analyze the 240+ blog posts that RStudio has put out since 2011. This post will do a few things: Spoiler alert: Hadley uses “pleased”</description>
    </item>
    
    <item>
      <title>Friendships among top R-twitterers</title>
      <link>/post/friendships-among-top-rtwitter/</link>
      <pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/friendships-among-top-rtwitter/</guid>
      <description>After loading my precious packages&amp;hellip; Now, let&amp;rsquo;s extract some useful information about those users: You&amp;rsquo;ll notice, that created data frame holds information about number of followers, friends (users they follow), lists they belong to, number of tweets (statuses) or how many times sometimes marked those tweets as their favourite. And these variables I use for building my &amp;lsquo;top score&amp;rsquo;: I simply calculate a percentile for each of those variables and sum it</description>
    </item>
    
    <item>
      <title>calculating date diffs per event with dplyr</title>
      <link>/post/calculating-date-diffs-per-eve/</link>
      <pubDate>Sat, 12 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/calculating-date-diffs-per-eve/</guid>
      <description>Sometimes you&amp;rsquo;d need to calculate rolling date diffs from a vector or a data frame when you&amp;rsquo;re manipulating repeated events from different categories. It&amp;rsquo;s very easy and I&amp;rsquo;ll show you three different methods. Using dplyr and pipes, easy peasy! Take into account that lubridate has three classes or different ways, to define time</description>
    </item>
    
    <item>
      <title>Sharing R products</title>
      <link>/post/sharing-r-products/</link>
      <pubDate>Thu, 10 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/sharing-r-products/</guid>
      <description>Sharing R data (.rda) and R code (.R) files is becoming more common in the social sciences. Brilliant! However, I think that the process of sharing R products could be made significantly easier for everyone involved if people followed one simple piece of advice: Don’t set R’s working directory from within an R script. Sharing data is easy, because users can put the data wherever they want on their computers, and use it from</description>
    </item>
    
    <item>
      <title>Making this Blog</title>
      <link>/post/making-this-blog/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/making-this-blog/</guid>
      <description>blogdown magic I made this blog using the magic of blogdown which is a framework that joins together a few technologies to make ‘static websites’ RMarkdown Hugo RMarkdown RMarkdown is an interface from R to markdown which is a way of marking up a text document with formating so other tools can convert it from a text file to a pretty format (PDF, Word, etc.) It’s a great way of documenting your code by having your narrative right next to the code that generated the</description>
    </item>
    
    <item>
      <title>How to navigate the world of R packages</title>
      <link>/post/how-to-navigate-the-world-of-r/</link>
      <pubDate>Mon, 07 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/how-to-navigate-the-world-of-r/</guid>
      <description>One of the most powerful features of R is the vast package echosystem. But there&amp;rsquo;s more than 11.000 packages just in CRAN, and a thousands more if you take GIT and Bioconductor into account, so the issue is to find the proper package for your needs. There’s a lot of sites to search for help if you need a hand when programming in R to choose a package. Here, a list of some of</description>
    </item>
    
    <item>
      <title>Bournemouth to bash on?</title>
      <link>/post/bournemouth-to-bash-on/</link>
      <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/bournemouth-to-bash-on/</guid>
      <description>I have plans to hive off the soccer/football section off to a separate blog as many sports readers will not be interested in code but until then, here is my latest effort As the new season is now upon us it was time to post a new article. I have also been intending to pen something based around James Curley’s excellent engsoccerdata package which anyone interested in R and European football should definitely check</description>
    </item>
    
    <item>
      <title>Combining R and Python for data analysis</title>
      <link>/post/combining-r-and-python-for-dat/</link>
      <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/combining-r-and-python-for-dat/</guid>
      <description>The main drawback of doing it this way is that I am losing on the interactive explorative tools included in HyperSpy. For this reason my workflow has been to interactively explore and develop the Python code in a Jupyter Notebook, and then copy the final script to a Python chunk in an R Markdown document. I do this to keep the final product together and get a completely reproducible analysis in my R Markdown document.</description>
    </item>
    
    <item>
      <title>Pimping the StatCan Blog</title>
      <link>/post/pimping-the-statcan-blog/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/pimping-the-statcan-blog/</guid>
      <description>Statistics Canada make available masses of useful data from Censuses and Surveys. One way they communicate is via twitter e.g. library(blogdown) shortcode(&amp;ldquo;tweet&amp;rdquo;, &amp;ldquo;891757886011002883&amp;rdquo;)In 2001, 31% of young adults (aged 20 to 34) were still living with their</description>
    </item>
    
    <item>
      <title>janitor, a good R package for Data Wrangling</title>
      <link>/post/janitor-a-good-r-package-for-d/</link>
      <pubDate>Thu, 27 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/janitor-a-good-r-package-for-d/</guid>
      <description>We all know the many hours spent cleaning and wrangling data. Sometimes I think my actual job is not “Data Scientist” but “Data Cleaner”. Data, as you surely know, is not often in the best shape, so for many people like me, one of the most appreciated tools is the one that makes cleaning</description>
    </item>
    
    <item>
      <title>Automated congratulatory tweet to Twitter Friends</title>
      <link>/post/automated-congratulatory-tweet/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/automated-congratulatory-tweet/</guid>
      <description>On the front page of my premiersoccerstats site, I have a Player Milestones table which highlights players who have reached certain levels in the Premier League’s latest round of games e.g. 100 Appearances This requires comparing two datasets and subsetting the rows with differences in the variable of interest. To this end, I use the daff package which was the subject of a presentation at the recent R User 2017</description>
    </item>
    
    <item>
      <title>Processing mail using R</title>
      <link>/post/processing-mail-using-r/</link>
      <pubDate>Sun, 23 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/processing-mail-using-r/</guid>
      <description>After a long time seeking for R packages to connect to a remote mailbox (not Gmail), I’ve had to admit that there’s no such feature right now in R. Tested a pair of Python scripts but too much convoluted to my needs. It’s an incredible issue that having more than 10 thousand packages available on CRAN, none of them was suitable for my needs. Some readers suggested tm.plugin.mail added to tm package, but my core feature is to connect to a remote</description>
    </item>
    
    <item>
      <title>3D chart using rgl library</title>
      <link>/post/3d-chart-using-rgl-library/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/3d-chart-using-rgl-library/</guid>
      <description>Iris is one of the most used data set in R. We’ve seen it in many formats, and broadly used for data manipulation. You could say that there’s nothing new to learn if someone use Iris. I was wondering if there’s something new, something never done to it before. Just a couple of clicks and found a way to have an interactive animated 3D chart. Just use the mouse pointer to drag and change perspective and move</description>
    </item>
    
    <item>
      <title>User2017- padr package example</title>
      <link>/post/user2017-padr-package-example/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/user2017-padr-package-example/</guid>
      <description>Of course, it is not the same as actually being there, but as a good fall-back the videos of the talks for the R User 2017 conference are now available on channel 9. I’ll be dipping into them over the next few weeks and reporting on any I find of interest. Let’s kick-off with the padr package from Edwin Thoen. It is on</description>
    </item>
    
    <item>
      <title>managing installation and packages in R</title>
      <link>/post/managing-installation-and-pack/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/managing-installation-and-pack/</guid>
      <description>Mentioned yesterday the useful library pacman , so a brief comment about it is due. But I&amp;rsquo;m going to recommend installR for managing updates first (packages and R itself). With a console command, and just for windows users, it&amp;rsquo;s so easy to keep your Rstudio</description>
    </item>
    
    <item>
      <title>fourfoldplot</title>
      <link>/post/fourfoldplot/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/fourfoldplot/</guid>
      <description>Working with R, it’s high likely you end with a table regarding to dichotomous variables in your datasets no matter the specific project you’re involved in. I like the ConfusionMatrix function from caret package, that calculates a cross-tabulation of observed and predicted classes. Here an example from caret</description>
    </item>
    
    <item>
      <title>Some essential R packages</title>
      <link>/post/some-essential-r-packages/</link>
      <pubDate>Sat, 15 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/some-essential-r-packages/</guid>
      <description>For me, there’s a bunch of packages considered as “essential” ‘cause in the end, sooner or later I use them in any project that involved opening the RStudio regardless of the type of issue that I’m trying to address. At some point in the process I need to present preliminary data (knitr, rmarkdown, janitor), display graphs (ggplot2, ggthemes, ggThemeAssist, gridBase, grid, corrplot) or simply manipulate data (dplyr, tidyr,</description>
    </item>
    
    <item>
      <title>First thing first: Thanks!</title>
      <link>/post/first-thing-first-thanks/</link>
      <pubDate>Wed, 12 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/first-thing-first-thanks/</guid>
      <description>First things first. Question of etiquette, when starting a blog like this, mainly focused on Data Science with R, is to acknowledge all the people and teams that made possible that I&amp;rsquo;m writing this today. People from CRAN, Rstudio and the R consortium, for pushing forward the best language in the world for data analytics. A language I love from the first day. Today, many years ago, i still remember my goose bumps when writing R code for the first</description>
    </item>
    
    <item>
      <title>Mapping Eurostat information Part 1</title>
      <link>/post/mapping-eurostat-information-p/</link>
      <pubDate>Tue, 11 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/mapping-eurostat-information-p/</guid>
      <description>Keeping up with the theme of utilizing official government open data to map via an R package I will now turn to the eurostat package which accesses data - via an API - from the European Commission. First released in 2015, there is an article (wuth R code) by its authors in the most recent issue of the R Journal,9&amp;frasl;1 which makes for an interesting read covering a variety of</description>
    </item>
    
    <item>
      <title>Benchmarking different implementations of weighted-ALS matrix factorization</title>
      <link>/post/benchmarking-different-impleme/</link>
      <pubDate>Mon, 10 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/benchmarking-different-impleme/</guid>
      <description>updated 01/08/2017 - added CG solver in reco, adjusted results As I promised in last post, I’m going to share benchmark of different implementation of matrix factorization with Weighted Alternating Least Squares. User-Item interaction matrix is made from lastfm-360K dataset. Implementations incude: My reco R package Ben Frederickson implicit python module Apache Spark implementation Quora’s qmf solver For the transparency I’ve created repository with all the</description>
    </item>
    
    <item>
      <title>Open Science tools for our research group</title>
      <link>/post/open-science-tools-for-our-res/</link>
      <pubDate>Mon, 10 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/open-science-tools-for-our-res/</guid>
      <description>I have been considering how to apply this thinking to our research. I am confident that it could be made more efficient and well-documented if R was adopted as a general tool for data analysis. If you recieve a spreadsheet from someone, containing some data analysis it can be very hard to decipher the thinking of the original author (and to be honest, analysis done by yourself 6 monts ago might as well have been done by a complete</description>
    </item>
    
    <item>
      <title>Mapping ADA Voting Scores 1947-2015</title>
      <link>/post/mapping-ada-voting-scores-1947/</link>
      <pubDate>Tue, 04 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/mapping-ada-voting-scores-1947/</guid>
      <description>Tracking Legislator Voting Patterns How do US legislators vote once they get elected? Or, perhaps more dynamically, how do they react to external shocks (e.g. the dissolution of the Soviet Union, 9&amp;frasl;11) that might blur partisan lines? More generally, how does voting behavior change across time and space? Let’s try to provide some answers to these questions using R. You can jump straight to the interactive Shiny app by clicking</description>
    </item>
    
    <item>
      <title>CEEA Reflections</title>
      <link>/post/ceea-reflections/</link>
      <pubDate>Mon, 12 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/ceea-reflections/</guid>
      <description>Yes, I get it. I don&amp;rsquo;t post often enough. I think I&amp;rsquo;m going to change that though, and overhaul things around here, for a few reasons. Better place to showcase my own work A place for professional reflection Interaction with the rstats and visualization communities Personal portfolio Since I was last here my kids have grown (!), my wife and I continue on the parenting journey (whee!), I launched my consulting career</description>
    </item>
    
    <item>
      <title>When marginal and conditional logistic model estimates diverge</title>
      <link>/post/when-marginal-and-conditional-/</link>
      <pubDate>Fri, 09 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/when-marginal-and-conditional-/</guid>
      <description>My aim is to show this through a couple of data simulations that allow us to see this visually. Now let’s generate some data and look at it: Since we have repeated measurements for each cluster (the two potential outcomes), we can transform this into a “longitudinal” data set, though the periods are not time but different exposures. When we look at the data visually, we get a hint that the marginal (or average) effect might not be the same as the conditional (cluster-specific)</description>
    </item>
    
    <item>
      <title>Ages by England &amp; Wales constituency</title>
      <link>/post/ages-by-england-wales-constitu/</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/ages-by-england-wales-constitu/</guid>
      <description>There is are a lot of opportunities for data visualizations in journalism and R is beginning to get a toehold in this arena I recently came across a for-loop tutorial from the R for journalists blog and decided to reprocess it using tidyverse packages whilst adding a plot and map The article uses some GB office of National Statistics data to calculate the estimated mean age of the population of each of the England and Wales parliamentary</description>
    </item>
    
    <item>
      <title>Integrating dplyr with Remote databases</title>
      <link>/post/integrating-dplyr-with-remote-/</link>
      <pubDate>Tue, 23 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/integrating-dplyr-with-remote-/</guid>
      <description>A recent RViews article covers the use of the dplyr package to interact with SQL databases All the code can be written in R, which dplyr then translates into SQL queries to harness the power of a database You will probably want to read the article if interested in extending the process to your own data but here is a taster from some of</description>
    </item>
    
    <item>
      <title>Get Sankey! Sankey diagrams for infosec</title>
      <link>/post/get-sankey-sankey-diagrams-for/</link>
      <pubDate>Fri, 19 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/get-sankey-sankey-diagrams-for/</guid>
      <description>Yesterday, a tweet caught my eye. It was something that I know I’d seen before, but it somehow had escaped my memory as to what it was called or how it was constructed. Well, it bugged me enough that I had to track it down. As I am currently neck deep in writing an annual risk report it’d be easy for me to agree with the thought. So, let’s play with them in the googleVis package for</description>
    </item>
    
    <item>
      <title>It can be easy to explore data generating mechanisms with the simstudy package</title>
      <link>/post/it-can-be-easy-to-explore-data/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/it-can-be-easy-to-explore-data/</guid>
      <description>I learned statistics and probability by simulating data. Sure, I did the occasional proof, but I never believed the results until I saw it in a simulation. I guess I have it backwards, but I that’s just the way I am. And now that I am a so-called professional, I continue to use simulation to understand models, to do sample size estimates and power calculations, and of course to teach. Sure - I’ll use the occasional formula when one exists, but I always feel the need to check it with</description>
    </item>
    
    <item>
      <title>shinyMlr</title>
      <link>/post/shinymlr/</link>
      <pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/shinymlr/</guid>
      <description>shinyMlr is a web application, built with the R-package “shiny” that provides a user interface for mlr. By wrapping the main functionalities of mlr into our app, as well as implementing additional features for data visualisation and data preprocessing, we built a widely usable application for your day to day machine learning tasks, which we would like to present to you</description>
    </item>
    
    <item>
      <title>Just a Test Post From Blogdown</title>
      <link>/post/just-a-test-post-from-blogdown/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/just-a-test-post-from-blogdown/</guid>
      <description>So, Yihui Xie gifted the RStats world with another presentation surface. Now you can easily produce Hugo generated blogs right from RStudio! Oh, and it&amp;rsquo;s pretty</description>
    </item>
    
    <item>
      <title>RStudio and Shiny Servers with AWS - Part 1</title>
      <link>/post/rstudio-and-shiny-servers-with/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/rstudio-and-shiny-servers-with/</guid>
      <description>After realizing how fast I can burn through my free 25 hours on shinyapps.io, I decided to repurpose my RStudio Server to also work with Shiny Server. Here’s my new setup: In case I ever have to go through this madness again, or if anyone else wants to, I’ve compiled some step by step notes on the</description>
    </item>
    
    <item>
      <title>Amazon RDS &#43; R</title>
      <link>/post/amazon-rds-r/</link>
      <pubDate>Wed, 10 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/amazon-rds-r/</guid>
      <description>Welcome to my first post! To start things off at Data Insights, I’m going to show you how to connect to an AWS RDS instance from R. For those of you who don’t know, RDS is an easy way to create a database in the cloud. In this post, I won’t be showing you how to setup an RDS instance, but I will show you how to connect to it if you have one running.</description>
    </item>
    
    <item>
      <title>Everyone knows that loops in R are to be avoided, but vectorization is not always possible</title>
      <link>/post/everyone-knows-that-loops-in-r/</link>
      <pubDate>Wed, 10 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/everyone-knows-that-loops-in-r/</guid>
      <description>Again, the specifics of the simulation are not important here. What is important, is the notion that the problem requires looking through individual data sequentially, something R is generally not so good at when the sequences get particularly long, and they must be repeated a large number of times. As you can see, things got markedly faster. And here is a more complete comparison of the fastest version with this additional</description>
    </item>
    
    <item>
      <title>You should make an R package for your paper</title>
      <link>/post/you-should-make-an-r-package-f/</link>
      <pubDate>Wed, 10 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/you-should-make-an-r-package-f/</guid>
      <description>R packages are made up of three main things: (1) data, (2) functions, and (3) documentation. Combining them into a single, self-contained bundle, means that all of the computational work from a project can be found in one place, downloaded and installed simply, and then run with a freely availible software anyone can obtain. As an added bonus you can even add a vignette to the package, which you can use to illustrate example analyses or a sample</description>
    </item>
    
    <item>
      <title>sinew</title>
      <link>/post/sinew/</link>
      <pubDate>Wed, 03 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/sinew/</guid>
      <description>Sinew is a R package that generates a Roxygen skeleton populated with information scraped from the function script. The added value of sinew is that it scrapes the script and fills in many important holes in the documentation: Examples showing different parameter specification in makeOxygen makeOxygen also creates documentation for data.frames and tibble objects The function is written to work on single files or whole directories, like a package R</description>
    </item>
    
    <item>
      <title>Intro to R workshop</title>
      <link>/post/intro-to-r-workshop/</link>
      <pubDate>Sat, 29 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/intro-to-r-workshop/</guid>
      <description>Last week, I had a pleasure to conduct a workshop for graduate students and faculty in the Department of Geography and GIS at the University of Cincinnati. In two afternoons, a group of mostly beginners, learned a little bit about R, RStudio, data processing, and visualisation, as well as about spatial data analysis in R. The workshop had four parts: Moreover, each part ends with a list of useful resources - let me know if I missed</description>
    </item>
    
    <item>
      <title>Assorted Shiny apps collection, full code and data</title>
      <link>/post/assorted-shiny-apps-collection/</link>
      <pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/assorted-shiny-apps-collection/</guid>
      <description>A bit of backstory. If I recall correctly, I began exploring RStudio’s Shiny package when I first heard of it in late 2012. Needless to say, a lot has changed since then, including not only all the alpha-release code-breaking changes I had to adjust to when making my first apps and what features and capabilities Shiny has grown to offer, but also simply how I go about coding apps has changed over time symbiotically with the package’s continued</description>
    </item>
    
    <item>
      <title>Data Visualization and UI design</title>
      <link>/post/data-visualization-and-ui-desi/</link>
      <pubDate>Thu, 13 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/data-visualization-and-ui-desi/</guid>
      <description>While I think the basic idea of the initial app was a good one, the implementation had a lot of problems. The user interface was confusing and there were a lot of counter-intuitive design decisions. Since I was the source of most of these decisions, I thought the release of version 2.0 of the app would be a good opportunity to write down some of the things I’ve</description>
    </item>
    
    <item>
      <title>slickR</title>
      <link>/post/slickr/</link>
      <pubDate>Fri, 07 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/slickr/</guid>
      <description>This tool helps review multiple outputs in an efficient manner and saves much needed space in documents and Shiny applications, while creating a user friendly experience. These carousels can be used directly from the R console, from RStudio, in Shiny apps and R Markdown documents. Some web scraping for the images</description>
    </item>
    
    <item>
      <title>ggedit 0.2.0</title>
      <link>/post/ggedit-020/</link>
      <pubDate>Fri, 31 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/ggedit-020/</guid>
      <description>To install the package you can call the standard R command To install the dev version: ggedit is an R package that is used to facilitate ggplot formatting. With ggedit, R users of all experience levels can easily move from creating ggplots to refining aesthetic details, all while maintaining portability for further reproducible research and collaboration. ggedit is run from an R console or as a reactive object in any Shiny application.</description>
    </item>
    
    <item>
      <title>UK 2015 Election Mapped</title>
      <link>/post/uk-2015-election-mapped/</link>
      <pubDate>Wed, 29 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/uk-2015-election-mapped/</guid>
      <description>Just providing a quick update to the previous post. Since that was done a few weeks ago, Evan Odell has been doing some great work on enhancing his Hansard package details of which you can view here. I plan to do some more work on this incredible resource in the future but for now am just looking at some</description>
    </item>
    
    <item>
      <title>Use mlrMBO to optimize via command line</title>
      <link>/post/use-mlrmbo-to-optimize-via-com/</link>
      <pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/use-mlrmbo-to-optimize-via-com/</guid>
      <description>Many people who want to apply Bayesian optimization want to use it to optimize an algorithm that is not implemented in R but runs on the command line as a shell script or an executable. We recently published mlrMBO on CRAN. As a normal package it normally operates inside of R, but with this post I want to demonstrate how mlrMBO can be used to optimize an external application. At the same time I will highlight some issues you can likely run</description>
    </item>
    
    <item>
      <title>Twitter Followers Collage</title>
      <link>/post/twitter-followers-collage/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/twitter-followers-collage/</guid>
      <description>A relatively new, but extremely welcome, additon to the R blogosphere is Maëlle Salmon She recently posted Faces of #rstats Twitter, which describes how to get a collage of 50x50px images of tweeters with ‘rstats’ in their profile Here is the end-product There are around 450 images, which happens to match my current number of followers so I thought I would adapt her code accordingly I have set the code to eval=FALSE to obviate a yet-to-be-resolved error when I remove a</description>
    </item>
    
    <item>
      <title>Being successful on Kaggle using mlr</title>
      <link>/post/being-successful-on-kaggle-usi/</link>
      <pubDate>Thu, 09 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/being-successful-on-kaggle-usi/</guid>
      <description>Achieving a good score on a Kaggle competition is typically quite difficult. This blog post outlines 7 tips for beginners to improve their ranking on the Kaggle leaderboards. For this purpose, I also created a Kernel for the Kaggle bike sharing competition that shows how the R package, mlr, can be used to tune a xgboost model with random search in parallel (using 16 cores). The R script scores rank 90 (of 3251) on the Kaggle</description>
    </item>
    
    <item>
      <title>Spotify - all 20 million tracks</title>
      <link>/post/spotify-all-20-million-tracks/</link>
      <pubDate>Mon, 27 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/spotify-all-20-million-tracks/</guid>
      <description>I have consistently been interested in assessing music information in R, for example my - somewhat dormant -charts dashboard A recent, excellent, blog post by RCharlie featuring the Spotify and Genius APIs to determine a ‘Gloom Index’ for Radiohead tracks piqued my interest. It also incorporates some illuminating code using the purrr package The Spotify,</description>
    </item>
    
    <item>
      <title>The Power of Tidy Data</title>
      <link>/post/the-power-of-tidy-data/</link>
      <pubDate>Thu, 16 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/the-power-of-tidy-data/</guid>
      <description>One problem with data analysis is that you often need to make critical decisions before you really understand the problem. Since data analysis is always somewhat exploratory you can often make some bad decisions in the early stages of your analysis which can cause lots of problems later on. Maybe at some point you thought that storing your data in a nested list was a good idea, but curse yourself when you try to draw a graph with that</description>
    </item>
    
    <item>
      <title>Fitting logistic regression on 100gb dataset on a laptop</title>
      <link>/post/fitting-logistic-regression-on/</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/fitting-logistic-regression-on/</guid>
      <description>EDIT: Thanks for comments, I created repository with full end-to-end reproducible code. You can find it here - https://github.com/dselivanov/kaggle-outbrain. This is continue of Lessons learned from “Outbrain Click Prediction” kaggle competition (part 1). As a quick recap - we achieved MAP@12 ~ 0.67 which is equal to ~90-100 position on leaderboard. And we didn’t use information about page views from 100gb (30gb compressed) page_views.csv.zip</description>
    </item>
    
    <item>
      <title>R for Excel Users</title>
      <link>/post/r-for-excel-users/</link>
      <pubDate>Thu, 02 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/r-for-excel-users/</guid>
      <description>Like most people, I first learned to work with numbers through an Excel spreadsheet. After graduating with an undergraduate philosophy degree, I somehow convinced a medical device marketing firm to give me a job writing Excel reports on the orthopedic biomaterials market. When I first started, I remember not knowing how to anything, but after a few months I became fairly proficient with the tool, and was able to build all sorts of useful</description>
    </item>
    
    <item>
      <title>Finite Mixture Modeling using Flexmix</title>
      <link>/post/finite-mixture-modeling-using-/</link>
      <pubDate>Wed, 01 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/finite-mixture-modeling-using-/</guid>
      <description>Model Based Clustering Quick EDA Model building Mixtures of Regressions Quick EDA Model Building Results Further investigation Notes References This page replicates the codes written by Grun &amp;amp; Leish (2007) in ‘FlexMix: An R package for finite mixture modelling’, University of Wollongong, Australia. My intent here was to learn the flexmix package by replicating the results by the authors. Model Based Clustering The model based clustering on the whiskey</description>
    </item>
    
    <item>
      <title>Intro to R slides</title>
      <link>/post/intro-to-r-slides/</link>
      <pubDate>Tue, 31 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/intro-to-r-slides/</guid>
      <description>For the Perception Action and Cognition Lab Open Science Week, 2017 (University of Leeds) I gave two talks introducing R. You can see the slides below. The code for the slides can be found over at GitHub. An introduction to R In this introduction to R I focused on tools from the tidyverse, as well as trying to provide some motivation for learning R. The audience was academics and postgraduates in a psychology</description>
    </item>
    
    <item>
      <title>Notebook Collaboration</title>
      <link>/post/notebook-collaboration/</link>
      <pubDate>Fri, 13 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/notebook-collaboration/</guid>
      <description>Wild boars amongst usOne of the great virtues of R Notebooks is the ease of collaboration and Tuija Sonkkila recently kindly made hers on wild boars available As - in a former existence - I was a pork buyer for a grocery chain, this piqued (almost-pun intended) my interest. So I just hit the code &amp;gt; Download Rmd button, and opened the resulting notebook file in RStudio to play</description>
    </item>
    
    <item>
      <title>Magic reprex</title>
      <link>/post/magic-reprex/</link>
      <pubDate>Wed, 11 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/magic-reprex/</guid>
      <description>Making reproducible examples can be hard. There&amp;rsquo;s a lot of things you need to consider. Like, making sure your environment is clean, the right packages are loaded, the code is formatted nicely, and images are the right resolution and dimension. Getting all of these ducks lined up can sometimes take a couple of minutes, if you have a nice tightly defined problem. Other times, it can take much, much</description>
    </item>
    
    <item>
      <title>Mapping Starbucks Locations</title>
      <link>/post/mapping-starbucks-locations/</link>
      <pubDate>Wed, 11 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/mapping-starbucks-locations/</guid>
      <description>This is where I’ll be posting tutorials on how to use R and Rstudio to create some amazing graphics and visualizations. If you are completely new to R, don’t worry, I will post guides to explain how to start form scratch. This post assumes you have R and Rstudio installed and know how to install packages. For this tutorial you will need to download tidyverse, RCurl, and leaflet which you can do in the bottom right panel of Rstudio by clicking the install</description>
    </item>
    
  </channel>
</rss>